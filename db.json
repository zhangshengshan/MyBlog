{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[],"Cache":[{"_id":"source/_posts/Deep-MNIST-for-Experts.md","hash":"49314fb40acd52d9520632f4046e52d3e730895a","modified":1483769231867},{"_id":"source/_posts/Google-面试宝典.md","hash":"bffd097caee4e0006b9c20dcd1cf62e3bc5e7331","modified":1483769231867},{"_id":"source/_posts/Install-Caffe-on-CentOS.md","hash":"da9ed9b5c630cd62d9c3cef3d49c4ef6eccb9c43","modified":1481520210960},{"_id":"source/_posts/LearningFlink.md","hash":"6027c27c60652efa27a29a7c1a844a9abed999d0","modified":1483769531669},{"_id":"source/_posts/MAC访问你DOCKER容器中的WEB页面.md","hash":"45f818e11c8c77ff60821f24ab3fd7c31341b98f","modified":1481520210960},{"_id":"source/_posts/17年要读的书和学习的技能.md","hash":"5c5a9a059e449e5309600c4c93e7c81fc397c8e9","modified":1481520210960},{"_id":"source/_posts/1-100素数判断pyhon程序.md","hash":"30a99579fa7cdaaba229d711e239349bf20e66b3","modified":1481520210960},{"_id":"source/_posts/3-2UVa1586.md","hash":"4e0f44ca2157cb91898eeb217af6d72b82795b11","modified":1482402838946},{"_id":"source/_posts/MergeSort.md","hash":"3a440ca8eae819d3e0c2fa029c76c1036847b4f8","modified":1481520210960},{"_id":"source/_posts/Save-DataFrame-into-a-partitioned-table-of-HIVE.md","hash":"54f114ba67f0ea47b72959f41c55fdef5de04159","modified":1481520210960},{"_id":"source/_posts/SPARK的宽依赖和窄依赖.md","hash":"da04cdbee0077f1b25eb1e77b131217699fdfe9c","modified":1481520210960},{"_id":"source/_posts/Scala-call-by-name-call-by-value.md","hash":"d8a538cd503a63d355f028732c416d4b2597a1cd","modified":1481520210960},{"_id":"source/_posts/ScalaList.md","hash":"4a8ffa182ebd9d273725df66703c72691fa8548e","modified":1481520210960},{"_id":"source/_posts/Spark-Window-Operation.md","hash":"f5f0f9899beecb5af0d32cd9df18ce5492c5be53","modified":1481520210960},{"_id":"source/_posts/Spark-2-0-Introduction.md","hash":"5f589230c88480a8d1e62521245a34d64e1e0718","modified":1481520210960},{"_id":"source/_posts/SparkPassFunctions.md","hash":"1c56f7acd3f216656f18efeb382ed5e6806459e6","modified":1481520210960},{"_id":"source/_posts/SparkStreamLearning.md","hash":"85b2e607dcd7e5a68bc4a360b82a4dc2bea75448","modified":1481520210960},{"_id":"source/_posts/Spark-Streaming-Programming-Guide.md","hash":"b5ff5ee9ff5c31bc7b11ec0aac82c61cd316d899","modified":1482402838946},{"_id":"source/_posts/install-tensorflow.md","hash":"534ca8c160579cc321b6eaa5de7240ff4d5d41dc","modified":1483769231867},{"_id":"source/_posts/save-spark-rdd-into-Mysql.md","hash":"4248aa52a30b556faca7952f6a42c88e8219fa44","modified":1481520210960},{"_id":"source/_posts/vim使用技巧.md","hash":"34ff36a68dd554c4a5b84403214440c9c1bae678","modified":1483769231867},{"_id":"source/_posts/机器学习相关材料.md","hash":"f54bc4b09c16ed132a69f01e6d227c303245f79b","modified":1481520210960},{"_id":"source/_posts/过拟合的原因.md","hash":"f154fcc55c1dac71fcb4171a1580de16f04d66dd","modified":1481520210961},{"_id":"source/_posts/SparkDataFrameLikeSql.md","hash":"f3ebad25b94bfb4272b73422365ee6c032fa636d","modified":1482402838946},{"_id":"source/_posts/UVa1225.md","hash":"1089f1871b81f70e271e857b6dd4ccabd9b06912","modified":1482402838946},{"_id":"source/_posts/UVa455.md","hash":"36a953b06513e2118a111eafef9f0b76000f874e","modified":1482402838946},{"_id":"source/about/index.md","hash":"274761ca34e4ac68dec3aaeb5a9b1fe27f064641","modified":1482402838946},{"_id":"source/categories/index.md","hash":"415d779cf75f2d2692c951ed2e4fd8f590545bc7","modified":1481520210961},{"_id":"source/tags/index.md","hash":"23708c34e5f98b7abe4c047bc98182dcb322007b","modified":1481520210961},{"_id":"public/atom.xml","hash":"01f76d42d2ba99b645c1a337205d24f7023192dd","modified":1483769539369},{"_id":"public/search.xml","hash":"41efb003e0ff706670f88269f70b2a27a8491c83","modified":1483769539369},{"_id":"public/about/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539387},{"_id":"public/categories/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539387},{"_id":"public/tags/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539387},{"_id":"public/2017/01/04/Deep-MNIST-for-Experts/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539387},{"_id":"public/2017/01/04/Google-面试宝典/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539388},{"_id":"public/2016/12/28/install-tensorflow/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539388},{"_id":"public/2016/12/22/vim使用技巧/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539388},{"_id":"public/2016/12/21/UVa455/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539389},{"_id":"public/2016/12/21/UVa1225/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539393},{"_id":"public/2016/12/21/3-2UVa1586/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539393},{"_id":"public/2016/12/15/Spark-Streaming-Programming-Guide/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539393},{"_id":"public/2016/12/09/17年要读的书和学习的技能/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539393},{"_id":"public/2016/12/09/SparkDataFrameLikeSql/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539393},{"_id":"public/2016/12/05/save-spark-rdd-into-Mysql/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539394},{"_id":"public/2016/11/28/SparkStreamLearning/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539394},{"_id":"public/2016/11/10/MAC访问你DOCKER容器中的WEB页面/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539394},{"_id":"public/2016/11/09/Install-Caffe-on-CentOS/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539394},{"_id":"public/2016/08/22/Spark-Window-Operation/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539394},{"_id":"public/2016/08/19/Spark-2-0-Introduction/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539394},{"_id":"public/2016/08/19/Save-DataFrame-into-a-partitioned-table-of-HIVE/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539394},{"_id":"public/2016/08/11/SparkPassFunctions/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539394},{"_id":"public/2016/07/26/MergeSort/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539395},{"_id":"public/2016/07/26/ScalaList/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539395},{"_id":"public/2016/07/19/Scala-call-by-name-call-by-value/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539395},{"_id":"public/2016/07/13/机器学习相关材料/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539395},{"_id":"public/2016/07/13/过拟合的原因/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539395},{"_id":"public/2016/04/25/SPARK的宽依赖和窄依赖/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539395},{"_id":"public/2016/04/21/1-100素数判断pyhon程序/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539395},{"_id":"public/archives/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539396},{"_id":"public/archives/page/2/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539396},{"_id":"public/archives/page/3/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539396},{"_id":"public/archives/2016/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539396},{"_id":"public/archives/2016/page/2/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539396},{"_id":"public/archives/2016/page/3/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539396},{"_id":"public/archives/2016/04/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539396},{"_id":"public/archives/2016/07/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539396},{"_id":"public/archives/2016/08/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539397},{"_id":"public/archives/2016/11/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539397},{"_id":"public/archives/2016/12/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539397},{"_id":"public/archives/2017/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539397},{"_id":"public/archives/2017/01/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539397},{"_id":"public/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539397},{"_id":"public/page/2/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539397},{"_id":"public/page/3/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539397},{"_id":"public/tags/tensorflow/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539398},{"_id":"public/tags/基础/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539398},{"_id":"public/tags/Python/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539398},{"_id":"public/tags/竞赛/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539398},{"_id":"public/tags/Scala/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539398},{"_id":"public/tags/Spark/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539398},{"_id":"public/tags/Spark-Scala-Streaming/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539398},{"_id":"public/tags/Spark-Streaming/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539398},{"_id":"public/tags/VIM/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539399},{"_id":"public/tags/Spark-DataFrame/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539399},{"_id":"public/2017/01/07/LearningFlink/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539404},{"_id":"public/tags/Flink/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1483769539404}],"Category":[],"Data":[],"Page":[{"title":"about","date":"2016-04-15T17:07:00.000Z","_content":"北冥有鱼，其名为鲲。鲲之大，不知其几千里也；化而为鸟，其名为鹏。鹏之背，不知其几千里也；怒而飞，其翼若垂天之云\n\n\n\n大神博客\n[星爷的博客](http://lxwei.github.io/)\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2016-04-16 01:07:00\n---\n北冥有鱼，其名为鲲。鲲之大，不知其几千里也；化而为鸟，其名为鹏。鹏之背，不知其几千里也；怒而飞，其翼若垂天之云\n\n\n\n大神博客\n[星爷的博客](http://lxwei.github.io/)\n","updated":"2016-12-22T10:33:58.946Z","path":"about/index.html","comments":1,"layout":"page","_id":"cixmu2nbl001pyeg3nmbxtexs","content":"<p>北冥有鱼，其名为鲲。鲲之大，不知其几千里也；化而为鸟，其名为鹏。鹏之背，不知其几千里也；怒而飞，其翼若垂天之云</p>\n<p>大神博客<br><a href=\"http://lxwei.github.io/\" target=\"_blank\" rel=\"external\">星爷的博客</a></p>\n","excerpt":"","more":"<p>北冥有鱼，其名为鲲。鲲之大，不知其几千里也；化而为鸟，其名为鹏。鹏之背，不知其几千里也；怒而飞，其翼若垂天之云</p>\n<p>大神博客<br><a href=\"http://lxwei.github.io/\">星爷的博客</a></p>\n"},{"title":"categories","date":"2016-04-15T18:21:49.000Z","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2016-04-16 02:21:49\nlayout: categories\n---\n","updated":"2016-12-12T05:23:30.961Z","path":"categories/index.html","comments":1,"_id":"cixmu2nbo001qyeg3390s33fc","content":"","excerpt":"","more":""},{"title":"tags","layout":"tags","_content":"```\nhello world\n```\n\n\n{% blockquote %}\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem.\n{% endblockquote %}\n","source":"tags/index.md","raw":"---\ntitle: tags\nlayout: tags\n---\n```\nhello world\n```\n\n\n{% blockquote %}\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem.\n{% endblockquote %}\n","date":"2016-12-12T05:23:30.961Z","updated":"2016-12-12T05:23:30.961Z","path":"tags/index.html","comments":1,"_id":"cixmu2nbp001ryeg310jtfrly","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hello world</span><br></pre></td></tr></table></figure>\n<blockquote><p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem.</p>\n</blockquote>\n","excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hello world</span><br></pre></td></tr></table></figure>\n<blockquote><p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem.</p>\n</blockquote>\n"}],"Post":[{"title":"Deep MNIST for Experts","date":"2017-01-04T15:30:16.000Z","_content":"\n\n```\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\nimport tensorflow as tf\nsess = tf.InteractiveSession()\n\n\n#None 表示这里可能存在很多个样本, 784=28*28表示共有784个像素点\n#y_表示与x对应的label, 由于采用的是one_hot编码的所以是10维\nx = tf.placeholder(tf.float32, shape=[None, 784])\ny_ = tf.placeholder(tf.float32, shape=[None, 10])\n\n\nW = tf.Variable(tf.zeros([784,10]))\nb = tf.Variable(tf.zeros([10]))\n\n\nsess.run(tf.global_variables_initializer())\n# 假设 有X个样本，那么 (X*784) * (784*10) = (X*10) \ny = tf.matmul(x,W) + b\n\n\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n\n```\n","source":"_posts/Deep-MNIST-for-Experts.md","raw":"---\ntitle: Deep MNIST for Experts\ndate: 2017-01-04 23:30:16\ntags: tensorflow\n---\n\n\n```\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\nimport tensorflow as tf\nsess = tf.InteractiveSession()\n\n\n#None 表示这里可能存在很多个样本, 784=28*28表示共有784个像素点\n#y_表示与x对应的label, 由于采用的是one_hot编码的所以是10维\nx = tf.placeholder(tf.float32, shape=[None, 784])\ny_ = tf.placeholder(tf.float32, shape=[None, 10])\n\n\nW = tf.Variable(tf.zeros([784,10]))\nb = tf.Variable(tf.zeros([10]))\n\n\nsess.run(tf.global_variables_initializer())\n# 假设 有X个样本，那么 (X*784) * (784*10) = (X*10) \ny = tf.matmul(x,W) + b\n\n\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n\n```\n","slug":"Deep-MNIST-for-Experts","published":1,"updated":"2017-01-07T06:07:11.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n7k0000yeg374yhsj2o","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class=\"line\">mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)</span><br><span class=\"line\"></span><br><span class=\"line\">import tensorflow as tf</span><br><span class=\"line\">sess = tf.InteractiveSession()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#None 表示这里可能存在很多个样本, 784=28*28表示共有784个像素点</span><br><span class=\"line\">#y_表示与x对应的label, 由于采用的是one_hot编码的所以是10维</span><br><span class=\"line\">x = tf.placeholder(tf.float32, shape=[None, 784])</span><br><span class=\"line\">y_ = tf.placeholder(tf.float32, shape=[None, 10])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">W = tf.Variable(tf.zeros([784,10]))</span><br><span class=\"line\">b = tf.Variable(tf.zeros([10]))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">sess.run(tf.global_variables_initializer())</span><br><span class=\"line\"># 假设 有X个样本，那么 (X*784) * (784*10) = (X*10) </span><br><span class=\"line\">y = tf.matmul(x,W) + b</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))</span><br></pre></td></tr></table></figure>\n","excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class=\"line\">mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)</span><br><span class=\"line\"></span><br><span class=\"line\">import tensorflow as tf</span><br><span class=\"line\">sess = tf.InteractiveSession()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#None 表示这里可能存在很多个样本, 784=28*28表示共有784个像素点</span><br><span class=\"line\">#y_表示与x对应的label, 由于采用的是one_hot编码的所以是10维</span><br><span class=\"line\">x = tf.placeholder(tf.float32, shape=[None, 784])</span><br><span class=\"line\">y_ = tf.placeholder(tf.float32, shape=[None, 10])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">W = tf.Variable(tf.zeros([784,10]))</span><br><span class=\"line\">b = tf.Variable(tf.zeros([10]))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">sess.run(tf.global_variables_initializer())</span><br><span class=\"line\"># 假设 有X个样本，那么 (X*784) * (784*10) = (X*10) </span><br><span class=\"line\">y = tf.matmul(x,W) + b</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))</span><br></pre></td></tr></table></figure>\n"},{"title":"Google 面试宝典","date":"2017-01-04T11:13:16.000Z","_content":"\ngeek.csdn.net/news/detail/107064\n","source":"_posts/Google-面试宝典.md","raw":"---\ntitle: Google 面试宝典\ndate: 2017-01-04 19:13:16\ntags: 基础\n---\n\ngeek.csdn.net/news/detail/107064\n","slug":"Google-面试宝典","published":1,"updated":"2017-01-07T06:07:11.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n7t0001yeg3h6pkhv0y","content":"<p>geek.csdn.net/news/detail/107064</p>\n","excerpt":"","more":"<p>geek.csdn.net/news/detail/107064</p>\n"},{"title":"Install Caffe on CentOS","date":"2016-11-09T08:07:49.000Z","_content":"尽量不要在CentOS平台上安装Caffe\n","source":"_posts/Install-Caffe-on-CentOS.md","raw":"---\ntitle: Install Caffe on CentOS\ndate: 2016-11-09 16:07:49\ntags:\n---\n尽量不要在CentOS平台上安装Caffe\n","slug":"Install-Caffe-on-CentOS","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n820003yeg38qo2osfo","content":"<p>尽量不要在CentOS平台上安装Caffe</p>\n","excerpt":"","more":"<p>尽量不要在CentOS平台上安装Caffe</p>\n"},{"title":"LearningFlink","date":"2017-01-07T06:07:30.000Z","_content":"\n\nFlink 处理有界和无界数据源需要采用不同的Api, 对应关系见下表格\n|DataSource      |ApiType        |\n|-------------|-------------|\n|bounded source|DataSet Api|\n|unbounded source|DataStream Api|\n\n\n\n","source":"_posts/LearningFlink.md","raw":"---\ntitle: LearningFlink\ndate: 2017-01-07 14:07:30\ntags: Flink\n---\n\n\nFlink 处理有界和无界数据源需要采用不同的Api, 对应关系见下表格\n|DataSource      |ApiType        |\n|-------------|-------------|\n|bounded source|DataSet Api|\n|unbounded source|DataStream Api|\n\n\n\n","slug":"LearningFlink","published":1,"updated":"2017-01-07T06:12:11.669Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n840004yeg3i072nyhd","content":"<p>Flink 处理有界和无界数据源需要采用不同的Api, 对应关系见下表格<br>|DataSource      |ApiType        |<br>|————-|————-|<br>|bounded source|DataSet Api|<br>|unbounded source|DataStream Api|</p>\n","excerpt":"","more":"<p>Flink 处理有界和无界数据源需要采用不同的Api, 对应关系见下表格<br>|DataSource      |ApiType        |<br>|————-|————-|<br>|bounded source|DataSet Api|<br>|unbounded source|DataStream Api|</p>\n"},{"title":"MAC访问你DOCKER容器中的WEB页面","date":"2016-11-10T15:22:16.000Z","_content":"\n\n\ndocker run -d -p hostport:dockerport --name your_container_name  your_image_name nginx -g \"daemon off;\"\n\n\nthe above instruction start a docker nginx application which bind is port dockerport to its host port hostport.\nusually you can access the nginx service on your host environment by curl the hostport, however in MacOs, ths hostport here \nis the virtual machine. so when you curl localhost:hostport, you will get no response.\n\n\nthe right way is access the virtual machine responding port. so the ip of virtual machine is needed.\n\n```\n    docker-machine ip your_virtual_machine \n```\n\n\n```\n    curl the ip you get:hostport\n```\n\n\n\n\n\n\n","source":"_posts/MAC访问你DOCKER容器中的WEB页面.md","raw":"---\ntitle: MAC访问你DOCKER容器中的WEB页面\ndate: 2016-11-10 23:22:16\ntags:\n---\n\n\n\ndocker run -d -p hostport:dockerport --name your_container_name  your_image_name nginx -g \"daemon off;\"\n\n\nthe above instruction start a docker nginx application which bind is port dockerport to its host port hostport.\nusually you can access the nginx service on your host environment by curl the hostport, however in MacOs, ths hostport here \nis the virtual machine. so when you curl localhost:hostport, you will get no response.\n\n\nthe right way is access the virtual machine responding port. so the ip of virtual machine is needed.\n\n```\n    docker-machine ip your_virtual_machine \n```\n\n\n```\n    curl the ip you get:hostport\n```\n\n\n\n\n\n\n","slug":"MAC访问你DOCKER容器中的WEB页面","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n8c0006yeg3ei23zuv1","content":"<p>docker run -d -p hostport:dockerport –name your_container_name  your_image_name nginx -g “daemon off;”</p>\n<p>the above instruction start a docker nginx application which bind is port dockerport to its host port hostport.<br>usually you can access the nginx service on your host environment by curl the hostport, however in MacOs, ths hostport here<br>is the virtual machine. so when you curl localhost:hostport, you will get no response.</p>\n<p>the right way is access the virtual machine responding port. so the ip of virtual machine is needed.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker-machine ip your_virtual_machine</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl the ip you get:hostport</span><br></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>docker run -d -p hostport:dockerport –name your_container_name  your_image_name nginx -g “daemon off;”</p>\n<p>the above instruction start a docker nginx application which bind is port dockerport to its host port hostport.<br>usually you can access the nginx service on your host environment by curl the hostport, however in MacOs, ths hostport here<br>is the virtual machine. so when you curl localhost:hostport, you will get no response.</p>\n<p>the right way is access the virtual machine responding port. so the ip of virtual machine is needed.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker-machine ip your_virtual_machine</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl the ip you get:hostport</span><br></pre></td></tr></table></figure>\n"},{"title":"17年要读的书和学习的技能","date":"2016-12-09T10:14:36.000Z","_content":"# 17年要读的书\n\n|书籍名称|目的        |\n|-------------|-------------|\n|算法艺术与信息学竞赛:算法竞赛入门经典(第2版) |提升算法水平，强化C／C++|\n|算法竞赛入门经典:训练指南 |提高算法，训练思维|\n|自己动手写Java虚拟机 |了解JAVA虚拟机原理，提升Golang编程水平|\n|响应式架构:消息模式Actor实现与Scala、Akka应用集成|学习并发编程、提升Scala编程水平|\n|[深度学习中文版](https://github.com/exacity/deeplearningbook-chinese)|学习深度学习，为该项目贡献代码|\n|分布式实时处理系统：原理、架构与实现 |深入理解分布式程序开发，提升C／C++实战能力|\n|深度学习：21天实战Caffe|实战深度学习，提升C／C++编程水平|\n\n# 17年要学习的技能\n机器学习方向\n-   DecisionTree\n-   XgBoost\n-   SVM \n-   AdaBoost\n-   PCA\n-   LogisticRegresion\n\nScala\n-   Akka\n-   Actor\n\nJAVA\n-   Spring SpringMVC MyBatis\n-   SpringBoot\n\nGolang\n-   Beego\n-   channel基础\n\n数学基础\n-   线性代数\n-   概率论\n\nSpark\n- Spark mlib\n- streaming(redis/kafka/akka/hbase)\n- structure streaming\n- basic rdd\n","source":"_posts/17年要读的书和学习的技能.md","raw":"---\ntitle: 17年要读的书和学习的技能\ndate: 2016-12-09 18:14:36\ntags:\n---\n# 17年要读的书\n\n|书籍名称|目的        |\n|-------------|-------------|\n|算法艺术与信息学竞赛:算法竞赛入门经典(第2版) |提升算法水平，强化C／C++|\n|算法竞赛入门经典:训练指南 |提高算法，训练思维|\n|自己动手写Java虚拟机 |了解JAVA虚拟机原理，提升Golang编程水平|\n|响应式架构:消息模式Actor实现与Scala、Akka应用集成|学习并发编程、提升Scala编程水平|\n|[深度学习中文版](https://github.com/exacity/deeplearningbook-chinese)|学习深度学习，为该项目贡献代码|\n|分布式实时处理系统：原理、架构与实现 |深入理解分布式程序开发，提升C／C++实战能力|\n|深度学习：21天实战Caffe|实战深度学习，提升C／C++编程水平|\n\n# 17年要学习的技能\n机器学习方向\n-   DecisionTree\n-   XgBoost\n-   SVM \n-   AdaBoost\n-   PCA\n-   LogisticRegresion\n\nScala\n-   Akka\n-   Actor\n\nJAVA\n-   Spring SpringMVC MyBatis\n-   SpringBoot\n\nGolang\n-   Beego\n-   channel基础\n\n数学基础\n-   线性代数\n-   概率论\n\nSpark\n- Spark mlib\n- streaming(redis/kafka/akka/hbase)\n- structure streaming\n- basic rdd\n","slug":"17年要读的书和学习的技能","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n8f0008yeg3la1fbc6f","content":"<h1 id=\"17年要读的书\"><a href=\"#17年要读的书\" class=\"headerlink\" title=\"17年要读的书\"></a>17年要读的书</h1><table>\n<thead>\n<tr>\n<th>书籍名称</th>\n<th>目的</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>算法艺术与信息学竞赛:算法竞赛入门经典(第2版)</td>\n<td>提升算法水平，强化C／C++</td>\n</tr>\n<tr>\n<td>算法竞赛入门经典:训练指南</td>\n<td>提高算法，训练思维</td>\n</tr>\n<tr>\n<td>自己动手写Java虚拟机</td>\n<td>了解JAVA虚拟机原理，提升Golang编程水平</td>\n</tr>\n<tr>\n<td>响应式架构:消息模式Actor实现与Scala、Akka应用集成</td>\n<td>学习并发编程、提升Scala编程水平</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/exacity/deeplearningbook-chinese\" target=\"_blank\" rel=\"external\">深度学习中文版</a></td>\n<td>学习深度学习，为该项目贡献代码</td>\n</tr>\n<tr>\n<td>分布式实时处理系统：原理、架构与实现</td>\n<td>深入理解分布式程序开发，提升C／C++实战能力</td>\n</tr>\n<tr>\n<td>深度学习：21天实战Caffe</td>\n<td>实战深度学习，提升C／C++编程水平</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"17年要学习的技能\"><a href=\"#17年要学习的技能\" class=\"headerlink\" title=\"17年要学习的技能\"></a>17年要学习的技能</h1><p>机器学习方向</p>\n<ul>\n<li>DecisionTree</li>\n<li>XgBoost</li>\n<li>SVM </li>\n<li>AdaBoost</li>\n<li>PCA</li>\n<li>LogisticRegresion</li>\n</ul>\n<p>Scala</p>\n<ul>\n<li>Akka</li>\n<li>Actor</li>\n</ul>\n<p>JAVA</p>\n<ul>\n<li>Spring SpringMVC MyBatis</li>\n<li>SpringBoot</li>\n</ul>\n<p>Golang</p>\n<ul>\n<li>Beego</li>\n<li>channel基础</li>\n</ul>\n<p>数学基础</p>\n<ul>\n<li>线性代数</li>\n<li>概率论</li>\n</ul>\n<p>Spark</p>\n<ul>\n<li>Spark mlib</li>\n<li>streaming(redis/kafka/akka/hbase)</li>\n<li>structure streaming</li>\n<li>basic rdd</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"17年要读的书\"><a href=\"#17年要读的书\" class=\"headerlink\" title=\"17年要读的书\"></a>17年要读的书</h1><table>\n<thead>\n<tr>\n<th>书籍名称</th>\n<th>目的</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>算法艺术与信息学竞赛:算法竞赛入门经典(第2版)</td>\n<td>提升算法水平，强化C／C++</td>\n</tr>\n<tr>\n<td>算法竞赛入门经典:训练指南</td>\n<td>提高算法，训练思维</td>\n</tr>\n<tr>\n<td>自己动手写Java虚拟机</td>\n<td>了解JAVA虚拟机原理，提升Golang编程水平</td>\n</tr>\n<tr>\n<td>响应式架构:消息模式Actor实现与Scala、Akka应用集成</td>\n<td>学习并发编程、提升Scala编程水平</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/exacity/deeplearningbook-chinese\">深度学习中文版</a></td>\n<td>学习深度学习，为该项目贡献代码</td>\n</tr>\n<tr>\n<td>分布式实时处理系统：原理、架构与实现</td>\n<td>深入理解分布式程序开发，提升C／C++实战能力</td>\n</tr>\n<tr>\n<td>深度学习：21天实战Caffe</td>\n<td>实战深度学习，提升C／C++编程水平</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"17年要学习的技能\"><a href=\"#17年要学习的技能\" class=\"headerlink\" title=\"17年要学习的技能\"></a>17年要学习的技能</h1><p>机器学习方向</p>\n<ul>\n<li>DecisionTree</li>\n<li>XgBoost</li>\n<li>SVM </li>\n<li>AdaBoost</li>\n<li>PCA</li>\n<li>LogisticRegresion</li>\n</ul>\n<p>Scala</p>\n<ul>\n<li>Akka</li>\n<li>Actor</li>\n</ul>\n<p>JAVA</p>\n<ul>\n<li>Spring SpringMVC MyBatis</li>\n<li>SpringBoot</li>\n</ul>\n<p>Golang</p>\n<ul>\n<li>Beego</li>\n<li>channel基础</li>\n</ul>\n<p>数学基础</p>\n<ul>\n<li>线性代数</li>\n<li>概率论</li>\n</ul>\n<p>Spark</p>\n<ul>\n<li>Spark mlib</li>\n<li>streaming(redis/kafka/akka/hbase)</li>\n<li>structure streaming</li>\n<li>basic rdd</li>\n</ul>\n"},{"title":"1-100素数判断pyhon程序","date":"2016-04-21T10:08:04.000Z","_content":"\n\n求取1-100的所有素数，采用函数式编程\n```python\ndef issu(x):\n    result=map(lambda y:x%y,range(2,x))\n    if  len(result)!=0 and 0 not in result:\n        return 1\n    else:\n        return 0\n\n\nprint filter(issu,range(1,101))\n\n```\n答案为\n**[3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]**\n","source":"_posts/1-100素数判断pyhon程序.md","raw":"---\ntitle: 1-100素数判断pyhon程序\ndate: 2016-04-21 18:08:04\ntags: Python\n---\n\n\n求取1-100的所有素数，采用函数式编程\n```python\ndef issu(x):\n    result=map(lambda y:x%y,range(2,x))\n    if  len(result)!=0 and 0 not in result:\n        return 1\n    else:\n        return 0\n\n\nprint filter(issu,range(1,101))\n\n```\n答案为\n**[3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]**\n","slug":"1-100素数判断pyhon程序","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n8k0009yeg3k0stsdwv","content":"<p>求取1-100的所有素数，采用函数式编程<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">issu</span><span class=\"params\">(x)</span>:</span></span><br><span class=\"line\">    result=map(<span class=\"keyword\">lambda</span> y:x%y,range(<span class=\"number\">2</span>,x))</span><br><span class=\"line\">    <span class=\"keyword\">if</span>  len(result)!=<span class=\"number\">0</span> <span class=\"keyword\">and</span> <span class=\"number\">0</span> <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> result:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> filter(issu,range(<span class=\"number\">1</span>,<span class=\"number\">101</span>))</span><br></pre></td></tr></table></figure></p>\n<p>答案为<br><strong>[3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]</strong></p>\n","excerpt":"","more":"<p>求取1-100的所有素数，采用函数式编程<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">issu</span><span class=\"params\">(x)</span>:</span></span><br><span class=\"line\">    result=map(<span class=\"keyword\">lambda</span> y:x%y,range(<span class=\"number\">2</span>,x))</span><br><span class=\"line\">    <span class=\"keyword\">if</span>  len(result)!=<span class=\"number\">0</span> <span class=\"keyword\">and</span> <span class=\"number\">0</span> <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> result:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> filter(issu,range(<span class=\"number\">1</span>,<span class=\"number\">101</span>))</span><br></pre></td></tr></table></figure></p>\n<p>答案为<br><strong>[3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]</strong></p>\n"},{"title":"3_2UVa1586","date":"2016-12-20T16:11:06.000Z","_content":"# Molar Mass ACM/ICPC sroul 2007, UVa1586\n```\n#include <stdlib.h>\n#include <stdio.h>\n#include <strings.h>\n#include <ctype.h>\n\n/* \n * ===  FUNCTION  ======================================================================\n *         Name:  main\n *  Description:  \n * =====================================================================================\n */\n\n/* \n * ===  FUNCTION  ======================================================================\n *         Name:  get_g\n *  Description:  \n * =====================================================================================\n */\nfloat get_g ( char a )\n{\n    switch(a){\n        case 'C':\n            return 12.01;\n            break;\n        case 'H':\n            return 1.008;\n            break;\n        case 'O':\n            return 16.00;\n            break;\n        case 'N':\n            return 14.01;\n            break;\n        default:\n            return -1.0;\n    }\n}\t\t\nint main ( int argc, char *argv[] ) {\n    char buf[101]={}; \n    int flag = 0;\n    float sum = 0.0;\n    int i = 0 ;\n    int j = 0;\n    int count = 0;\n\n    while( (scanf(\"%s\", buf)!=EOF) ){\n        flag = 0;\n        for (i = 0; buf[i]!='\\0'; i++) {\n            count = 0;\n            for( j=i+1;isdigit(buf[j])&&buf[j];j++ ){\n                count = count * 10 + (buf[j]-'0');\n            }\n            if (count==0) {\n                count=1;\n            }\n            if (buf[i]!='C'\n                    && buf[i]!='N'\n                    && buf[i]!='O'\n                    && buf[i]!='H'\n                    ) {\n                flag = 1;\n            }\n            sum += count * get_g(buf[i]);\n            i=j-1;\n        }\n        if (!flag){\n            printf ( \"sum is %f\\n\",sum );\n        }else{\n//            printf ( \"input error\\n\" );\n        }\n    }\n    return EXIT_SUCCESS;\n}\t\t\t\t/* ----------  end of function main  ---------- */\n```\n","source":"_posts/3-2UVa1586.md","raw":"---\ntitle: 3_2UVa1586\ndate: 2016-12-21 00:11:06\ntags: 竞赛\n---\n# Molar Mass ACM/ICPC sroul 2007, UVa1586\n```\n#include <stdlib.h>\n#include <stdio.h>\n#include <strings.h>\n#include <ctype.h>\n\n/* \n * ===  FUNCTION  ======================================================================\n *         Name:  main\n *  Description:  \n * =====================================================================================\n */\n\n/* \n * ===  FUNCTION  ======================================================================\n *         Name:  get_g\n *  Description:  \n * =====================================================================================\n */\nfloat get_g ( char a )\n{\n    switch(a){\n        case 'C':\n            return 12.01;\n            break;\n        case 'H':\n            return 1.008;\n            break;\n        case 'O':\n            return 16.00;\n            break;\n        case 'N':\n            return 14.01;\n            break;\n        default:\n            return -1.0;\n    }\n}\t\t\nint main ( int argc, char *argv[] ) {\n    char buf[101]={}; \n    int flag = 0;\n    float sum = 0.0;\n    int i = 0 ;\n    int j = 0;\n    int count = 0;\n\n    while( (scanf(\"%s\", buf)!=EOF) ){\n        flag = 0;\n        for (i = 0; buf[i]!='\\0'; i++) {\n            count = 0;\n            for( j=i+1;isdigit(buf[j])&&buf[j];j++ ){\n                count = count * 10 + (buf[j]-'0');\n            }\n            if (count==0) {\n                count=1;\n            }\n            if (buf[i]!='C'\n                    && buf[i]!='N'\n                    && buf[i]!='O'\n                    && buf[i]!='H'\n                    ) {\n                flag = 1;\n            }\n            sum += count * get_g(buf[i]);\n            i=j-1;\n        }\n        if (!flag){\n            printf ( \"sum is %f\\n\",sum );\n        }else{\n//            printf ( \"input error\\n\" );\n        }\n    }\n    return EXIT_SUCCESS;\n}\t\t\t\t/* ----------  end of function main  ---------- */\n```\n","slug":"3-2UVa1586","published":1,"updated":"2016-12-22T10:33:58.946Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n8u000cyeg3l66tpmma","content":"<h1 id=\"Molar-Mass-ACM-ICPC-sroul-2007-UVa1586\"><a href=\"#Molar-Mass-ACM-ICPC-sroul-2007-UVa1586\" class=\"headerlink\" title=\"Molar Mass ACM/ICPC sroul 2007, UVa1586\"></a>Molar Mass ACM/ICPC sroul 2007, UVa1586</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;strings.h&gt;</span><br><span class=\"line\">#include &lt;ctype.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">/* </span><br><span class=\"line\"> * ===  FUNCTION  ======================================================================</span><br><span class=\"line\"> *         Name:  main</span><br><span class=\"line\"> *  Description:  </span><br><span class=\"line\"> * =====================================================================================</span><br><span class=\"line\"> */</span><br><span class=\"line\"></span><br><span class=\"line\">/* </span><br><span class=\"line\"> * ===  FUNCTION  ======================================================================</span><br><span class=\"line\"> *         Name:  get_g</span><br><span class=\"line\"> *  Description:  </span><br><span class=\"line\"> * =====================================================================================</span><br><span class=\"line\"> */</span><br><span class=\"line\">float get_g ( char a )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    switch(a)&#123;</span><br><span class=\"line\">        case &apos;C&apos;:</span><br><span class=\"line\">            return 12.01;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        case &apos;H&apos;:</span><br><span class=\"line\">            return 1.008;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        case &apos;O&apos;:</span><br><span class=\"line\">            return 16.00;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        case &apos;N&apos;:</span><br><span class=\"line\">            return 14.01;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        default:</span><br><span class=\"line\">            return -1.0;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;\t\t</span><br><span class=\"line\">int main ( int argc, char *argv[] ) &#123;</span><br><span class=\"line\">    char buf[101]=&#123;&#125;; </span><br><span class=\"line\">    int flag = 0;</span><br><span class=\"line\">    float sum = 0.0;</span><br><span class=\"line\">    int i = 0 ;</span><br><span class=\"line\">    int j = 0;</span><br><span class=\"line\">    int count = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">    while( (scanf(&quot;%s&quot;, buf)!=EOF) )&#123;</span><br><span class=\"line\">        flag = 0;</span><br><span class=\"line\">        for (i = 0; buf[i]!=&apos;\\0&apos;; i++) &#123;</span><br><span class=\"line\">            count = 0;</span><br><span class=\"line\">            for( j=i+1;isdigit(buf[j])&amp;&amp;buf[j];j++ )&#123;</span><br><span class=\"line\">                count = count * 10 + (buf[j]-&apos;0&apos;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (count==0) &#123;</span><br><span class=\"line\">                count=1;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (buf[i]!=&apos;C&apos;</span><br><span class=\"line\">                    &amp;&amp; buf[i]!=&apos;N&apos;</span><br><span class=\"line\">                    &amp;&amp; buf[i]!=&apos;O&apos;</span><br><span class=\"line\">                    &amp;&amp; buf[i]!=&apos;H&apos;</span><br><span class=\"line\">                    ) &#123;</span><br><span class=\"line\">                flag = 1;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            sum += count * get_g(buf[i]);</span><br><span class=\"line\">            i=j-1;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (!flag)&#123;</span><br><span class=\"line\">            printf ( &quot;sum is %f\\n&quot;,sum );</span><br><span class=\"line\">        &#125;else&#123;</span><br><span class=\"line\">//            printf ( &quot;input error\\n&quot; );</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return EXIT_SUCCESS;</span><br><span class=\"line\">&#125;\t\t\t\t/* ----------  end of function main  ---------- */</span><br></pre></td></tr></table></figure>\n","excerpt":"","more":"<h1 id=\"Molar-Mass-ACM-ICPC-sroul-2007-UVa1586\"><a href=\"#Molar-Mass-ACM-ICPC-sroul-2007-UVa1586\" class=\"headerlink\" title=\"Molar Mass ACM/ICPC sroul 2007, UVa1586\"></a>Molar Mass ACM/ICPC sroul 2007, UVa1586</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;strings.h&gt;</span><br><span class=\"line\">#include &lt;ctype.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">/* </span><br><span class=\"line\"> * ===  FUNCTION  ======================================================================</span><br><span class=\"line\"> *         Name:  main</span><br><span class=\"line\"> *  Description:  </span><br><span class=\"line\"> * =====================================================================================</span><br><span class=\"line\"> */</span><br><span class=\"line\"></span><br><span class=\"line\">/* </span><br><span class=\"line\"> * ===  FUNCTION  ======================================================================</span><br><span class=\"line\"> *         Name:  get_g</span><br><span class=\"line\"> *  Description:  </span><br><span class=\"line\"> * =====================================================================================</span><br><span class=\"line\"> */</span><br><span class=\"line\">float get_g ( char a )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    switch(a)&#123;</span><br><span class=\"line\">        case &apos;C&apos;:</span><br><span class=\"line\">            return 12.01;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        case &apos;H&apos;:</span><br><span class=\"line\">            return 1.008;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        case &apos;O&apos;:</span><br><span class=\"line\">            return 16.00;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        case &apos;N&apos;:</span><br><span class=\"line\">            return 14.01;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        default:</span><br><span class=\"line\">            return -1.0;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;\t\t</span><br><span class=\"line\">int main ( int argc, char *argv[] ) &#123;</span><br><span class=\"line\">    char buf[101]=&#123;&#125;; </span><br><span class=\"line\">    int flag = 0;</span><br><span class=\"line\">    float sum = 0.0;</span><br><span class=\"line\">    int i = 0 ;</span><br><span class=\"line\">    int j = 0;</span><br><span class=\"line\">    int count = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">    while( (scanf(&quot;%s&quot;, buf)!=EOF) )&#123;</span><br><span class=\"line\">        flag = 0;</span><br><span class=\"line\">        for (i = 0; buf[i]!=&apos;\\0&apos;; i++) &#123;</span><br><span class=\"line\">            count = 0;</span><br><span class=\"line\">            for( j=i+1;isdigit(buf[j])&amp;&amp;buf[j];j++ )&#123;</span><br><span class=\"line\">                count = count * 10 + (buf[j]-&apos;0&apos;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (count==0) &#123;</span><br><span class=\"line\">                count=1;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (buf[i]!=&apos;C&apos;</span><br><span class=\"line\">                    &amp;&amp; buf[i]!=&apos;N&apos;</span><br><span class=\"line\">                    &amp;&amp; buf[i]!=&apos;O&apos;</span><br><span class=\"line\">                    &amp;&amp; buf[i]!=&apos;H&apos;</span><br><span class=\"line\">                    ) &#123;</span><br><span class=\"line\">                flag = 1;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            sum += count * get_g(buf[i]);</span><br><span class=\"line\">            i=j-1;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (!flag)&#123;</span><br><span class=\"line\">            printf ( &quot;sum is %f\\n&quot;,sum );</span><br><span class=\"line\">        &#125;else&#123;</span><br><span class=\"line\">//            printf ( &quot;input error\\n&quot; );</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return EXIT_SUCCESS;</span><br><span class=\"line\">&#125;\t\t\t\t/* ----------  end of function main  ---------- */</span><br></pre></td></tr></table></figure>\n"},{"title":"MergeSort","date":"2016-07-26T12:30:03.000Z","_content":"归并排序\n\n```\ndef msort[A](less: (A, A) => Boolean)(xs: List[A]): List[A] = { \n    def merge(xs1: List[A], xs2: List[A]): List[A] =\n        if (xs1.isEmpty) xs2\n        else if (xs2.isEmpty) xs1\n        else if (less(xs1.head, xs2.head)) xs1.head :: merge(xs1.tail, xs2) else xs2.head :: merge(xs1, xs2.tail)\n    val n = xs.length/2\n    if (n == 0) xs\n    else merge(msort(less)(xs take n), msort(less)(xs drop n))\n}\n```\n\n如果你对python列表的用法比较熟悉的话，可以按照如下的方式理解\n\n```\n    xs take n   // xs[0:n+1]\n    xs drop n   // xs[n+1:]\n```\n\nmsort函数应该按照如下方式进行调用\n```\nmsort((x: Int, y: Int) => x < y)(List(5, 7, 1, 3))\n```\n","source":"_posts/MergeSort.md","raw":"---\ntitle: MergeSort\ndate: 2016-07-26 20:30:03\ntags: Scala\n---\n归并排序\n\n```\ndef msort[A](less: (A, A) => Boolean)(xs: List[A]): List[A] = { \n    def merge(xs1: List[A], xs2: List[A]): List[A] =\n        if (xs1.isEmpty) xs2\n        else if (xs2.isEmpty) xs1\n        else if (less(xs1.head, xs2.head)) xs1.head :: merge(xs1.tail, xs2) else xs2.head :: merge(xs1, xs2.tail)\n    val n = xs.length/2\n    if (n == 0) xs\n    else merge(msort(less)(xs take n), msort(less)(xs drop n))\n}\n```\n\n如果你对python列表的用法比较熟悉的话，可以按照如下的方式理解\n\n```\n    xs take n   // xs[0:n+1]\n    xs drop n   // xs[n+1:]\n```\n\nmsort函数应该按照如下方式进行调用\n```\nmsort((x: Int, y: Int) => x < y)(List(5, 7, 1, 3))\n```\n","slug":"MergeSort","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n8y000dyeg3f72cq8kn","content":"<p>归并排序</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def msort[A](less: (A, A) =&gt; Boolean)(xs: List[A]): List[A] = &#123; </span><br><span class=\"line\">    def merge(xs1: List[A], xs2: List[A]): List[A] =</span><br><span class=\"line\">        if (xs1.isEmpty) xs2</span><br><span class=\"line\">        else if (xs2.isEmpty) xs1</span><br><span class=\"line\">        else if (less(xs1.head, xs2.head)) xs1.head :: merge(xs1.tail, xs2) else xs2.head :: merge(xs1, xs2.tail)</span><br><span class=\"line\">    val n = xs.length/2</span><br><span class=\"line\">    if (n == 0) xs</span><br><span class=\"line\">    else merge(msort(less)(xs take n), msort(less)(xs drop n))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果你对python列表的用法比较熟悉的话，可以按照如下的方式理解</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xs take n   // xs[0:n+1]</span><br><span class=\"line\">xs drop n   // xs[n+1:]</span><br></pre></td></tr></table></figure>\n<p>msort函数应该按照如下方式进行调用<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">msort((x: Int, y: Int) =&gt; x &lt; y)(List(5, 7, 1, 3))</span><br></pre></td></tr></table></figure></p>\n","excerpt":"","more":"<p>归并排序</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def msort[A](less: (A, A) =&gt; Boolean)(xs: List[A]): List[A] = &#123; </span><br><span class=\"line\">    def merge(xs1: List[A], xs2: List[A]): List[A] =</span><br><span class=\"line\">        if (xs1.isEmpty) xs2</span><br><span class=\"line\">        else if (xs2.isEmpty) xs1</span><br><span class=\"line\">        else if (less(xs1.head, xs2.head)) xs1.head :: merge(xs1.tail, xs2) else xs2.head :: merge(xs1, xs2.tail)</span><br><span class=\"line\">    val n = xs.length/2</span><br><span class=\"line\">    if (n == 0) xs</span><br><span class=\"line\">    else merge(msort(less)(xs take n), msort(less)(xs drop n))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果你对python列表的用法比较熟悉的话，可以按照如下的方式理解</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xs take n   // xs[0:n+1]</span><br><span class=\"line\">xs drop n   // xs[n+1:]</span><br></pre></td></tr></table></figure>\n<p>msort函数应该按照如下方式进行调用<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">msort((x: Int, y: Int) =&gt; x &lt; y)(List(5, 7, 1, 3))</span><br></pre></td></tr></table></figure></p>\n"},{"title":"Save DataFrame into a partitioned table of HIVE","date":"2016-08-19T09:15:15.000Z","_content":"\n\n# How to save a spark DataFrame as a patitioned hive table #\n## utilise saveAsTable method ##\n\n```\n    val conf = new SparkConf().setAppName(\"Simple Application\").setMaster(\"local\")\n    val sc = new SparkContext(conf)\n    val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n    import sqlContext.implicits._\n    val hiveContext = new org.apache.spark.sql.hive.HiveContext(sc)\n    hiveContext.sql(\"use database\")\n\n    val cmd =\n      \"\"\"\n         select\n          col1,\n          col2\n         from\n          table\n      \"\"\".stripMargin\n    val yourDf = hiveContext.sql(cmd)\n    yourDf.printSchema()\n    yourDf.write.partitionBy(\"col2\").saveAsTable(\"partitionTableName\")\n```\n\n\n\n\n","source":"_posts/Save-DataFrame-into-a-partitioned-table-of-HIVE.md","raw":"---\ntitle: Save DataFrame into a partitioned table of HIVE\ndate: 2016-08-19 17:15:15\ntags: Spark\n---\n\n\n# How to save a spark DataFrame as a patitioned hive table #\n## utilise saveAsTable method ##\n\n```\n    val conf = new SparkConf().setAppName(\"Simple Application\").setMaster(\"local\")\n    val sc = new SparkContext(conf)\n    val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n    import sqlContext.implicits._\n    val hiveContext = new org.apache.spark.sql.hive.HiveContext(sc)\n    hiveContext.sql(\"use database\")\n\n    val cmd =\n      \"\"\"\n         select\n          col1,\n          col2\n         from\n          table\n      \"\"\".stripMargin\n    val yourDf = hiveContext.sql(cmd)\n    yourDf.printSchema()\n    yourDf.write.partitionBy(\"col2\").saveAsTable(\"partitionTableName\")\n```\n\n\n\n\n","slug":"Save-DataFrame-into-a-partitioned-table-of-HIVE","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n91000fyeg3m64wospz","content":"<h1 id=\"How-to-save-a-spark-DataFrame-as-a-patitioned-hive-table\"><a href=\"#How-to-save-a-spark-DataFrame-as-a-patitioned-hive-table\" class=\"headerlink\" title=\"How to save a spark DataFrame as a patitioned hive table\"></a>How to save a spark DataFrame as a patitioned hive table</h1><h2 id=\"utilise-saveAsTable-method\"><a href=\"#utilise-saveAsTable-method\" class=\"headerlink\" title=\"utilise saveAsTable method\"></a>utilise saveAsTable method</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val conf = new SparkConf().setAppName(&quot;Simple Application&quot;).setMaster(&quot;local&quot;)</span><br><span class=\"line\">val sc = new SparkContext(conf)</span><br><span class=\"line\">val sqlContext = new org.apache.spark.sql.SQLContext(sc)</span><br><span class=\"line\">import sqlContext.implicits._</span><br><span class=\"line\">val hiveContext = new org.apache.spark.sql.hive.HiveContext(sc)</span><br><span class=\"line\">hiveContext.sql(&quot;use database&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">val cmd =</span><br><span class=\"line\">  &quot;&quot;&quot;</span><br><span class=\"line\">     select</span><br><span class=\"line\">      col1,</span><br><span class=\"line\">      col2</span><br><span class=\"line\">     from</span><br><span class=\"line\">      table</span><br><span class=\"line\">  &quot;&quot;&quot;.stripMargin</span><br><span class=\"line\">val yourDf = hiveContext.sql(cmd)</span><br><span class=\"line\">yourDf.printSchema()</span><br><span class=\"line\">yourDf.write.partitionBy(&quot;col2&quot;).saveAsTable(&quot;partitionTableName&quot;)</span><br></pre></td></tr></table></figure>\n","excerpt":"","more":"<h1 id=\"How-to-save-a-spark-DataFrame-as-a-patitioned-hive-table\"><a href=\"#How-to-save-a-spark-DataFrame-as-a-patitioned-hive-table\" class=\"headerlink\" title=\"How to save a spark DataFrame as a patitioned hive table\"></a>How to save a spark DataFrame as a patitioned hive table</h1><h2 id=\"utilise-saveAsTable-method\"><a href=\"#utilise-saveAsTable-method\" class=\"headerlink\" title=\"utilise saveAsTable method\"></a>utilise saveAsTable method</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val conf = new SparkConf().setAppName(&quot;Simple Application&quot;).setMaster(&quot;local&quot;)</span><br><span class=\"line\">val sc = new SparkContext(conf)</span><br><span class=\"line\">val sqlContext = new org.apache.spark.sql.SQLContext(sc)</span><br><span class=\"line\">import sqlContext.implicits._</span><br><span class=\"line\">val hiveContext = new org.apache.spark.sql.hive.HiveContext(sc)</span><br><span class=\"line\">hiveContext.sql(&quot;use database&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">val cmd =</span><br><span class=\"line\">  &quot;&quot;&quot;</span><br><span class=\"line\">     select</span><br><span class=\"line\">      col1,</span><br><span class=\"line\">      col2</span><br><span class=\"line\">     from</span><br><span class=\"line\">      table</span><br><span class=\"line\">  &quot;&quot;&quot;.stripMargin</span><br><span class=\"line\">val yourDf = hiveContext.sql(cmd)</span><br><span class=\"line\">yourDf.printSchema()</span><br><span class=\"line\">yourDf.write.partitionBy(&quot;col2&quot;).saveAsTable(&quot;partitionTableName&quot;)</span><br></pre></td></tr></table></figure>\n"},{"title":"SPARK的宽依赖和窄依赖","date":"2016-04-25T15:37:04.000Z","_content":"\n\nspark 的各种不同的transformation操作,可以根据是否依赖父RDDs的所有partision分为‘窄依赖’和‘宽依赖’,简单的说,有shuffle操作的就是宽依赖,而没有shuffle操作的就是窄依赖。\n对于窄依赖,spark会尽量将他们划分为同一个stage,而宽依赖则会称为另外的stage。\n\n","source":"_posts/SPARK的宽依赖和窄依赖.md","raw":"---\ntitle: SPARK的宽依赖和窄依赖\ndate: 2016-04-25 23:37:04\ntags: Spark\n---\n\n\nspark 的各种不同的transformation操作,可以根据是否依赖父RDDs的所有partision分为‘窄依赖’和‘宽依赖’,简单的说,有shuffle操作的就是宽依赖,而没有shuffle操作的就是窄依赖。\n对于窄依赖,spark会尽量将他们划分为同一个stage,而宽依赖则会称为另外的stage。\n\n","slug":"SPARK的宽依赖和窄依赖","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n95000hyeg328o79730","content":"<p>spark 的各种不同的transformation操作,可以根据是否依赖父RDDs的所有partision分为‘窄依赖’和‘宽依赖’,简单的说,有shuffle操作的就是宽依赖,而没有shuffle操作的就是窄依赖。<br>对于窄依赖,spark会尽量将他们划分为同一个stage,而宽依赖则会称为另外的stage。</p>\n","excerpt":"","more":"<p>spark 的各种不同的transformation操作,可以根据是否依赖父RDDs的所有partision分为‘窄依赖’和‘宽依赖’,简单的说,有shuffle操作的就是宽依赖,而没有shuffle操作的就是窄依赖。<br>对于窄依赖,spark会尽量将他们划分为同一个stage,而宽依赖则会称为另外的stage。</p>\n"},{"title":"Scala call-by-name call-by-value","date":"2016-07-19T15:30:34.000Z","_content":"Call-by-value has the advantage that it avoids repeated evaluation of arguments.\nCall-by-name has the advantage that it avoids evaluation of arguments when the\nparameter is not used at all by the function. Call-by-value is usually more efficient\nthan call-by-name, but a call-by-value evaluation might loop where a call-by-name\nevaluation would terminate. Consider:\n\nCall-by-value 的优势在于避免不断的计算参数。而call-by-name的优势在于如果一个函数根本就不会用到的参数，那么也不会被计算，与call-by-value恰好相反。下面的例子展示了一个Call-by-value会不停循环但是Call-by-name会停止的例子。\n\n```\nscala> def loop: Int = loop\nloop: Int\nscala> def first(x: Int, y: Int) = x\nfirst: (Int,Int)Int\n```\nThen first(1, loop) reduces with call-by-name to 1, whereas the same term reduces with call-by-value repeatedly to itself, hence evaluation does not terminate.\nfirst(1, loop)\n→ first(1, loop)\n→ first(1, loop)\n→ ...\n上面的例子，之所以不停的循环的原因就是,y 被声明为 Call-by-value，因而，按照上面的说法，无论是否这个参数会被用到，该参数都会被计算，所以会不停的循环。\n\nScala uses call-by-value by default, but it switches to call-by-name evaluation if the\nparameter type is preceded by =>.\n```\nscala> def constOne(x: Int, y: => Int) = 1\nconstOne: (Int,=> Int)Int\nscala> constOne(1, loop)\nunnamed0: Int = 1\nscala> constOne(loop, 2) // gives an infinite loop.\n```\n\n\nconstOne(1,loop) 会停止，y被声明为Call-by-name, 所以当没有用到这个参数的时候,则不会被计算，因此不会陷入无限循环。\nconstOne(loop,2) 则恰好相反。\n\n\n\n\n本文示例 来自于  《ScalaByExample》,感谢原作者。\n\n\n\n","source":"_posts/Scala-call-by-name-call-by-value.md","raw":"---\ntitle: Scala call-by-name call-by-value\ndate: 2016-07-19 23:30:34\ntags: Scala\n---\nCall-by-value has the advantage that it avoids repeated evaluation of arguments.\nCall-by-name has the advantage that it avoids evaluation of arguments when the\nparameter is not used at all by the function. Call-by-value is usually more efficient\nthan call-by-name, but a call-by-value evaluation might loop where a call-by-name\nevaluation would terminate. Consider:\n\nCall-by-value 的优势在于避免不断的计算参数。而call-by-name的优势在于如果一个函数根本就不会用到的参数，那么也不会被计算，与call-by-value恰好相反。下面的例子展示了一个Call-by-value会不停循环但是Call-by-name会停止的例子。\n\n```\nscala> def loop: Int = loop\nloop: Int\nscala> def first(x: Int, y: Int) = x\nfirst: (Int,Int)Int\n```\nThen first(1, loop) reduces with call-by-name to 1, whereas the same term reduces with call-by-value repeatedly to itself, hence evaluation does not terminate.\nfirst(1, loop)\n→ first(1, loop)\n→ first(1, loop)\n→ ...\n上面的例子，之所以不停的循环的原因就是,y 被声明为 Call-by-value，因而，按照上面的说法，无论是否这个参数会被用到，该参数都会被计算，所以会不停的循环。\n\nScala uses call-by-value by default, but it switches to call-by-name evaluation if the\nparameter type is preceded by =>.\n```\nscala> def constOne(x: Int, y: => Int) = 1\nconstOne: (Int,=> Int)Int\nscala> constOne(1, loop)\nunnamed0: Int = 1\nscala> constOne(loop, 2) // gives an infinite loop.\n```\n\n\nconstOne(1,loop) 会停止，y被声明为Call-by-name, 所以当没有用到这个参数的时候,则不会被计算，因此不会陷入无限循环。\nconstOne(loop,2) 则恰好相反。\n\n\n\n\n本文示例 来自于  《ScalaByExample》,感谢原作者。\n\n\n\n","slug":"Scala-call-by-name-call-by-value","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n9a000jyeg34igxakw1","content":"<p>Call-by-value has the advantage that it avoids repeated evaluation of arguments.<br>Call-by-name has the advantage that it avoids evaluation of arguments when the<br>parameter is not used at all by the function. Call-by-value is usually more efficient<br>than call-by-name, but a call-by-value evaluation might loop where a call-by-name<br>evaluation would terminate. Consider:</p>\n<p>Call-by-value 的优势在于避免不断的计算参数。而call-by-name的优势在于如果一个函数根本就不会用到的参数，那么也不会被计算，与call-by-value恰好相反。下面的例子展示了一个Call-by-value会不停循环但是Call-by-name会停止的例子。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scala&gt; def loop: Int = loop</span><br><span class=\"line\">loop: Int</span><br><span class=\"line\">scala&gt; def first(x: Int, y: Int) = x</span><br><span class=\"line\">first: (Int,Int)Int</span><br></pre></td></tr></table></figure>\n<p>Then first(1, loop) reduces with call-by-name to 1, whereas the same term reduces with call-by-value repeatedly to itself, hence evaluation does not terminate.<br>first(1, loop)<br>→ first(1, loop)<br>→ first(1, loop)<br>→ …<br>上面的例子，之所以不停的循环的原因就是,y 被声明为 Call-by-value，因而，按照上面的说法，无论是否这个参数会被用到，该参数都会被计算，所以会不停的循环。</p>\n<p>Scala uses call-by-value by default, but it switches to call-by-name evaluation if the<br>parameter type is preceded by =&gt;.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scala&gt; def constOne(x: Int, y: =&gt; Int) = 1</span><br><span class=\"line\">constOne: (Int,=&gt; Int)Int</span><br><span class=\"line\">scala&gt; constOne(1, loop)</span><br><span class=\"line\">unnamed0: Int = 1</span><br><span class=\"line\">scala&gt; constOne(loop, 2) // gives an infinite loop.</span><br></pre></td></tr></table></figure></p>\n<p>constOne(1,loop) 会停止，y被声明为Call-by-name, 所以当没有用到这个参数的时候,则不会被计算，因此不会陷入无限循环。<br>constOne(loop,2) 则恰好相反。</p>\n<p>本文示例 来自于  《ScalaByExample》,感谢原作者。</p>\n","excerpt":"","more":"<p>Call-by-value has the advantage that it avoids repeated evaluation of arguments.<br>Call-by-name has the advantage that it avoids evaluation of arguments when the<br>parameter is not used at all by the function. Call-by-value is usually more efficient<br>than call-by-name, but a call-by-value evaluation might loop where a call-by-name<br>evaluation would terminate. Consider:</p>\n<p>Call-by-value 的优势在于避免不断的计算参数。而call-by-name的优势在于如果一个函数根本就不会用到的参数，那么也不会被计算，与call-by-value恰好相反。下面的例子展示了一个Call-by-value会不停循环但是Call-by-name会停止的例子。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scala&gt; def loop: Int = loop</span><br><span class=\"line\">loop: Int</span><br><span class=\"line\">scala&gt; def first(x: Int, y: Int) = x</span><br><span class=\"line\">first: (Int,Int)Int</span><br></pre></td></tr></table></figure>\n<p>Then first(1, loop) reduces with call-by-name to 1, whereas the same term reduces with call-by-value repeatedly to itself, hence evaluation does not terminate.<br>first(1, loop)<br>→ first(1, loop)<br>→ first(1, loop)<br>→ …<br>上面的例子，之所以不停的循环的原因就是,y 被声明为 Call-by-value，因而，按照上面的说法，无论是否这个参数会被用到，该参数都会被计算，所以会不停的循环。</p>\n<p>Scala uses call-by-value by default, but it switches to call-by-name evaluation if the<br>parameter type is preceded by =&gt;.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scala&gt; def constOne(x: Int, y: =&gt; Int) = 1</span><br><span class=\"line\">constOne: (Int,=&gt; Int)Int</span><br><span class=\"line\">scala&gt; constOne(1, loop)</span><br><span class=\"line\">unnamed0: Int = 1</span><br><span class=\"line\">scala&gt; constOne(loop, 2) // gives an infinite loop.</span><br></pre></td></tr></table></figure></p>\n<p>constOne(1,loop) 会停止，y被声明为Call-by-name, 所以当没有用到这个参数的时候,则不会被计算，因此不会陷入无限循环。<br>constOne(loop,2) 则恰好相反。</p>\n<p>本文示例 来自于  《ScalaByExample》,感谢原作者。</p>\n"},{"title":"ScalaList","date":"2016-07-26T05:11:12.000Z","_content":"Lists are not built in in Scala; they are defined by an abstract class List, **which comes with two subclasses for :: and Nil.**\nList 并不是Scala的内置类型。List被定义为抽象类。\n\n```\n    package scala\n    abstract class List[+A] {\n```\nList is an abstract class, so one cannot define elements by calling the empty List constructor (e.g. by new List). The class has a type parameter a. It is co-variant in this parameter,which means thatList[S] <: List[T] for all types S and T such thatS <: T.The class is situated in the package scala.This is a package containing the most important standard classes of Scala. List defines a number of methods, which are explained in the following.\nList 是抽象类，所以没有办法通过空的List构造器来定义元素。List存在一个类型参数A。该参数是协变类型, 对于任意类型S和T，如果S<:T, 则 List[S]<:List[T]。该类的定义在scala package中。这个包是Scala中最重要的标准calsses。\n","source":"_posts/ScalaList.md","raw":"---\ntitle: ScalaList\ndate: 2016-07-26 13:11:12\ntags: Scala\n---\nLists are not built in in Scala; they are defined by an abstract class List, **which comes with two subclasses for :: and Nil.**\nList 并不是Scala的内置类型。List被定义为抽象类。\n\n```\n    package scala\n    abstract class List[+A] {\n```\nList is an abstract class, so one cannot define elements by calling the empty List constructor (e.g. by new List). The class has a type parameter a. It is co-variant in this parameter,which means thatList[S] <: List[T] for all types S and T such thatS <: T.The class is situated in the package scala.This is a package containing the most important standard classes of Scala. List defines a number of methods, which are explained in the following.\nList 是抽象类，所以没有办法通过空的List构造器来定义元素。List存在一个类型参数A。该参数是协变类型, 对于任意类型S和T，如果S<:T, 则 List[S]<:List[T]。该类的定义在scala package中。这个包是Scala中最重要的标准calsses。\n","slug":"ScalaList","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n9d000lyeg30kbalqs2","content":"<p>Lists are not built in in Scala; they are defined by an abstract class List, <strong>which comes with two subclasses for :: and Nil.</strong><br>List 并不是Scala的内置类型。List被定义为抽象类。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package scala</span><br><span class=\"line\">abstract class List[+A] &#123;</span><br></pre></td></tr></table></figure>\n<p>List is an abstract class, so one cannot define elements by calling the empty List constructor (e.g. by new List). The class has a type parameter a. It is co-variant in this parameter,which means thatList[S] &lt;: List[T] for all types S and T such thatS &lt;: T.The class is situated in the package scala.This is a package containing the most important standard classes of Scala. List defines a number of methods, which are explained in the following.<br>List 是抽象类，所以没有办法通过空的List构造器来定义元素。List存在一个类型参数A。该参数是协变类型, 对于任意类型S和T，如果S&lt;:T, 则 List[S]&lt;:List[T]。该类的定义在scala package中。这个包是Scala中最重要的标准calsses。</p>\n","excerpt":"","more":"<p>Lists are not built in in Scala; they are defined by an abstract class List, <strong>which comes with two subclasses for :: and Nil.</strong><br>List 并不是Scala的内置类型。List被定义为抽象类。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package scala</span><br><span class=\"line\">abstract class List[+A] &#123;</span><br></pre></td></tr></table></figure>\n<p>List is an abstract class, so one cannot define elements by calling the empty List constructor (e.g. by new List). The class has a type parameter a. It is co-variant in this parameter,which means thatList[S] &lt;: List[T] for all types S and T such thatS &lt;: T.The class is situated in the package scala.This is a package containing the most important standard classes of Scala. List defines a number of methods, which are explained in the following.<br>List 是抽象类，所以没有办法通过空的List构造器来定义元素。List存在一个类型参数A。该参数是协变类型, 对于任意类型S和T，如果S&lt;:T, 则 List[S]&lt;:List[T]。该类的定义在scala package中。这个包是Scala中最重要的标准calsses。</p>\n"},{"title":"Spark Window Operation ","date":"2016-08-22T06:39:58.000Z","_content":"","source":"_posts/Spark-Window-Operation.md","raw":"---\ntitle: 'Spark Window Operation '\ndate: 2016-08-22 14:39:58\ntags:\n---\n","slug":"Spark-Window-Operation","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n9g000nyeg38791pstj","content":"","excerpt":"","more":""},{"title":"Spark 2.0 Introduction","date":"2016-08-19T10:04:07.000Z","_content":"\n# Spark 2.0 MLib Introduction #\n\n\nAs of Spark 2.0, the RDD-based APIs in the spark.mllib package have entered maintenance mode. The primary Machine Learning API for Spark is now the DataFrame-based API in the spark.ml package.\n\nSpark2.0 ,在spark.mllib中的基于RDD的机器学习APIs将会进入维护模式。现在机器学习的主要的API基于DataFrame,位于spark.ml中。\n\n\n\nWhat are the implications?\n\n    MLlib will still support the RDD-based API in spark.mllib with bug fixes.\n    MLlib will not add new features to the RDD-based API.\n    In the Spark 2.x releases, MLlib will add features to the DataFrames-based API to reach feature parity with the RDD-based API.\n    After reaching feature parity (roughly estimated for Spark 2.2), the RDD-based API will be deprecated.\n    The RDD-based API is expected to be removed in Spark 3.0.\n\n\nWhy is MLlib switching to the DataFrame-based API?\n\n    DataFrames provide a more user-friendly API than RDDs. The many benefits of DataFrames include Spark Datasources, SQL/DataFrame queries, Tungsten and Catalyst optimizations, and uniform APIs across languages.\n    The DataFrame-based API for MLlib provides a uniform API across ML algorithms and across multiple languages.\n    DataFrames facilitate practical ML Pipelines, particularly feature transformations. See the Pipelines guide for details.\n\n\n\n\n","source":"_posts/Spark-2-0-Introduction.md","raw":"---\ntitle: Spark 2.0 Introduction\ndate: 2016-08-19 18:04:07\ntags: Spark\n---\n\n# Spark 2.0 MLib Introduction #\n\n\nAs of Spark 2.0, the RDD-based APIs in the spark.mllib package have entered maintenance mode. The primary Machine Learning API for Spark is now the DataFrame-based API in the spark.ml package.\n\nSpark2.0 ,在spark.mllib中的基于RDD的机器学习APIs将会进入维护模式。现在机器学习的主要的API基于DataFrame,位于spark.ml中。\n\n\n\nWhat are the implications?\n\n    MLlib will still support the RDD-based API in spark.mllib with bug fixes.\n    MLlib will not add new features to the RDD-based API.\n    In the Spark 2.x releases, MLlib will add features to the DataFrames-based API to reach feature parity with the RDD-based API.\n    After reaching feature parity (roughly estimated for Spark 2.2), the RDD-based API will be deprecated.\n    The RDD-based API is expected to be removed in Spark 3.0.\n\n\nWhy is MLlib switching to the DataFrame-based API?\n\n    DataFrames provide a more user-friendly API than RDDs. The many benefits of DataFrames include Spark Datasources, SQL/DataFrame queries, Tungsten and Catalyst optimizations, and uniform APIs across languages.\n    The DataFrame-based API for MLlib provides a uniform API across ML algorithms and across multiple languages.\n    DataFrames facilitate practical ML Pipelines, particularly feature transformations. See the Pipelines guide for details.\n\n\n\n\n","slug":"Spark-2-0-Introduction","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n9k000pyeg3vsrd2y4g","content":"<h1 id=\"Spark-2-0-MLib-Introduction\"><a href=\"#Spark-2-0-MLib-Introduction\" class=\"headerlink\" title=\"Spark 2.0 MLib Introduction\"></a>Spark 2.0 MLib Introduction</h1><p>As of Spark 2.0, the RDD-based APIs in the spark.mllib package have entered maintenance mode. The primary Machine Learning API for Spark is now the DataFrame-based API in the spark.ml package.</p>\n<p>Spark2.0 ,在spark.mllib中的基于RDD的机器学习APIs将会进入维护模式。现在机器学习的主要的API基于DataFrame,位于spark.ml中。</p>\n<p>What are the implications?</p>\n<pre><code>MLlib will still support the RDD-based API in spark.mllib with bug fixes.\nMLlib will not add new features to the RDD-based API.\nIn the Spark 2.x releases, MLlib will add features to the DataFrames-based API to reach feature parity with the RDD-based API.\nAfter reaching feature parity (roughly estimated for Spark 2.2), the RDD-based API will be deprecated.\nThe RDD-based API is expected to be removed in Spark 3.0.\n</code></pre><p>Why is MLlib switching to the DataFrame-based API?</p>\n<pre><code>DataFrames provide a more user-friendly API than RDDs. The many benefits of DataFrames include Spark Datasources, SQL/DataFrame queries, Tungsten and Catalyst optimizations, and uniform APIs across languages.\nThe DataFrame-based API for MLlib provides a uniform API across ML algorithms and across multiple languages.\nDataFrames facilitate practical ML Pipelines, particularly feature transformations. See the Pipelines guide for details.\n</code></pre>","excerpt":"","more":"<h1 id=\"Spark-2-0-MLib-Introduction\"><a href=\"#Spark-2-0-MLib-Introduction\" class=\"headerlink\" title=\"Spark 2.0 MLib Introduction\"></a>Spark 2.0 MLib Introduction</h1><p>As of Spark 2.0, the RDD-based APIs in the spark.mllib package have entered maintenance mode. The primary Machine Learning API for Spark is now the DataFrame-based API in the spark.ml package.</p>\n<p>Spark2.0 ,在spark.mllib中的基于RDD的机器学习APIs将会进入维护模式。现在机器学习的主要的API基于DataFrame,位于spark.ml中。</p>\n<p>What are the implications?</p>\n<pre><code>MLlib will still support the RDD-based API in spark.mllib with bug fixes.\nMLlib will not add new features to the RDD-based API.\nIn the Spark 2.x releases, MLlib will add features to the DataFrames-based API to reach feature parity with the RDD-based API.\nAfter reaching feature parity (roughly estimated for Spark 2.2), the RDD-based API will be deprecated.\nThe RDD-based API is expected to be removed in Spark 3.0.\n</code></pre><p>Why is MLlib switching to the DataFrame-based API?</p>\n<pre><code>DataFrames provide a more user-friendly API than RDDs. The many benefits of DataFrames include Spark Datasources, SQL/DataFrame queries, Tungsten and Catalyst optimizations, and uniform APIs across languages.\nThe DataFrame-based API for MLlib provides a uniform API across ML algorithms and across multiple languages.\nDataFrames facilitate practical ML Pipelines, particularly feature transformations. See the Pipelines guide for details.\n</code></pre>"},{"title":"SparkPassFunctions","date":"2016-08-11T07:19:37.000Z","_content":"\n\n\n```\n    class MyClass {\n      val field = \"Hello\"\n      def doStuff(rdd: RDD[String]): RDD[String] = {\n      val field_ = this.field\n      rdd.map(x => field_ + x)}\n    }\n```\n","source":"_posts/SparkPassFunctions.md","raw":"---\ntitle: SparkPassFunctions\ndate: 2016-08-11 15:19:37\ntags: Spark\n---\n\n\n\n```\n    class MyClass {\n      val field = \"Hello\"\n      def doStuff(rdd: RDD[String]): RDD[String] = {\n      val field_ = this.field\n      rdd.map(x => field_ + x)}\n    }\n```\n","slug":"SparkPassFunctions","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n9n000qyeg3ijtkosl2","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class MyClass &#123;</span><br><span class=\"line\">  val field = &quot;Hello&quot;</span><br><span class=\"line\">  def doStuff(rdd: RDD[String]): RDD[String] = &#123;</span><br><span class=\"line\">  val field_ = this.field</span><br><span class=\"line\">  rdd.map(x =&gt; field_ + x)&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class MyClass &#123;</span><br><span class=\"line\">  val field = &quot;Hello&quot;</span><br><span class=\"line\">  def doStuff(rdd: RDD[String]): RDD[String] = &#123;</span><br><span class=\"line\">  val field_ = this.field</span><br><span class=\"line\">  rdd.map(x =&gt; field_ + x)&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n"},{"title":"SparkStreamLearning","date":"2016-11-28T05:16:15.000Z","_content":"# input source \nkafka \nakka\n# output \nredis\nkafka\nelasticSearch\nhive\nmySql\n","source":"_posts/SparkStreamLearning.md","raw":"---\ntitle: SparkStreamLearning\ndate: 2016-11-28 13:16:15\ntags: Spark Scala Streaming\n---\n# input source \nkafka \nakka\n# output \nredis\nkafka\nelasticSearch\nhive\nmySql\n","slug":"SparkStreamLearning","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n9v000tyeg3hiyy3e6o","content":"<h1 id=\"input-source\"><a href=\"#input-source\" class=\"headerlink\" title=\"input source\"></a>input source</h1><p>kafka<br>akka</p>\n<h1 id=\"output\"><a href=\"#output\" class=\"headerlink\" title=\"output\"></a>output</h1><p>redis<br>kafka<br>elasticSearch<br>hive<br>mySql</p>\n","excerpt":"","more":"<h1 id=\"input-source\"><a href=\"#input-source\" class=\"headerlink\" title=\"input source\"></a>input source</h1><p>kafka<br>akka</p>\n<h1 id=\"output\"><a href=\"#output\" class=\"headerlink\" title=\"output\"></a>output</h1><p>redis<br>kafka<br>elasticSearch<br>hive<br>mySql</p>\n"},{"title":"Spark Streaming Programming Guide","date":"2016-12-15T15:58:03.000Z","_content":"\n\n","source":"_posts/Spark-Streaming-Programming-Guide.md","raw":"---\ntitle: Spark Streaming Programming Guide\ndate: 2016-12-15 23:58:03\ntags: Spark Streaming\n---\n\n\n","slug":"Spark-Streaming-Programming-Guide","published":1,"updated":"2016-12-22T10:33:58.946Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2n9y000uyeg3stasyio4","content":"","excerpt":"","more":""},{"title":"install tensorflow","date":"2016-12-28T07:04:08.000Z","_content":"\nanaconda 提供了python科学计算的环境，为各种python软件包安装和管理提供了遍历，按照官方文档的方式即可以安装tensorflow. \n\n## 创建tensorflow的虚拟环境\n```\nconda create -n tensorflow python=3.5\n```\n\n## 安装tensorflow \n```\n$ source activate tensorflow\n(tensorflow)$  # Your prompt should change\n\n# Linux/Mac OS X, Python 2.7/3.4/3.5, CPU only:\n(tensorflow)$ conda install -c conda-forge tensorflow\n```\n\n如果网络状况不好，那么可以采用pip安装。\n\n```\n$ source activate tensorflow\n(tensorflow)$  # Your prompt should change\n```\n\n```\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\n```\n\n**请注意这里不能采用pip3安装，因为anaconda环境中pip3安装是有问题的**\n```\npip install --ignore-installed --upgrade $TF_BINARY_URL\n```\n\n\n## 测试是否安装成功\n\n```\nimport tensorflow as tf\nprint(tf.__versioin__)\n```\n\n\n\n","source":"_posts/install-tensorflow.md","raw":"---\ntitle: install tensorflow\ndate: 2016-12-28 15:04:08\ntags: tensorflow\n---\n\nanaconda 提供了python科学计算的环境，为各种python软件包安装和管理提供了遍历，按照官方文档的方式即可以安装tensorflow. \n\n## 创建tensorflow的虚拟环境\n```\nconda create -n tensorflow python=3.5\n```\n\n## 安装tensorflow \n```\n$ source activate tensorflow\n(tensorflow)$  # Your prompt should change\n\n# Linux/Mac OS X, Python 2.7/3.4/3.5, CPU only:\n(tensorflow)$ conda install -c conda-forge tensorflow\n```\n\n如果网络状况不好，那么可以采用pip安装。\n\n```\n$ source activate tensorflow\n(tensorflow)$  # Your prompt should change\n```\n\n```\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\n```\n\n**请注意这里不能采用pip3安装，因为anaconda环境中pip3安装是有问题的**\n```\npip install --ignore-installed --upgrade $TF_BINARY_URL\n```\n\n\n## 测试是否安装成功\n\n```\nimport tensorflow as tf\nprint(tf.__versioin__)\n```\n\n\n\n","slug":"install-tensorflow","published":1,"updated":"2017-01-07T06:07:11.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2na2000wyeg3kn7nmx49","content":"<p>anaconda 提供了python科学计算的环境，为各种python软件包安装和管理提供了遍历，按照官方文档的方式即可以安装tensorflow. </p>\n<h2 id=\"创建tensorflow的虚拟环境\"><a href=\"#创建tensorflow的虚拟环境\" class=\"headerlink\" title=\"创建tensorflow的虚拟环境\"></a>创建tensorflow的虚拟环境</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n tensorflow python=3.5</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装tensorflow\"><a href=\"#安装tensorflow\" class=\"headerlink\" title=\"安装tensorflow\"></a>安装tensorflow</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ source activate tensorflow</span><br><span class=\"line\">(tensorflow)$  # Your prompt should change</span><br><span class=\"line\"></span><br><span class=\"line\"># Linux/Mac OS X, Python 2.7/3.4/3.5, CPU only:</span><br><span class=\"line\">(tensorflow)$ conda install -c conda-forge tensorflow</span><br></pre></td></tr></table></figure>\n<p>如果网络状况不好，那么可以采用pip安装。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ source activate tensorflow</span><br><span class=\"line\">(tensorflow)$  # Your prompt should change</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl</span><br></pre></td></tr></table></figure>\n<p><strong>请注意这里不能采用pip3安装，因为anaconda环境中pip3安装是有问题的</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install --ignore-installed --upgrade $TF_BINARY_URL</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"测试是否安装成功\"><a href=\"#测试是否安装成功\" class=\"headerlink\" title=\"测试是否安装成功\"></a>测试是否安装成功</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import tensorflow as tf</span><br><span class=\"line\">print(tf.__versioin__)</span><br></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>anaconda 提供了python科学计算的环境，为各种python软件包安装和管理提供了遍历，按照官方文档的方式即可以安装tensorflow. </p>\n<h2 id=\"创建tensorflow的虚拟环境\"><a href=\"#创建tensorflow的虚拟环境\" class=\"headerlink\" title=\"创建tensorflow的虚拟环境\"></a>创建tensorflow的虚拟环境</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n tensorflow python=3.5</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装tensorflow\"><a href=\"#安装tensorflow\" class=\"headerlink\" title=\"安装tensorflow\"></a>安装tensorflow</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ source activate tensorflow</span><br><span class=\"line\">(tensorflow)$  # Your prompt should change</span><br><span class=\"line\"></span><br><span class=\"line\"># Linux/Mac OS X, Python 2.7/3.4/3.5, CPU only:</span><br><span class=\"line\">(tensorflow)$ conda install -c conda-forge tensorflow</span><br></pre></td></tr></table></figure>\n<p>如果网络状况不好，那么可以采用pip安装。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ source activate tensorflow</span><br><span class=\"line\">(tensorflow)$  # Your prompt should change</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl</span><br></pre></td></tr></table></figure>\n<p><strong>请注意这里不能采用pip3安装，因为anaconda环境中pip3安装是有问题的</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install --ignore-installed --upgrade $TF_BINARY_URL</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"测试是否安装成功\"><a href=\"#测试是否安装成功\" class=\"headerlink\" title=\"测试是否安装成功\"></a>测试是否安装成功</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import tensorflow as tf</span><br><span class=\"line\">print(tf.__versioin__)</span><br></pre></td></tr></table></figure>\n"},{"title":"save spark rdd into Mysql","date":"2016-12-05T14:12:19.000Z","_content":"\n```\nimport java.util.Properties\nval target_df = targetRdd.toDF()\nval prop = new Properties()\nprop.put(\"user\", \"username\")\nprop.put(\"password\", \"password\")\nret_df.write.mode(\"append\").jdbc(\"jdbc:mysql://host:port/database\",\"table\",prop)\n```\n\n","source":"_posts/save-spark-rdd-into-Mysql.md","raw":"---\ntitle: save spark rdd into Mysql\ndate: 2016-12-05 22:12:19\ntags:\n---\n\n```\nimport java.util.Properties\nval target_df = targetRdd.toDF()\nval prop = new Properties()\nprop.put(\"user\", \"username\")\nprop.put(\"password\", \"password\")\nret_df.write.mode(\"append\").jdbc(\"jdbc:mysql://host:port/database\",\"table\",prop)\n```\n\n","slug":"save-spark-rdd-into-Mysql","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2na5000yyeg3qxxmrc2s","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import java.util.Properties</span><br><span class=\"line\">val target_df = targetRdd.toDF()</span><br><span class=\"line\">val prop = new Properties()</span><br><span class=\"line\">prop.put(&quot;user&quot;, &quot;username&quot;)</span><br><span class=\"line\">prop.put(&quot;password&quot;, &quot;password&quot;)</span><br><span class=\"line\">ret_df.write.mode(&quot;append&quot;).jdbc(&quot;jdbc:mysql://host:port/database&quot;,&quot;table&quot;,prop)</span><br></pre></td></tr></table></figure>\n","excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import java.util.Properties</span><br><span class=\"line\">val target_df = targetRdd.toDF()</span><br><span class=\"line\">val prop = new Properties()</span><br><span class=\"line\">prop.put(&quot;user&quot;, &quot;username&quot;)</span><br><span class=\"line\">prop.put(&quot;password&quot;, &quot;password&quot;)</span><br><span class=\"line\">ret_df.write.mode(&quot;append&quot;).jdbc(&quot;jdbc:mysql://host:port/database&quot;,&quot;table&quot;,prop)</span><br></pre></td></tr></table></figure>\n"},{"title":"vim使用技巧","date":"2016-12-21T16:10:50.000Z","_content":"\n\n## dbext\n在命令式中输入如下指令，比如DBCompleteTables可以在vim的dictionary中存储当前数据库的表格名称。\n```\nDBCompleteTables\nDBCompleteProcedures\nDBCompleteViews\n```\n此时在vim中输入表格名称时候可以通过ctrl+x 和 ctrl+k 来实现自动不全表名称的功能。\n\n","source":"_posts/vim使用技巧.md","raw":"---\ntitle: vim使用技巧\ndate: 2016-12-22 00:10:50\ntags: VIM\n---\n\n\n## dbext\n在命令式中输入如下指令，比如DBCompleteTables可以在vim的dictionary中存储当前数据库的表格名称。\n```\nDBCompleteTables\nDBCompleteProcedures\nDBCompleteViews\n```\n此时在vim中输入表格名称时候可以通过ctrl+x 和 ctrl+k 来实现自动不全表名称的功能。\n\n","slug":"vim使用技巧","published":1,"updated":"2017-01-07T06:07:11.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2na90011yeg34na39s4d","content":"<h2 id=\"dbext\"><a href=\"#dbext\" class=\"headerlink\" title=\"dbext\"></a>dbext</h2><p>在命令式中输入如下指令，比如DBCompleteTables可以在vim的dictionary中存储当前数据库的表格名称。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DBCompleteTables</span><br><span class=\"line\">DBCompleteProcedures</span><br><span class=\"line\">DBCompleteViews</span><br></pre></td></tr></table></figure></p>\n<p>此时在vim中输入表格名称时候可以通过ctrl+x 和 ctrl+k 来实现自动不全表名称的功能。</p>\n","excerpt":"","more":"<h2 id=\"dbext\"><a href=\"#dbext\" class=\"headerlink\" title=\"dbext\"></a>dbext</h2><p>在命令式中输入如下指令，比如DBCompleteTables可以在vim的dictionary中存储当前数据库的表格名称。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DBCompleteTables</span><br><span class=\"line\">DBCompleteProcedures</span><br><span class=\"line\">DBCompleteViews</span><br></pre></td></tr></table></figure></p>\n<p>此时在vim中输入表格名称时候可以通过ctrl+x 和 ctrl+k 来实现自动不全表名称的功能。</p>\n"},{"title":"机器学习相关材料","date":"2016-07-13T12:42:36.000Z","_content":"\n\n1、数学基础\n- 1、微积分 http://v.163.com/special/sp/singlevariablecalculus.html  http://open.163.com/special/opencourse/multivariable.html\n- 2、线性代数 http://open.163.com/special/opencourse/daishu.html\n- 3、概率统计http://open.163.com/special/Khan/probability.html\n想要深入学习机器学习，需要具有扎实的数学基础（矩阵分析和概率统计是基础的理论）\n\n2、进阶版本数学基础课程\n- 1、最优化理论（重点凸优化理论）  http://stanford.edu/~boyd/cvxbook/   http://xiaoyc.com/duality-theory-for-optimization/#1-1-lagrangian\n- 2、时变函数与泛函分析 http://ocw.nctu.edu.tw/course_list.php?page=2&bgid=1&gid=1  http://open.163.com/special/opencourse/fanhanfenxi.html\n- 3、随机过程 Hyperlink: Stochastic Process MIT View the complete course: Discrete Stochastic Processes\n\n3、机器学习基础课程\n- 1、Coursera上Andrew Ng Andrew Ng的《机器学习》\n- 2、林軒田(国立台湾大学) 機器學習基石\n\n4、机器学习基础课程\n- 1、 《统计学习方法》李航\n- 2、 《机器学习导论》\n- 3、 《PRML》\n- 4、 《图解机器学习》[日]杉山将\n- 5、   Machine Learning: A Probabilistic Prespective （Kevin Murphy）\n- 6、   Pattern Recognition and Machine Learning （Christopher Bishop）\n- 7、 《Spark机器学习》\n- 8、 《机器学习实战》\n- 9、 《贝叶斯思维:统计建模的Python学习法》\n- 10、Python自然语言处理》\n- 11、数学之美 （吴军）\n- 12、Web智能算法 （Haralambos Marmanis, Dmitry Babenko）\n- 13、集体智慧编程 （Toby Segaran）\n- 14、推荐系统实践\n- 15、计算广告学\n\n5、深度学习（注定将成为最近几年的爆发式增长）\n- 1、《Deep Learning》http://www.deeplearningbook.org\n- 2、  CSDN Blog http://blog.csdn.net/zouxy09/article/details/8775360\n- 3、《斯坦福大学深度学习教程》http://ufldl.stanford.edu/tutorial\n\n6、 杂项\n\n- 《Choosing a Machine Learning Classifier》\n- 《An Introduction to Deep Learning: From Perceptrons to Deep Networks》 译文：《http://www.cnblogs.com/xiaowanyer/p/3701944.html》\n- 《The LION Way: Machine Learning plus Intelligent Optimization》\n- 《分布式并行处理的数据》\n- 《Deep Learning for Natural Language Processing and Related Applications》\n- 《Neural Networks and Deep Learning》\n- 《分布式机器学习的故事》\n- 《Deep Learning 101》\n- 《Deep learning from the bottom up》\n- 《Deep Learning（深度学习）学习笔记整理系列》\n- 《Google Turns To Deep Learning Classification To Fight Web Spam》\n- 《Deep Learning Sentiment Analysis for Movie Reviews using Neo4j》\n- 《EMNLP上两篇关于股票趋势的应用论文 》\n- 《Learning to Rank for Information Retrieval and Natural Language Processing》\n- 《Geoffrey E. Hinton》\n- 《Andrej Karpathy的深度强化学习演示》 论文在这里\n- 《用大数据和机器学习做股票价格预测》\n- 《机器学习经典算法详解及Python实现--基于SMO的SVM分类器》\n- 《Use Google's Word2Vec for movie reviews》\n- 《深度卷积神经网络下围棋》\n- 《机器学习经典算法详解及Python实现--线性回归（Linear Regression）算法》\n- 《Caffe》\n- 《GoogLeNet深度学习模型的Caffe复现 》 GoogleNet论文\n- 《Deep Learning实战之word2vec》\n- 《A Deep Dive into Recurrent Neural Nets》\n- 《Geoffrey E. Hinton个人主页》\n- 《Deep Learning on Hadoop 2.0》\n- 《美团推荐算法实践》\n- 《The Trouble with SVMs》\n- 《Gaussian Processes for Machine Learning》\n- 《Introduction to ARMA Time Series Models – simplified》\n- 《Neural Net in C++ Tutorial》\n- 《Deep Learning Tutorials》\n- 《Deep Learning, The Curse of Dimensionality, and Autoencoders》\n- 《Topic modeling with LDA: MLlib meets GraphX》\n- 《Deep Learning for Multi-label Classification》\n- 《Google DeepMind publications》  AlphaGo团队官方论文\n- 《AM207: Monte Carlo Methods, Stochastic Optimization》\n- 《Back-to-Basics Weekend Reading - Machine Learning》\n- 《A Probabilistic Theory of Deep Learning》\n- 《How does Quora use machine learning in 2015?》\n- 《Parallel Machine Learning with scikit-learn and IPython》\n- 《Time Series Econometrics - A Concise Course》\n- 《A comparison of open source tools for sentiment analysis》\n- 《International Joint Conference on Artificial Intelligence Accepted paper》\n- 《How to Evaluate Machine Learning Models, Part 1: Orientation》 How to Evaluate Machine Learning Models, Part 2a: Classification Metrics,How to Evaluate Machine Learning Models, Part 2b: Ranking and Regression Metrics.\n- 《Learning scikit-learn: Machine Learning in Python》\n- 《Lightning fast Machine Learning with Spark》\n- 《How we’re using machine learning to fight shell selling》\n- 《Mining of Massive Datasets》\n- 《Advances in Extreme Learning Machines》\n- 《The Curse of Dimensionality in classification》\n- 《Demistifying LSTM Neural Networks》\n- 《Decoding Dimensionality Reduction, PCA and SVD》\n- 《What are the advantages of different classification algorithms?》\n- 《Kaggle R Tutorial on Machine Learning》 《Interactive R Tutorial: Machine Learning for the Titanic Competition》.\n- 《Logistic Regression and Gradient Descent》\n- 《Stock Forecasting With Machine Learning - Seven Possible Errors》\n- 《LR原理解析》  http://www.cnblogs.com/xiaowanyer/p/3701944.html\n- 机器学习顶级会议和杂志 http://icml.cc/2015/?page_id=175\n- 贝耶斯回归材料 http://blog.csdn.net/haoni123321/article/details/37913795\n- 贝耶斯回归材料 http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/ \n- AlphaGo原理解析https://www.youtube.com/watch?v=63FDxJ5e_Ew\n\n","source":"_posts/机器学习相关材料.md","raw":"---\ntitle: 机器学习相关材料\ndate: 2016-07-13 20:42:36\ntags:\n---\n\n\n1、数学基础\n- 1、微积分 http://v.163.com/special/sp/singlevariablecalculus.html  http://open.163.com/special/opencourse/multivariable.html\n- 2、线性代数 http://open.163.com/special/opencourse/daishu.html\n- 3、概率统计http://open.163.com/special/Khan/probability.html\n想要深入学习机器学习，需要具有扎实的数学基础（矩阵分析和概率统计是基础的理论）\n\n2、进阶版本数学基础课程\n- 1、最优化理论（重点凸优化理论）  http://stanford.edu/~boyd/cvxbook/   http://xiaoyc.com/duality-theory-for-optimization/#1-1-lagrangian\n- 2、时变函数与泛函分析 http://ocw.nctu.edu.tw/course_list.php?page=2&bgid=1&gid=1  http://open.163.com/special/opencourse/fanhanfenxi.html\n- 3、随机过程 Hyperlink: Stochastic Process MIT View the complete course: Discrete Stochastic Processes\n\n3、机器学习基础课程\n- 1、Coursera上Andrew Ng Andrew Ng的《机器学习》\n- 2、林軒田(国立台湾大学) 機器學習基石\n\n4、机器学习基础课程\n- 1、 《统计学习方法》李航\n- 2、 《机器学习导论》\n- 3、 《PRML》\n- 4、 《图解机器学习》[日]杉山将\n- 5、   Machine Learning: A Probabilistic Prespective （Kevin Murphy）\n- 6、   Pattern Recognition and Machine Learning （Christopher Bishop）\n- 7、 《Spark机器学习》\n- 8、 《机器学习实战》\n- 9、 《贝叶斯思维:统计建模的Python学习法》\n- 10、Python自然语言处理》\n- 11、数学之美 （吴军）\n- 12、Web智能算法 （Haralambos Marmanis, Dmitry Babenko）\n- 13、集体智慧编程 （Toby Segaran）\n- 14、推荐系统实践\n- 15、计算广告学\n\n5、深度学习（注定将成为最近几年的爆发式增长）\n- 1、《Deep Learning》http://www.deeplearningbook.org\n- 2、  CSDN Blog http://blog.csdn.net/zouxy09/article/details/8775360\n- 3、《斯坦福大学深度学习教程》http://ufldl.stanford.edu/tutorial\n\n6、 杂项\n\n- 《Choosing a Machine Learning Classifier》\n- 《An Introduction to Deep Learning: From Perceptrons to Deep Networks》 译文：《http://www.cnblogs.com/xiaowanyer/p/3701944.html》\n- 《The LION Way: Machine Learning plus Intelligent Optimization》\n- 《分布式并行处理的数据》\n- 《Deep Learning for Natural Language Processing and Related Applications》\n- 《Neural Networks and Deep Learning》\n- 《分布式机器学习的故事》\n- 《Deep Learning 101》\n- 《Deep learning from the bottom up》\n- 《Deep Learning（深度学习）学习笔记整理系列》\n- 《Google Turns To Deep Learning Classification To Fight Web Spam》\n- 《Deep Learning Sentiment Analysis for Movie Reviews using Neo4j》\n- 《EMNLP上两篇关于股票趋势的应用论文 》\n- 《Learning to Rank for Information Retrieval and Natural Language Processing》\n- 《Geoffrey E. Hinton》\n- 《Andrej Karpathy的深度强化学习演示》 论文在这里\n- 《用大数据和机器学习做股票价格预测》\n- 《机器学习经典算法详解及Python实现--基于SMO的SVM分类器》\n- 《Use Google's Word2Vec for movie reviews》\n- 《深度卷积神经网络下围棋》\n- 《机器学习经典算法详解及Python实现--线性回归（Linear Regression）算法》\n- 《Caffe》\n- 《GoogLeNet深度学习模型的Caffe复现 》 GoogleNet论文\n- 《Deep Learning实战之word2vec》\n- 《A Deep Dive into Recurrent Neural Nets》\n- 《Geoffrey E. Hinton个人主页》\n- 《Deep Learning on Hadoop 2.0》\n- 《美团推荐算法实践》\n- 《The Trouble with SVMs》\n- 《Gaussian Processes for Machine Learning》\n- 《Introduction to ARMA Time Series Models – simplified》\n- 《Neural Net in C++ Tutorial》\n- 《Deep Learning Tutorials》\n- 《Deep Learning, The Curse of Dimensionality, and Autoencoders》\n- 《Topic modeling with LDA: MLlib meets GraphX》\n- 《Deep Learning for Multi-label Classification》\n- 《Google DeepMind publications》  AlphaGo团队官方论文\n- 《AM207: Monte Carlo Methods, Stochastic Optimization》\n- 《Back-to-Basics Weekend Reading - Machine Learning》\n- 《A Probabilistic Theory of Deep Learning》\n- 《How does Quora use machine learning in 2015?》\n- 《Parallel Machine Learning with scikit-learn and IPython》\n- 《Time Series Econometrics - A Concise Course》\n- 《A comparison of open source tools for sentiment analysis》\n- 《International Joint Conference on Artificial Intelligence Accepted paper》\n- 《How to Evaluate Machine Learning Models, Part 1: Orientation》 How to Evaluate Machine Learning Models, Part 2a: Classification Metrics,How to Evaluate Machine Learning Models, Part 2b: Ranking and Regression Metrics.\n- 《Learning scikit-learn: Machine Learning in Python》\n- 《Lightning fast Machine Learning with Spark》\n- 《How we’re using machine learning to fight shell selling》\n- 《Mining of Massive Datasets》\n- 《Advances in Extreme Learning Machines》\n- 《The Curse of Dimensionality in classification》\n- 《Demistifying LSTM Neural Networks》\n- 《Decoding Dimensionality Reduction, PCA and SVD》\n- 《What are the advantages of different classification algorithms?》\n- 《Kaggle R Tutorial on Machine Learning》 《Interactive R Tutorial: Machine Learning for the Titanic Competition》.\n- 《Logistic Regression and Gradient Descent》\n- 《Stock Forecasting With Machine Learning - Seven Possible Errors》\n- 《LR原理解析》  http://www.cnblogs.com/xiaowanyer/p/3701944.html\n- 机器学习顶级会议和杂志 http://icml.cc/2015/?page_id=175\n- 贝耶斯回归材料 http://blog.csdn.net/haoni123321/article/details/37913795\n- 贝耶斯回归材料 http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/ \n- AlphaGo原理解析https://www.youtube.com/watch?v=63FDxJ5e_Ew\n\n","slug":"机器学习相关材料","published":1,"updated":"2016-12-12T05:23:30.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2nac0013yeg3xf19eljt","content":"<p>1、数学基础</p>\n<ul>\n<li>1、微积分 <a href=\"http://v.163.com/special/sp/singlevariablecalculus.html\" target=\"_blank\" rel=\"external\">http://v.163.com/special/sp/singlevariablecalculus.html</a>  <a href=\"http://open.163.com/special/opencourse/multivariable.html\" target=\"_blank\" rel=\"external\">http://open.163.com/special/opencourse/multivariable.html</a></li>\n<li>2、线性代数 <a href=\"http://open.163.com/special/opencourse/daishu.html\" target=\"_blank\" rel=\"external\">http://open.163.com/special/opencourse/daishu.html</a></li>\n<li>3、概率统计<a href=\"http://open.163.com/special/Khan/probability.html\" target=\"_blank\" rel=\"external\">http://open.163.com/special/Khan/probability.html</a><br>想要深入学习机器学习，需要具有扎实的数学基础（矩阵分析和概率统计是基础的理论）</li>\n</ul>\n<p>2、进阶版本数学基础课程</p>\n<ul>\n<li>1、最优化理论（重点凸优化理论）  <a href=\"http://stanford.edu/~boyd/cvxbook/\" target=\"_blank\" rel=\"external\">http://stanford.edu/~boyd/cvxbook/</a>   <a href=\"http://xiaoyc.com/duality-theory-for-optimization/#1-1-lagrangian\" target=\"_blank\" rel=\"external\">http://xiaoyc.com/duality-theory-for-optimization/#1-1-lagrangian</a></li>\n<li>2、时变函数与泛函分析 <a href=\"http://ocw.nctu.edu.tw/course_list.php?page=2&amp;bgid=1&amp;gid=1\" target=\"_blank\" rel=\"external\">http://ocw.nctu.edu.tw/course_list.php?page=2&amp;bgid=1&amp;gid=1</a>  <a href=\"http://open.163.com/special/opencourse/fanhanfenxi.html\" target=\"_blank\" rel=\"external\">http://open.163.com/special/opencourse/fanhanfenxi.html</a></li>\n<li>3、随机过程 Hyperlink: Stochastic Process MIT View the complete course: Discrete Stochastic Processes</li>\n</ul>\n<p>3、机器学习基础课程</p>\n<ul>\n<li>1、Coursera上Andrew Ng Andrew Ng的《机器学习》</li>\n<li>2、林軒田(国立台湾大学) 機器學習基石</li>\n</ul>\n<p>4、机器学习基础课程</p>\n<ul>\n<li>1、 《统计学习方法》李航</li>\n<li>2、 《机器学习导论》</li>\n<li>3、 《PRML》</li>\n<li>4、 《图解机器学习》[日]杉山将</li>\n<li>5、   Machine Learning: A Probabilistic Prespective （Kevin Murphy）</li>\n<li>6、   Pattern Recognition and Machine Learning （Christopher Bishop）</li>\n<li>7、 《Spark机器学习》</li>\n<li>8、 《机器学习实战》</li>\n<li>9、 《贝叶斯思维:统计建模的Python学习法》</li>\n<li>10、Python自然语言处理》</li>\n<li>11、数学之美 （吴军）</li>\n<li>12、Web智能算法 （Haralambos Marmanis, Dmitry Babenko）</li>\n<li>13、集体智慧编程 （Toby Segaran）</li>\n<li>14、推荐系统实践</li>\n<li>15、计算广告学</li>\n</ul>\n<p>5、深度学习（注定将成为最近几年的爆发式增长）</p>\n<ul>\n<li>1、《Deep Learning》<a href=\"http://www.deeplearningbook.org\" target=\"_blank\" rel=\"external\">http://www.deeplearningbook.org</a></li>\n<li>2、  CSDN Blog <a href=\"http://blog.csdn.net/zouxy09/article/details/8775360\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/zouxy09/article/details/8775360</a></li>\n<li>3、《斯坦福大学深度学习教程》<a href=\"http://ufldl.stanford.edu/tutorial\" target=\"_blank\" rel=\"external\">http://ufldl.stanford.edu/tutorial</a></li>\n</ul>\n<p>6、 杂项</p>\n<ul>\n<li>《Choosing a Machine Learning Classifier》</li>\n<li>《An Introduction to Deep Learning: From Perceptrons to Deep Networks》 译文：《<a href=\"http://www.cnblogs.com/xiaowanyer/p/3701944.html》\" target=\"_blank\" rel=\"external\">http://www.cnblogs.com/xiaowanyer/p/3701944.html》</a></li>\n<li>《The LION Way: Machine Learning plus Intelligent Optimization》</li>\n<li>《分布式并行处理的数据》</li>\n<li>《Deep Learning for Natural Language Processing and Related Applications》</li>\n<li>《Neural Networks and Deep Learning》</li>\n<li>《分布式机器学习的故事》</li>\n<li>《Deep Learning 101》</li>\n<li>《Deep learning from the bottom up》</li>\n<li>《Deep Learning（深度学习）学习笔记整理系列》</li>\n<li>《Google Turns To Deep Learning Classification To Fight Web Spam》</li>\n<li>《Deep Learning Sentiment Analysis for Movie Reviews using Neo4j》</li>\n<li>《EMNLP上两篇关于股票趋势的应用论文 》</li>\n<li>《Learning to Rank for Information Retrieval and Natural Language Processing》</li>\n<li>《Geoffrey E. Hinton》</li>\n<li>《Andrej Karpathy的深度强化学习演示》 论文在这里</li>\n<li>《用大数据和机器学习做股票价格预测》</li>\n<li>《机器学习经典算法详解及Python实现–基于SMO的SVM分类器》</li>\n<li>《Use Google’s Word2Vec for movie reviews》</li>\n<li>《深度卷积神经网络下围棋》</li>\n<li>《机器学习经典算法详解及Python实现–线性回归（Linear Regression）算法》</li>\n<li>《Caffe》</li>\n<li>《GoogLeNet深度学习模型的Caffe复现 》 GoogleNet论文</li>\n<li>《Deep Learning实战之word2vec》</li>\n<li>《A Deep Dive into Recurrent Neural Nets》</li>\n<li>《Geoffrey E. Hinton个人主页》</li>\n<li>《Deep Learning on Hadoop 2.0》</li>\n<li>《美团推荐算法实践》</li>\n<li>《The Trouble with SVMs》</li>\n<li>《Gaussian Processes for Machine Learning》</li>\n<li>《Introduction to ARMA Time Series Models – simplified》</li>\n<li>《Neural Net in C++ Tutorial》</li>\n<li>《Deep Learning Tutorials》</li>\n<li>《Deep Learning, The Curse of Dimensionality, and Autoencoders》</li>\n<li>《Topic modeling with LDA: MLlib meets GraphX》</li>\n<li>《Deep Learning for Multi-label Classification》</li>\n<li>《Google DeepMind publications》  AlphaGo团队官方论文</li>\n<li>《AM207: Monte Carlo Methods, Stochastic Optimization》</li>\n<li>《Back-to-Basics Weekend Reading - Machine Learning》</li>\n<li>《A Probabilistic Theory of Deep Learning》</li>\n<li>《How does Quora use machine learning in 2015?》</li>\n<li>《Parallel Machine Learning with scikit-learn and IPython》</li>\n<li>《Time Series Econometrics - A Concise Course》</li>\n<li>《A comparison of open source tools for sentiment analysis》</li>\n<li>《International Joint Conference on Artificial Intelligence Accepted paper》</li>\n<li>《How to Evaluate Machine Learning Models, Part 1: Orientation》 How to Evaluate Machine Learning Models, Part 2a: Classification Metrics,How to Evaluate Machine Learning Models, Part 2b: Ranking and Regression Metrics.</li>\n<li>《Learning scikit-learn: Machine Learning in Python》</li>\n<li>《Lightning fast Machine Learning with Spark》</li>\n<li>《How we’re using machine learning to fight shell selling》</li>\n<li>《Mining of Massive Datasets》</li>\n<li>《Advances in Extreme Learning Machines》</li>\n<li>《The Curse of Dimensionality in classification》</li>\n<li>《Demistifying LSTM Neural Networks》</li>\n<li>《Decoding Dimensionality Reduction, PCA and SVD》</li>\n<li>《What are the advantages of different classification algorithms?》</li>\n<li>《Kaggle R Tutorial on Machine Learning》 《Interactive R Tutorial: Machine Learning for the Titanic Competition》.</li>\n<li>《Logistic Regression and Gradient Descent》</li>\n<li>《Stock Forecasting With Machine Learning - Seven Possible Errors》</li>\n<li>《LR原理解析》  <a href=\"http://www.cnblogs.com/xiaowanyer/p/3701944.html\" target=\"_blank\" rel=\"external\">http://www.cnblogs.com/xiaowanyer/p/3701944.html</a></li>\n<li>机器学习顶级会议和杂志 <a href=\"http://icml.cc/2015/?page_id=175\" target=\"_blank\" rel=\"external\">http://icml.cc/2015/?page_id=175</a></li>\n<li>贝耶斯回归材料 <a href=\"http://blog.csdn.net/haoni123321/article/details/37913795\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/haoni123321/article/details/37913795</a></li>\n<li>贝耶斯回归材料 <a href=\"http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/\" target=\"_blank\" rel=\"external\">http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/</a> </li>\n<li>AlphaGo原理解析<a href=\"https://www.youtube.com/watch?v=63FDxJ5e_Ew\" target=\"_blank\" rel=\"external\">https://www.youtube.com/watch?v=63FDxJ5e_Ew</a></li>\n</ul>\n","excerpt":"","more":"<p>1、数学基础</p>\n<ul>\n<li>1、微积分 <a href=\"http://v.163.com/special/sp/singlevariablecalculus.html\">http://v.163.com/special/sp/singlevariablecalculus.html</a>  <a href=\"http://open.163.com/special/opencourse/multivariable.html\">http://open.163.com/special/opencourse/multivariable.html</a></li>\n<li>2、线性代数 <a href=\"http://open.163.com/special/opencourse/daishu.html\">http://open.163.com/special/opencourse/daishu.html</a></li>\n<li>3、概率统计<a href=\"http://open.163.com/special/Khan/probability.html\">http://open.163.com/special/Khan/probability.html</a><br>想要深入学习机器学习，需要具有扎实的数学基础（矩阵分析和概率统计是基础的理论）</li>\n</ul>\n<p>2、进阶版本数学基础课程</p>\n<ul>\n<li>1、最优化理论（重点凸优化理论）  <a href=\"http://stanford.edu/~boyd/cvxbook/\">http://stanford.edu/~boyd/cvxbook/</a>   <a href=\"http://xiaoyc.com/duality-theory-for-optimization/#1-1-lagrangian\">http://xiaoyc.com/duality-theory-for-optimization/#1-1-lagrangian</a></li>\n<li>2、时变函数与泛函分析 <a href=\"http://ocw.nctu.edu.tw/course_list.php?page=2&amp;bgid=1&amp;gid=1\">http://ocw.nctu.edu.tw/course_list.php?page=2&amp;bgid=1&amp;gid=1</a>  <a href=\"http://open.163.com/special/opencourse/fanhanfenxi.html\">http://open.163.com/special/opencourse/fanhanfenxi.html</a></li>\n<li>3、随机过程 Hyperlink: Stochastic Process MIT View the complete course: Discrete Stochastic Processes</li>\n</ul>\n<p>3、机器学习基础课程</p>\n<ul>\n<li>1、Coursera上Andrew Ng Andrew Ng的《机器学习》</li>\n<li>2、林軒田(国立台湾大学) 機器學習基石</li>\n</ul>\n<p>4、机器学习基础课程</p>\n<ul>\n<li>1、 《统计学习方法》李航</li>\n<li>2、 《机器学习导论》</li>\n<li>3、 《PRML》</li>\n<li>4、 《图解机器学习》[日]杉山将</li>\n<li>5、   Machine Learning: A Probabilistic Prespective （Kevin Murphy）</li>\n<li>6、   Pattern Recognition and Machine Learning （Christopher Bishop）</li>\n<li>7、 《Spark机器学习》</li>\n<li>8、 《机器学习实战》</li>\n<li>9、 《贝叶斯思维:统计建模的Python学习法》</li>\n<li>10、Python自然语言处理》</li>\n<li>11、数学之美 （吴军）</li>\n<li>12、Web智能算法 （Haralambos Marmanis, Dmitry Babenko）</li>\n<li>13、集体智慧编程 （Toby Segaran）</li>\n<li>14、推荐系统实践</li>\n<li>15、计算广告学</li>\n</ul>\n<p>5、深度学习（注定将成为最近几年的爆发式增长）</p>\n<ul>\n<li>1、《Deep Learning》<a href=\"http://www.deeplearningbook.org\">http://www.deeplearningbook.org</a></li>\n<li>2、  CSDN Blog <a href=\"http://blog.csdn.net/zouxy09/article/details/8775360\">http://blog.csdn.net/zouxy09/article/details/8775360</a></li>\n<li>3、《斯坦福大学深度学习教程》<a href=\"http://ufldl.stanford.edu/tutorial\">http://ufldl.stanford.edu/tutorial</a></li>\n</ul>\n<p>6、 杂项</p>\n<ul>\n<li>《Choosing a Machine Learning Classifier》</li>\n<li>《An Introduction to Deep Learning: From Perceptrons to Deep Networks》 译文：《<a href=\"http://www.cnblogs.com/xiaowanyer/p/3701944.html》\">http://www.cnblogs.com/xiaowanyer/p/3701944.html》</a></li>\n<li>《The LION Way: Machine Learning plus Intelligent Optimization》</li>\n<li>《分布式并行处理的数据》</li>\n<li>《Deep Learning for Natural Language Processing and Related Applications》</li>\n<li>《Neural Networks and Deep Learning》</li>\n<li>《分布式机器学习的故事》</li>\n<li>《Deep Learning 101》</li>\n<li>《Deep learning from the bottom up》</li>\n<li>《Deep Learning（深度学习）学习笔记整理系列》</li>\n<li>《Google Turns To Deep Learning Classification To Fight Web Spam》</li>\n<li>《Deep Learning Sentiment Analysis for Movie Reviews using Neo4j》</li>\n<li>《EMNLP上两篇关于股票趋势的应用论文 》</li>\n<li>《Learning to Rank for Information Retrieval and Natural Language Processing》</li>\n<li>《Geoffrey E. Hinton》</li>\n<li>《Andrej Karpathy的深度强化学习演示》 论文在这里</li>\n<li>《用大数据和机器学习做股票价格预测》</li>\n<li>《机器学习经典算法详解及Python实现–基于SMO的SVM分类器》</li>\n<li>《Use Google’s Word2Vec for movie reviews》</li>\n<li>《深度卷积神经网络下围棋》</li>\n<li>《机器学习经典算法详解及Python实现–线性回归（Linear Regression）算法》</li>\n<li>《Caffe》</li>\n<li>《GoogLeNet深度学习模型的Caffe复现 》 GoogleNet论文</li>\n<li>《Deep Learning实战之word2vec》</li>\n<li>《A Deep Dive into Recurrent Neural Nets》</li>\n<li>《Geoffrey E. Hinton个人主页》</li>\n<li>《Deep Learning on Hadoop 2.0》</li>\n<li>《美团推荐算法实践》</li>\n<li>《The Trouble with SVMs》</li>\n<li>《Gaussian Processes for Machine Learning》</li>\n<li>《Introduction to ARMA Time Series Models – simplified》</li>\n<li>《Neural Net in C++ Tutorial》</li>\n<li>《Deep Learning Tutorials》</li>\n<li>《Deep Learning, The Curse of Dimensionality, and Autoencoders》</li>\n<li>《Topic modeling with LDA: MLlib meets GraphX》</li>\n<li>《Deep Learning for Multi-label Classification》</li>\n<li>《Google DeepMind publications》  AlphaGo团队官方论文</li>\n<li>《AM207: Monte Carlo Methods, Stochastic Optimization》</li>\n<li>《Back-to-Basics Weekend Reading - Machine Learning》</li>\n<li>《A Probabilistic Theory of Deep Learning》</li>\n<li>《How does Quora use machine learning in 2015?》</li>\n<li>《Parallel Machine Learning with scikit-learn and IPython》</li>\n<li>《Time Series Econometrics - A Concise Course》</li>\n<li>《A comparison of open source tools for sentiment analysis》</li>\n<li>《International Joint Conference on Artificial Intelligence Accepted paper》</li>\n<li>《How to Evaluate Machine Learning Models, Part 1: Orientation》 How to Evaluate Machine Learning Models, Part 2a: Classification Metrics,How to Evaluate Machine Learning Models, Part 2b: Ranking and Regression Metrics.</li>\n<li>《Learning scikit-learn: Machine Learning in Python》</li>\n<li>《Lightning fast Machine Learning with Spark》</li>\n<li>《How we’re using machine learning to fight shell selling》</li>\n<li>《Mining of Massive Datasets》</li>\n<li>《Advances in Extreme Learning Machines》</li>\n<li>《The Curse of Dimensionality in classification》</li>\n<li>《Demistifying LSTM Neural Networks》</li>\n<li>《Decoding Dimensionality Reduction, PCA and SVD》</li>\n<li>《What are the advantages of different classification algorithms?》</li>\n<li>《Kaggle R Tutorial on Machine Learning》 《Interactive R Tutorial: Machine Learning for the Titanic Competition》.</li>\n<li>《Logistic Regression and Gradient Descent》</li>\n<li>《Stock Forecasting With Machine Learning - Seven Possible Errors》</li>\n<li>《LR原理解析》  <a href=\"http://www.cnblogs.com/xiaowanyer/p/3701944.html\">http://www.cnblogs.com/xiaowanyer/p/3701944.html</a></li>\n<li>机器学习顶级会议和杂志 <a href=\"http://icml.cc/2015/?page_id=175\">http://icml.cc/2015/?page_id=175</a></li>\n<li>贝耶斯回归材料 <a href=\"http://blog.csdn.net/haoni123321/article/details/37913795\">http://blog.csdn.net/haoni123321/article/details/37913795</a></li>\n<li>贝耶斯回归材料 <a href=\"http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/\">http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/</a> </li>\n<li>AlphaGo原理解析<a href=\"https://www.youtube.com/watch?v=63FDxJ5e_Ew\">https://www.youtube.com/watch?v=63FDxJ5e_Ew</a></li>\n</ul>\n"},{"title":"过拟合的原因","date":"2016-07-13T05:46:10.000Z","_content":"# 过拟合产生原因\n\n## 观测数据存在误差\n用于训练的样本数据，即观测数据因为各种个样的原因，总会产生误差。如果选择的假设过分追求能够完美解释观测数据（对于回归问题，可能是拟合曲线“穿过”所有的样本点，或者类似于均方误差过小），都有可能造成过拟合的现象。造成这种现象的根本原因在于，拟合曲线把误差也完美的学习了。\n\n## 产生样本因素很多，但是实际可能只有小部分提取出来\n影响产生观测数据的因素有很多，但是现实中可能仅提取几个和结果相关度很高的因素来进行分析。这个时候观察数据会倾向于围绕你的有限模型的预测结果呈正态分布，于是你实际观察到的结果就是这个正态分布的随机取样，这个取样很可能受到其余因素的影响偏离你的模型所预测的中心，这个时候便不能贪心不足地试图通过改变模型来“完美”匹配数据，因为那些使结果偏离你的预测的贡献因素不是你这个有限模型里面含有的因素所能概括的，硬要打肿脸充胖子只能导致不实际的模型。\n\n## 奥卡姆剃刀法则\n$$\np\\left( h|D\\right )   = p\\left( h\\right ) p\\left( D|h\\right ) \n$$\n高卡姆剃刀法则的含义是如果存在多个假设和观察一致，则应当选择最简单的那一个。最简单的假设意味着$\\left( h\\right)$较大，而与观测一致，意味着似然数值较大，即$p\\left( D|h\\right )$较大。\n\n奥卡姆剃刀法则青睐于先验概率，认为先验较大的模型有较大的优势；最大似然法则认为似然大的模型具有较大的优势；而贝叶斯法则则认为二者乘积决定模型的选择问题。\n\n## 贝叶斯奥卡姆剃刀\n上面的奥卡姆剃刀法则描述的是传统的剃刀法则，主要指先验概率$\\left( h\\right)$,而贝叶斯法奥卡姆剃刀法其实和似然$p\\left( D|h\\right )$上面，即该法则主要衡量的因素是似然本身出现的概率大小。 \n","source":"_posts/过拟合的原因.md","raw":"---\ntitle: 过拟合的原因\ndate: 2016-07-13 13:46:10\ntags:\n---\n# 过拟合产生原因\n\n## 观测数据存在误差\n用于训练的样本数据，即观测数据因为各种个样的原因，总会产生误差。如果选择的假设过分追求能够完美解释观测数据（对于回归问题，可能是拟合曲线“穿过”所有的样本点，或者类似于均方误差过小），都有可能造成过拟合的现象。造成这种现象的根本原因在于，拟合曲线把误差也完美的学习了。\n\n## 产生样本因素很多，但是实际可能只有小部分提取出来\n影响产生观测数据的因素有很多，但是现实中可能仅提取几个和结果相关度很高的因素来进行分析。这个时候观察数据会倾向于围绕你的有限模型的预测结果呈正态分布，于是你实际观察到的结果就是这个正态分布的随机取样，这个取样很可能受到其余因素的影响偏离你的模型所预测的中心，这个时候便不能贪心不足地试图通过改变模型来“完美”匹配数据，因为那些使结果偏离你的预测的贡献因素不是你这个有限模型里面含有的因素所能概括的，硬要打肿脸充胖子只能导致不实际的模型。\n\n## 奥卡姆剃刀法则\n$$\np\\left( h|D\\right )   = p\\left( h\\right ) p\\left( D|h\\right ) \n$$\n高卡姆剃刀法则的含义是如果存在多个假设和观察一致，则应当选择最简单的那一个。最简单的假设意味着$\\left( h\\right)$较大，而与观测一致，意味着似然数值较大，即$p\\left( D|h\\right )$较大。\n\n奥卡姆剃刀法则青睐于先验概率，认为先验较大的模型有较大的优势；最大似然法则认为似然大的模型具有较大的优势；而贝叶斯法则则认为二者乘积决定模型的选择问题。\n\n## 贝叶斯奥卡姆剃刀\n上面的奥卡姆剃刀法则描述的是传统的剃刀法则，主要指先验概率$\\left( h\\right)$,而贝叶斯法奥卡姆剃刀法其实和似然$p\\left( D|h\\right )$上面，即该法则主要衡量的因素是似然本身出现的概率大小。 \n","slug":"过拟合的原因","published":1,"updated":"2016-12-12T05:23:30.961Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2nah0015yeg3snmt2sjm","content":"<h1 id=\"过拟合产生原因\"><a href=\"#过拟合产生原因\" class=\"headerlink\" title=\"过拟合产生原因\"></a>过拟合产生原因</h1><h2 id=\"观测数据存在误差\"><a href=\"#观测数据存在误差\" class=\"headerlink\" title=\"观测数据存在误差\"></a>观测数据存在误差</h2><p>用于训练的样本数据，即观测数据因为各种个样的原因，总会产生误差。如果选择的假设过分追求能够完美解释观测数据（对于回归问题，可能是拟合曲线“穿过”所有的样本点，或者类似于均方误差过小），都有可能造成过拟合的现象。造成这种现象的根本原因在于，拟合曲线把误差也完美的学习了。</p>\n<h2 id=\"产生样本因素很多，但是实际可能只有小部分提取出来\"><a href=\"#产生样本因素很多，但是实际可能只有小部分提取出来\" class=\"headerlink\" title=\"产生样本因素很多，但是实际可能只有小部分提取出来\"></a>产生样本因素很多，但是实际可能只有小部分提取出来</h2><p>影响产生观测数据的因素有很多，但是现实中可能仅提取几个和结果相关度很高的因素来进行分析。这个时候观察数据会倾向于围绕你的有限模型的预测结果呈正态分布，于是你实际观察到的结果就是这个正态分布的随机取样，这个取样很可能受到其余因素的影响偏离你的模型所预测的中心，这个时候便不能贪心不足地试图通过改变模型来“完美”匹配数据，因为那些使结果偏离你的预测的贡献因素不是你这个有限模型里面含有的因素所能概括的，硬要打肿脸充胖子只能导致不实际的模型。</p>\n<h2 id=\"奥卡姆剃刀法则\"><a href=\"#奥卡姆剃刀法则\" class=\"headerlink\" title=\"奥卡姆剃刀法则\"></a>奥卡姆剃刀法则</h2><p>$$<br>p\\left( h|D\\right )   = p\\left( h\\right ) p\\left( D|h\\right )<br>$$<br>高卡姆剃刀法则的含义是如果存在多个假设和观察一致，则应当选择最简单的那一个。最简单的假设意味着$\\left( h\\right)$较大，而与观测一致，意味着似然数值较大，即$p\\left( D|h\\right )$较大。</p>\n<p>奥卡姆剃刀法则青睐于先验概率，认为先验较大的模型有较大的优势；最大似然法则认为似然大的模型具有较大的优势；而贝叶斯法则则认为二者乘积决定模型的选择问题。</p>\n<h2 id=\"贝叶斯奥卡姆剃刀\"><a href=\"#贝叶斯奥卡姆剃刀\" class=\"headerlink\" title=\"贝叶斯奥卡姆剃刀\"></a>贝叶斯奥卡姆剃刀</h2><p>上面的奥卡姆剃刀法则描述的是传统的剃刀法则，主要指先验概率$\\left( h\\right)$,而贝叶斯法奥卡姆剃刀法其实和似然$p\\left( D|h\\right )$上面，即该法则主要衡量的因素是似然本身出现的概率大小。 </p>\n","excerpt":"","more":"<h1 id=\"过拟合产生原因\"><a href=\"#过拟合产生原因\" class=\"headerlink\" title=\"过拟合产生原因\"></a>过拟合产生原因</h1><h2 id=\"观测数据存在误差\"><a href=\"#观测数据存在误差\" class=\"headerlink\" title=\"观测数据存在误差\"></a>观测数据存在误差</h2><p>用于训练的样本数据，即观测数据因为各种个样的原因，总会产生误差。如果选择的假设过分追求能够完美解释观测数据（对于回归问题，可能是拟合曲线“穿过”所有的样本点，或者类似于均方误差过小），都有可能造成过拟合的现象。造成这种现象的根本原因在于，拟合曲线把误差也完美的学习了。</p>\n<h2 id=\"产生样本因素很多，但是实际可能只有小部分提取出来\"><a href=\"#产生样本因素很多，但是实际可能只有小部分提取出来\" class=\"headerlink\" title=\"产生样本因素很多，但是实际可能只有小部分提取出来\"></a>产生样本因素很多，但是实际可能只有小部分提取出来</h2><p>影响产生观测数据的因素有很多，但是现实中可能仅提取几个和结果相关度很高的因素来进行分析。这个时候观察数据会倾向于围绕你的有限模型的预测结果呈正态分布，于是你实际观察到的结果就是这个正态分布的随机取样，这个取样很可能受到其余因素的影响偏离你的模型所预测的中心，这个时候便不能贪心不足地试图通过改变模型来“完美”匹配数据，因为那些使结果偏离你的预测的贡献因素不是你这个有限模型里面含有的因素所能概括的，硬要打肿脸充胖子只能导致不实际的模型。</p>\n<h2 id=\"奥卡姆剃刀法则\"><a href=\"#奥卡姆剃刀法则\" class=\"headerlink\" title=\"奥卡姆剃刀法则\"></a>奥卡姆剃刀法则</h2><p>$$<br>p\\left( h|D\\right )   = p\\left( h\\right ) p\\left( D|h\\right )<br>$$<br>高卡姆剃刀法则的含义是如果存在多个假设和观察一致，则应当选择最简单的那一个。最简单的假设意味着$\\left( h\\right)$较大，而与观测一致，意味着似然数值较大，即$p\\left( D|h\\right )$较大。</p>\n<p>奥卡姆剃刀法则青睐于先验概率，认为先验较大的模型有较大的优势；最大似然法则认为似然大的模型具有较大的优势；而贝叶斯法则则认为二者乘积决定模型的选择问题。</p>\n<h2 id=\"贝叶斯奥卡姆剃刀\"><a href=\"#贝叶斯奥卡姆剃刀\" class=\"headerlink\" title=\"贝叶斯奥卡姆剃刀\"></a>贝叶斯奥卡姆剃刀</h2><p>上面的奥卡姆剃刀法则描述的是传统的剃刀法则，主要指先验概率$\\left( h\\right)$,而贝叶斯法奥卡姆剃刀法其实和似然$p\\left( D|h\\right )$上面，即该法则主要衡量的因素是似然本身出现的概率大小。 </p>\n"},{"title":"SparkDataFrameLikeSql","date":"2016-12-09T08:11:00.000Z","_content":"The idea of spark Datafame may be inspired from dataframe of pandas which is a package of python for structure data processing. On my opinion, dataframe can by prefered by the people with BI(business intelligence) background for high development efficiency.\n\nDataFrame in Spark could by registered as something which could be considered approximately as a virtual table, therefore anyone who has expierence of SQL could explore the data at quite a low cost of time.\n\nThis article will focus on some dataframe processing method without the help of registering a virtual table and executing SQL, however the corresponding SQL operations such as  SELECT, WHERE, GROUPBY, MIN, MAX, COUNT, SUM ,DISTINCT, ORDERBY, DESC/ASC, JOIN and GROUPBY TOP will be supplied for a better understanding of dataframe in spark.\n\n## prepare test data\n\nFirstly we make a DataFrame object a by reading a json file\n```\nval sc: SparkContext // An existing SparkContext.\nval sqlContext = new org.apache.spark.sql.SQLContext(sc)\n// this is used to implicitly convert an RDD to a DataFrame.\nimport sqlContext.implicits._\nval a = sqlContext.read.json(\"people.json\")\n```\nand the content of people.json is as below\n```\n{\"name\":\"Michael\" , \"age\":23 ,\"depart\":\"A\",\"salary\":3000 }\n{\"name\":\"Dan\"     , \"age\":23 ,\"depart\":\"A\",\"salary\":3500 }\n{\"name\":\"Alex\"    , \"age\":23 ,\"depart\":\"A\",\"salary\":3600 }\n{\"name\":\"Ben\"     , \"age\":23 ,\"depart\":\"A\",\"salary\":3700 }\n{\"name\":\"Andy\"    , \"age\":30 ,\"depart\":\"B\",\"salary\":4000 }\n{\"name\":\"Justin\"  , \"age\":19 ,\"depart\":\"A\",\"salary\":5000 }\n{\"name\":\"Jack\"    , \"age\":19 ,\"depart\":\"B\",\"salary\":2000 }\n```\nlet us image a as a Table which is stored in a RDS database such as MySQL.\n\n## desc \n\n```\ndesc people;\n```\n```\nscala> a.printSchema\nroot\n|-- age: long (nullable = true)\n|-- depart: string (nullable = true)\n|-- name: string (nullable = true)\n|-- salary: long (nullable = true)\n```\n\n## SELECT \n```\nselect name from people;\n```\n\n```\na.select(\"name\").show\na.select($\"name\").show\na.select(a(\"name\")).show\n```\nthe three methods above are equivelent.\n\n## WHERE\n```\nselect name,age from people where age = 23\n```\n```\na.select(\"name\", \"age\").where($\"age\"===23).show\na.select(\"name\", \"age\").filter($\"age\"===23).show\n```\n\n## MIN,MAX,SUM,COUNT\n\n```\nselect min(age), max(age), sum(salary), count(age) from people\n```\n\n\n```\na.select(min(\"age\"),max(\"age\"),sum(\"salary\"),count(\"age\")).show\na.agg(min(\"age\"),max(\"age\"),sum(\"salary\"),count(\"age\")).show\n```\nand the result is \n```\n\n+--------+--------+-----------+----------+\n|min(age)|max(age)|sum(salary)|count(age)|\n+--------+--------+-----------+----------+\n|      19|      30|      24800|         7|\n+--------+--------+-----------+----------+\n\n```\n\n## COUNT DISTINCT\n\n```\nselect count (distinct age) , count ( distinct name ) from people\n```\n\n```\na.select(count(\"age\"),countDistinct(\"age\")).show\na.agg(count(\"age\"), countDistinct(\"name\")).show\n```\nand the result is \n```\n+-------------------+--------------------+\n|count(DISTINCT age)|count(DISTINCT name)|\n+-------------------+--------------------+\n|                  7|                   3|\n+-------------------+--------------------+\n```\n\n\n## ORDERBY desc\n```\nselect * from people orderby age desc, name desc\n\n```\n\n```\na.sort($\"age\".desc,$\"name\".desc).show\n```\n```\n+---+------+-------+------+\n|age|depart|   name|salary|\n+---+------+-------+------+\n| 30|     B|   Andy|  4000|\n| 23|     A|Michael|  3000|\n| 23|     A|    Dan|  3500|\n| 23|     A|    Ben|  3700|\n| 23|     A|   Alex|  3600|\n| 19|     A| Justin|  5000|\n| 19|     B|   Jack|  2000|\n+---+------+-------+------+\n```\n\n\n## inner join, left outer join and convert null to a default value \nfirst we make another dataframe based on a \n```\nval c = a.filter(not ($\"age\"===23))\n\nscala> c.show\n+---+------+------+------+\n|age|depart|  name|salary|\n+---+------+------+------+\n| 30|     B|  Andy|  4000|\n| 19|     A|Justin|  5000|\n| 19|     B|  Jack|  2000|\n+---+------+------+------+\n\n```\nnow we try to join a and c \n\n```\n    select \n        a.age as a_age,\n        if(c.age is null, 0, c.age) as c_age,\n        a.depart as a_depart\n    from \n        a\n    left outer join\n        c\n    on \n        a.age = c.age\n```\nthe cording dataframe form is \n```\n\nscala> a.join(c,a(\"age\")===c(\"age\"),\"left\").select(a(\"age\").alias(\"a_age\"),c(\"age\").alias(\"c_age\"),a(\"depart\").alias(\"a_depart\")).na.fill(0,Seq(\"c_age\")).show\n+-----+-----+--------+\n|a_age|c_age|a_depart|\n+-----+-----+--------+\n|   23|    0|       A|\n|   23|    0|       A|\n|   23|    0|       A|\n|   23|    0|       A|\n|   30|   30|       B|\n|   19|   19|       A|\n|   19|   19|       A|\n|   19|   19|       B|\n|   19|   19|       B|\n+-----+-----+--------+\n\n```\nwhat if those records whose c.age is null is execluded \n```\nselect \n    a.age as a_age,\n    if(c.age is null, 0, c.age) as c_age,\n    a.depart as a_depart\nfrom \n    a\nleft outer join\n    c\non \n    a.age = c.age\nwhere \n    c.age is not null\n```\nthe na.drop method provided this function\n```\nscala> a.join(c,a(\"age\")===c(\"age\"),\"left\").select(a(\"age\").alias(\"a_age\"),c(\"age\").alias(\"c_age\"),a(\"depart\").alias(\"a_depart\")).na.drop.show\n+-----+-----+--------+\n|a_age|c_age|a_depart|\n+-----+-----+--------+\n|   30|   30|       B|\n|   19|   19|       A|\n|   19|   19|       A|\n|   19|   19|       B|\n|   19|   19|       B|\n+-----+-----+--------+\n```\n\n## Top N for group \nuse window operation can help \n```\nimport org.apache.spark.sql.expressions.Window\nval w = Window.partitionBy($\"depart\")\nimport org.apache.spark.sql.expressions.Window\nval rankAsc = row_number().over(w.orderBy($\"salary\")).alias(\"rank_asc\")\nval rankDesc = row_number().over(w.orderBy($\"salary\".desc)).alias(\"rank_desc\")\n```\n\n```\nscala> a.select($\"*\", rankAsc, rankDesc).filter($\"rank_asc\"<3 || $\"rank_desc\" >= 2).show\n+---+------+-------+------+--------+---------+\n|age|depart|   name|salary|rank_asc|rank_desc|\n+---+------+-------+------+--------+---------+\n| 30|     B|   Andy|  4000|       2|        1|\n| 19|     B|   Jack|  2000|       1|        2|\n| 23|     A|    Ben|  3700|       4|        2|\n| 23|     A|   Alex|  3600|       3|        3|\n| 23|     A|    Dan|  3500|       2|        4|\n| 23|     A|Michael|  3000|       1|        5|\n+---+------+-------+------+--------+---------+\nscala> a.select($\"*\", rankAsc, rankDesc).filter($\"rank_asc\"<3 && $\"rank_desc\" >= 2).show\n+---+------+-------+------+--------+---------+\n|age|depart|   name|salary|rank_asc|rank_desc|\n+---+------+-------+------+--------+---------+\n| 19|     B|   Jack|  2000|       1|        2|\n| 23|     A|    Dan|  3500|       2|        4|\n| 23|     A|Michael|  3000|       1|        5|\n+---+------+-------+------+--------+---------+\n```\nwhat's more, it is clearly ```select *``` in SQL could by implemented by ```select($\"*\")```\n","source":"_posts/SparkDataFrameLikeSql.md","raw":"---\ntitle: SparkDataFrameLikeSql\ndate: 2016-12-09 16:11:00\ntags: Spark DataFrame\n---\nThe idea of spark Datafame may be inspired from dataframe of pandas which is a package of python for structure data processing. On my opinion, dataframe can by prefered by the people with BI(business intelligence) background for high development efficiency.\n\nDataFrame in Spark could by registered as something which could be considered approximately as a virtual table, therefore anyone who has expierence of SQL could explore the data at quite a low cost of time.\n\nThis article will focus on some dataframe processing method without the help of registering a virtual table and executing SQL, however the corresponding SQL operations such as  SELECT, WHERE, GROUPBY, MIN, MAX, COUNT, SUM ,DISTINCT, ORDERBY, DESC/ASC, JOIN and GROUPBY TOP will be supplied for a better understanding of dataframe in spark.\n\n## prepare test data\n\nFirstly we make a DataFrame object a by reading a json file\n```\nval sc: SparkContext // An existing SparkContext.\nval sqlContext = new org.apache.spark.sql.SQLContext(sc)\n// this is used to implicitly convert an RDD to a DataFrame.\nimport sqlContext.implicits._\nval a = sqlContext.read.json(\"people.json\")\n```\nand the content of people.json is as below\n```\n{\"name\":\"Michael\" , \"age\":23 ,\"depart\":\"A\",\"salary\":3000 }\n{\"name\":\"Dan\"     , \"age\":23 ,\"depart\":\"A\",\"salary\":3500 }\n{\"name\":\"Alex\"    , \"age\":23 ,\"depart\":\"A\",\"salary\":3600 }\n{\"name\":\"Ben\"     , \"age\":23 ,\"depart\":\"A\",\"salary\":3700 }\n{\"name\":\"Andy\"    , \"age\":30 ,\"depart\":\"B\",\"salary\":4000 }\n{\"name\":\"Justin\"  , \"age\":19 ,\"depart\":\"A\",\"salary\":5000 }\n{\"name\":\"Jack\"    , \"age\":19 ,\"depart\":\"B\",\"salary\":2000 }\n```\nlet us image a as a Table which is stored in a RDS database such as MySQL.\n\n## desc \n\n```\ndesc people;\n```\n```\nscala> a.printSchema\nroot\n|-- age: long (nullable = true)\n|-- depart: string (nullable = true)\n|-- name: string (nullable = true)\n|-- salary: long (nullable = true)\n```\n\n## SELECT \n```\nselect name from people;\n```\n\n```\na.select(\"name\").show\na.select($\"name\").show\na.select(a(\"name\")).show\n```\nthe three methods above are equivelent.\n\n## WHERE\n```\nselect name,age from people where age = 23\n```\n```\na.select(\"name\", \"age\").where($\"age\"===23).show\na.select(\"name\", \"age\").filter($\"age\"===23).show\n```\n\n## MIN,MAX,SUM,COUNT\n\n```\nselect min(age), max(age), sum(salary), count(age) from people\n```\n\n\n```\na.select(min(\"age\"),max(\"age\"),sum(\"salary\"),count(\"age\")).show\na.agg(min(\"age\"),max(\"age\"),sum(\"salary\"),count(\"age\")).show\n```\nand the result is \n```\n\n+--------+--------+-----------+----------+\n|min(age)|max(age)|sum(salary)|count(age)|\n+--------+--------+-----------+----------+\n|      19|      30|      24800|         7|\n+--------+--------+-----------+----------+\n\n```\n\n## COUNT DISTINCT\n\n```\nselect count (distinct age) , count ( distinct name ) from people\n```\n\n```\na.select(count(\"age\"),countDistinct(\"age\")).show\na.agg(count(\"age\"), countDistinct(\"name\")).show\n```\nand the result is \n```\n+-------------------+--------------------+\n|count(DISTINCT age)|count(DISTINCT name)|\n+-------------------+--------------------+\n|                  7|                   3|\n+-------------------+--------------------+\n```\n\n\n## ORDERBY desc\n```\nselect * from people orderby age desc, name desc\n\n```\n\n```\na.sort($\"age\".desc,$\"name\".desc).show\n```\n```\n+---+------+-------+------+\n|age|depart|   name|salary|\n+---+------+-------+------+\n| 30|     B|   Andy|  4000|\n| 23|     A|Michael|  3000|\n| 23|     A|    Dan|  3500|\n| 23|     A|    Ben|  3700|\n| 23|     A|   Alex|  3600|\n| 19|     A| Justin|  5000|\n| 19|     B|   Jack|  2000|\n+---+------+-------+------+\n```\n\n\n## inner join, left outer join and convert null to a default value \nfirst we make another dataframe based on a \n```\nval c = a.filter(not ($\"age\"===23))\n\nscala> c.show\n+---+------+------+------+\n|age|depart|  name|salary|\n+---+------+------+------+\n| 30|     B|  Andy|  4000|\n| 19|     A|Justin|  5000|\n| 19|     B|  Jack|  2000|\n+---+------+------+------+\n\n```\nnow we try to join a and c \n\n```\n    select \n        a.age as a_age,\n        if(c.age is null, 0, c.age) as c_age,\n        a.depart as a_depart\n    from \n        a\n    left outer join\n        c\n    on \n        a.age = c.age\n```\nthe cording dataframe form is \n```\n\nscala> a.join(c,a(\"age\")===c(\"age\"),\"left\").select(a(\"age\").alias(\"a_age\"),c(\"age\").alias(\"c_age\"),a(\"depart\").alias(\"a_depart\")).na.fill(0,Seq(\"c_age\")).show\n+-----+-----+--------+\n|a_age|c_age|a_depart|\n+-----+-----+--------+\n|   23|    0|       A|\n|   23|    0|       A|\n|   23|    0|       A|\n|   23|    0|       A|\n|   30|   30|       B|\n|   19|   19|       A|\n|   19|   19|       A|\n|   19|   19|       B|\n|   19|   19|       B|\n+-----+-----+--------+\n\n```\nwhat if those records whose c.age is null is execluded \n```\nselect \n    a.age as a_age,\n    if(c.age is null, 0, c.age) as c_age,\n    a.depart as a_depart\nfrom \n    a\nleft outer join\n    c\non \n    a.age = c.age\nwhere \n    c.age is not null\n```\nthe na.drop method provided this function\n```\nscala> a.join(c,a(\"age\")===c(\"age\"),\"left\").select(a(\"age\").alias(\"a_age\"),c(\"age\").alias(\"c_age\"),a(\"depart\").alias(\"a_depart\")).na.drop.show\n+-----+-----+--------+\n|a_age|c_age|a_depart|\n+-----+-----+--------+\n|   30|   30|       B|\n|   19|   19|       A|\n|   19|   19|       A|\n|   19|   19|       B|\n|   19|   19|       B|\n+-----+-----+--------+\n```\n\n## Top N for group \nuse window operation can help \n```\nimport org.apache.spark.sql.expressions.Window\nval w = Window.partitionBy($\"depart\")\nimport org.apache.spark.sql.expressions.Window\nval rankAsc = row_number().over(w.orderBy($\"salary\")).alias(\"rank_asc\")\nval rankDesc = row_number().over(w.orderBy($\"salary\".desc)).alias(\"rank_desc\")\n```\n\n```\nscala> a.select($\"*\", rankAsc, rankDesc).filter($\"rank_asc\"<3 || $\"rank_desc\" >= 2).show\n+---+------+-------+------+--------+---------+\n|age|depart|   name|salary|rank_asc|rank_desc|\n+---+------+-------+------+--------+---------+\n| 30|     B|   Andy|  4000|       2|        1|\n| 19|     B|   Jack|  2000|       1|        2|\n| 23|     A|    Ben|  3700|       4|        2|\n| 23|     A|   Alex|  3600|       3|        3|\n| 23|     A|    Dan|  3500|       2|        4|\n| 23|     A|Michael|  3000|       1|        5|\n+---+------+-------+------+--------+---------+\nscala> a.select($\"*\", rankAsc, rankDesc).filter($\"rank_asc\"<3 && $\"rank_desc\" >= 2).show\n+---+------+-------+------+--------+---------+\n|age|depart|   name|salary|rank_asc|rank_desc|\n+---+------+-------+------+--------+---------+\n| 19|     B|   Jack|  2000|       1|        2|\n| 23|     A|    Dan|  3500|       2|        4|\n| 23|     A|Michael|  3000|       1|        5|\n+---+------+-------+------+--------+---------+\n```\nwhat's more, it is clearly ```select *``` in SQL could by implemented by ```select($\"*\")```\n","slug":"SparkDataFrameLikeSql","published":1,"updated":"2016-12-22T10:33:58.946Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2nam0017yeg3au5zwog2","content":"<p>The idea of spark Datafame may be inspired from dataframe of pandas which is a package of python for structure data processing. On my opinion, dataframe can by prefered by the people with BI(business intelligence) background for high development efficiency.</p>\n<p>DataFrame in Spark could by registered as something which could be considered approximately as a virtual table, therefore anyone who has expierence of SQL could explore the data at quite a low cost of time.</p>\n<p>This article will focus on some dataframe processing method without the help of registering a virtual table and executing SQL, however the corresponding SQL operations such as  SELECT, WHERE, GROUPBY, MIN, MAX, COUNT, SUM ,DISTINCT, ORDERBY, DESC/ASC, JOIN and GROUPBY TOP will be supplied for a better understanding of dataframe in spark.</p>\n<h2 id=\"prepare-test-data\"><a href=\"#prepare-test-data\" class=\"headerlink\" title=\"prepare test data\"></a>prepare test data</h2><p>Firstly we make a DataFrame object a by reading a json file<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val sc: SparkContext // An existing SparkContext.</span><br><span class=\"line\">val sqlContext = new org.apache.spark.sql.SQLContext(sc)</span><br><span class=\"line\">// this is used to implicitly convert an RDD to a DataFrame.</span><br><span class=\"line\">import sqlContext.implicits._</span><br><span class=\"line\">val a = sqlContext.read.json(&quot;people.json&quot;)</span><br></pre></td></tr></table></figure></p>\n<p>and the content of people.json is as below<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;name&quot;:&quot;Michael&quot; , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3000 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Dan&quot;     , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3500 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Alex&quot;    , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3600 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Ben&quot;     , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3700 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Andy&quot;    , &quot;age&quot;:30 ,&quot;depart&quot;:&quot;B&quot;,&quot;salary&quot;:4000 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Justin&quot;  , &quot;age&quot;:19 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:5000 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Jack&quot;    , &quot;age&quot;:19 ,&quot;depart&quot;:&quot;B&quot;,&quot;salary&quot;:2000 &#125;</span><br></pre></td></tr></table></figure></p>\n<p>let us image a as a Table which is stored in a RDS database such as MySQL.</p>\n<h2 id=\"desc\"><a href=\"#desc\" class=\"headerlink\" title=\"desc\"></a>desc</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">desc people;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scala&gt; a.printSchema</span><br><span class=\"line\">root</span><br><span class=\"line\">|-- age: long (nullable = true)</span><br><span class=\"line\">|-- depart: string (nullable = true)</span><br><span class=\"line\">|-- name: string (nullable = true)</span><br><span class=\"line\">|-- salary: long (nullable = true)</span><br></pre></td></tr></table></figure>\n<h2 id=\"SELECT\"><a href=\"#SELECT\" class=\"headerlink\" title=\"SELECT\"></a>SELECT</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select name from people;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.select(&quot;name&quot;).show</span><br><span class=\"line\">a.select($&quot;name&quot;).show</span><br><span class=\"line\">a.select(a(&quot;name&quot;)).show</span><br></pre></td></tr></table></figure>\n<p>the three methods above are equivelent.</p>\n<h2 id=\"WHERE\"><a href=\"#WHERE\" class=\"headerlink\" title=\"WHERE\"></a>WHERE</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select name,age from people where age = 23</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.select(&quot;name&quot;, &quot;age&quot;).where($&quot;age&quot;===23).show</span><br><span class=\"line\">a.select(&quot;name&quot;, &quot;age&quot;).filter($&quot;age&quot;===23).show</span><br></pre></td></tr></table></figure>\n<h2 id=\"MIN-MAX-SUM-COUNT\"><a href=\"#MIN-MAX-SUM-COUNT\" class=\"headerlink\" title=\"MIN,MAX,SUM,COUNT\"></a>MIN,MAX,SUM,COUNT</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select min(age), max(age), sum(salary), count(age) from people</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.select(min(&quot;age&quot;),max(&quot;age&quot;),sum(&quot;salary&quot;),count(&quot;age&quot;)).show</span><br><span class=\"line\">a.agg(min(&quot;age&quot;),max(&quot;age&quot;),sum(&quot;salary&quot;),count(&quot;age&quot;)).show</span><br></pre></td></tr></table></figure>\n<p>and the result is<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">+--------+--------+-----------+----------+</span><br><span class=\"line\">|min(age)|max(age)|sum(salary)|count(age)|</span><br><span class=\"line\">+--------+--------+-----------+----------+</span><br><span class=\"line\">|      19|      30|      24800|         7|</span><br><span class=\"line\">+--------+--------+-----------+----------+</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"COUNT-DISTINCT\"><a href=\"#COUNT-DISTINCT\" class=\"headerlink\" title=\"COUNT DISTINCT\"></a>COUNT DISTINCT</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select count (distinct age) , count ( distinct name ) from people</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.select(count(&quot;age&quot;),countDistinct(&quot;age&quot;)).show</span><br><span class=\"line\">a.agg(count(&quot;age&quot;), countDistinct(&quot;name&quot;)).show</span><br></pre></td></tr></table></figure>\n<p>and the result is<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+-------------------+--------------------+</span><br><span class=\"line\">|count(DISTINCT age)|count(DISTINCT name)|</span><br><span class=\"line\">+-------------------+--------------------+</span><br><span class=\"line\">|                  7|                   3|</span><br><span class=\"line\">+-------------------+--------------------+</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"ORDERBY-desc\"><a href=\"#ORDERBY-desc\" class=\"headerlink\" title=\"ORDERBY desc\"></a>ORDERBY desc</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * from people orderby age desc, name desc</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.sort($&quot;age&quot;.desc,$&quot;name&quot;.desc).show</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+---+------+-------+------+</span><br><span class=\"line\">|age|depart|   name|salary|</span><br><span class=\"line\">+---+------+-------+------+</span><br><span class=\"line\">| 30|     B|   Andy|  4000|</span><br><span class=\"line\">| 23|     A|Michael|  3000|</span><br><span class=\"line\">| 23|     A|    Dan|  3500|</span><br><span class=\"line\">| 23|     A|    Ben|  3700|</span><br><span class=\"line\">| 23|     A|   Alex|  3600|</span><br><span class=\"line\">| 19|     A| Justin|  5000|</span><br><span class=\"line\">| 19|     B|   Jack|  2000|</span><br><span class=\"line\">+---+------+-------+------+</span><br></pre></td></tr></table></figure>\n<h2 id=\"inner-join-left-outer-join-and-convert-null-to-a-default-value\"><a href=\"#inner-join-left-outer-join-and-convert-null-to-a-default-value\" class=\"headerlink\" title=\"inner join, left outer join and convert null to a default value\"></a>inner join, left outer join and convert null to a default value</h2><p>first we make another dataframe based on a<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val c = a.filter(not ($&quot;age&quot;===23))</span><br><span class=\"line\"></span><br><span class=\"line\">scala&gt; c.show</span><br><span class=\"line\">+---+------+------+------+</span><br><span class=\"line\">|age|depart|  name|salary|</span><br><span class=\"line\">+---+------+------+------+</span><br><span class=\"line\">| 30|     B|  Andy|  4000|</span><br><span class=\"line\">| 19|     A|Justin|  5000|</span><br><span class=\"line\">| 19|     B|  Jack|  2000|</span><br><span class=\"line\">+---+------+------+------+</span><br></pre></td></tr></table></figure></p>\n<p>now we try to join a and c </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select </span><br><span class=\"line\">    a.age as a_age,</span><br><span class=\"line\">    if(c.age is null, 0, c.age) as c_age,</span><br><span class=\"line\">    a.depart as a_depart</span><br><span class=\"line\">from </span><br><span class=\"line\">    a</span><br><span class=\"line\">left outer join</span><br><span class=\"line\">    c</span><br><span class=\"line\">on </span><br><span class=\"line\">    a.age = c.age</span><br></pre></td></tr></table></figure>\n<p>the cording dataframe form is<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">scala&gt; a.join(c,a(&quot;age&quot;)===c(&quot;age&quot;),&quot;left&quot;).select(a(&quot;age&quot;).alias(&quot;a_age&quot;),c(&quot;age&quot;).alias(&quot;c_age&quot;),a(&quot;depart&quot;).alias(&quot;a_depart&quot;)).na.fill(0,Seq(&quot;c_age&quot;)).show</span><br><span class=\"line\">+-----+-----+--------+</span><br><span class=\"line\">|a_age|c_age|a_depart|</span><br><span class=\"line\">+-----+-----+--------+</span><br><span class=\"line\">|   23|    0|       A|</span><br><span class=\"line\">|   23|    0|       A|</span><br><span class=\"line\">|   23|    0|       A|</span><br><span class=\"line\">|   23|    0|       A|</span><br><span class=\"line\">|   30|   30|       B|</span><br><span class=\"line\">|   19|   19|       A|</span><br><span class=\"line\">|   19|   19|       A|</span><br><span class=\"line\">|   19|   19|       B|</span><br><span class=\"line\">|   19|   19|       B|</span><br><span class=\"line\">+-----+-----+--------+</span><br></pre></td></tr></table></figure></p>\n<p>what if those records whose c.age is null is execluded<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select </span><br><span class=\"line\">    a.age as a_age,</span><br><span class=\"line\">    if(c.age is null, 0, c.age) as c_age,</span><br><span class=\"line\">    a.depart as a_depart</span><br><span class=\"line\">from </span><br><span class=\"line\">    a</span><br><span class=\"line\">left outer join</span><br><span class=\"line\">    c</span><br><span class=\"line\">on </span><br><span class=\"line\">    a.age = c.age</span><br><span class=\"line\">where </span><br><span class=\"line\">    c.age is not null</span><br></pre></td></tr></table></figure></p>\n<p>the na.drop method provided this function<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scala&gt; a.join(c,a(&quot;age&quot;)===c(&quot;age&quot;),&quot;left&quot;).select(a(&quot;age&quot;).alias(&quot;a_age&quot;),c(&quot;age&quot;).alias(&quot;c_age&quot;),a(&quot;depart&quot;).alias(&quot;a_depart&quot;)).na.drop.show</span><br><span class=\"line\">+-----+-----+--------+</span><br><span class=\"line\">|a_age|c_age|a_depart|</span><br><span class=\"line\">+-----+-----+--------+</span><br><span class=\"line\">|   30|   30|       B|</span><br><span class=\"line\">|   19|   19|       A|</span><br><span class=\"line\">|   19|   19|       A|</span><br><span class=\"line\">|   19|   19|       B|</span><br><span class=\"line\">|   19|   19|       B|</span><br><span class=\"line\">+-----+-----+--------+</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Top-N-for-group\"><a href=\"#Top-N-for-group\" class=\"headerlink\" title=\"Top N for group\"></a>Top N for group</h2><p>use window operation can help<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import org.apache.spark.sql.expressions.Window</span><br><span class=\"line\">val w = Window.partitionBy($&quot;depart&quot;)</span><br><span class=\"line\">import org.apache.spark.sql.expressions.Window</span><br><span class=\"line\">val rankAsc = row_number().over(w.orderBy($&quot;salary&quot;)).alias(&quot;rank_asc&quot;)</span><br><span class=\"line\">val rankDesc = row_number().over(w.orderBy($&quot;salary&quot;.desc)).alias(&quot;rank_desc&quot;)</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scala&gt; a.select($&quot;*&quot;, rankAsc, rankDesc).filter($&quot;rank_asc&quot;&lt;3 || $&quot;rank_desc&quot; &gt;= 2).show</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br><span class=\"line\">|age|depart|   name|salary|rank_asc|rank_desc|</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br><span class=\"line\">| 30|     B|   Andy|  4000|       2|        1|</span><br><span class=\"line\">| 19|     B|   Jack|  2000|       1|        2|</span><br><span class=\"line\">| 23|     A|    Ben|  3700|       4|        2|</span><br><span class=\"line\">| 23|     A|   Alex|  3600|       3|        3|</span><br><span class=\"line\">| 23|     A|    Dan|  3500|       2|        4|</span><br><span class=\"line\">| 23|     A|Michael|  3000|       1|        5|</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br><span class=\"line\">scala&gt; a.select($&quot;*&quot;, rankAsc, rankDesc).filter($&quot;rank_asc&quot;&lt;3 &amp;&amp; $&quot;rank_desc&quot; &gt;= 2).show</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br><span class=\"line\">|age|depart|   name|salary|rank_asc|rank_desc|</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br><span class=\"line\">| 19|     B|   Jack|  2000|       1|        2|</span><br><span class=\"line\">| 23|     A|    Dan|  3500|       2|        4|</span><br><span class=\"line\">| 23|     A|Michael|  3000|       1|        5|</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br></pre></td></tr></table></figure>\n<p>what’s more, it is clearly <code>select *</code> in SQL could by implemented by <code>select($&quot;*&quot;)</code></p>\n","excerpt":"","more":"<p>The idea of spark Datafame may be inspired from dataframe of pandas which is a package of python for structure data processing. On my opinion, dataframe can by prefered by the people with BI(business intelligence) background for high development efficiency.</p>\n<p>DataFrame in Spark could by registered as something which could be considered approximately as a virtual table, therefore anyone who has expierence of SQL could explore the data at quite a low cost of time.</p>\n<p>This article will focus on some dataframe processing method without the help of registering a virtual table and executing SQL, however the corresponding SQL operations such as  SELECT, WHERE, GROUPBY, MIN, MAX, COUNT, SUM ,DISTINCT, ORDERBY, DESC/ASC, JOIN and GROUPBY TOP will be supplied for a better understanding of dataframe in spark.</p>\n<h2 id=\"prepare-test-data\"><a href=\"#prepare-test-data\" class=\"headerlink\" title=\"prepare test data\"></a>prepare test data</h2><p>Firstly we make a DataFrame object a by reading a json file<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val sc: SparkContext // An existing SparkContext.</span><br><span class=\"line\">val sqlContext = new org.apache.spark.sql.SQLContext(sc)</span><br><span class=\"line\">// this is used to implicitly convert an RDD to a DataFrame.</span><br><span class=\"line\">import sqlContext.implicits._</span><br><span class=\"line\">val a = sqlContext.read.json(&quot;people.json&quot;)</span><br></pre></td></tr></table></figure></p>\n<p>and the content of people.json is as below<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;name&quot;:&quot;Michael&quot; , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3000 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Dan&quot;     , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3500 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Alex&quot;    , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3600 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Ben&quot;     , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3700 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Andy&quot;    , &quot;age&quot;:30 ,&quot;depart&quot;:&quot;B&quot;,&quot;salary&quot;:4000 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Justin&quot;  , &quot;age&quot;:19 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:5000 &#125;</span><br><span class=\"line\">&#123;&quot;name&quot;:&quot;Jack&quot;    , &quot;age&quot;:19 ,&quot;depart&quot;:&quot;B&quot;,&quot;salary&quot;:2000 &#125;</span><br></pre></td></tr></table></figure></p>\n<p>let us image a as a Table which is stored in a RDS database such as MySQL.</p>\n<h2 id=\"desc\"><a href=\"#desc\" class=\"headerlink\" title=\"desc\"></a>desc</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">desc people;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scala&gt; a.printSchema</span><br><span class=\"line\">root</span><br><span class=\"line\">|-- age: long (nullable = true)</span><br><span class=\"line\">|-- depart: string (nullable = true)</span><br><span class=\"line\">|-- name: string (nullable = true)</span><br><span class=\"line\">|-- salary: long (nullable = true)</span><br></pre></td></tr></table></figure>\n<h2 id=\"SELECT\"><a href=\"#SELECT\" class=\"headerlink\" title=\"SELECT\"></a>SELECT</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select name from people;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.select(&quot;name&quot;).show</span><br><span class=\"line\">a.select($&quot;name&quot;).show</span><br><span class=\"line\">a.select(a(&quot;name&quot;)).show</span><br></pre></td></tr></table></figure>\n<p>the three methods above are equivelent.</p>\n<h2 id=\"WHERE\"><a href=\"#WHERE\" class=\"headerlink\" title=\"WHERE\"></a>WHERE</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select name,age from people where age = 23</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.select(&quot;name&quot;, &quot;age&quot;).where($&quot;age&quot;===23).show</span><br><span class=\"line\">a.select(&quot;name&quot;, &quot;age&quot;).filter($&quot;age&quot;===23).show</span><br></pre></td></tr></table></figure>\n<h2 id=\"MIN-MAX-SUM-COUNT\"><a href=\"#MIN-MAX-SUM-COUNT\" class=\"headerlink\" title=\"MIN,MAX,SUM,COUNT\"></a>MIN,MAX,SUM,COUNT</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select min(age), max(age), sum(salary), count(age) from people</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.select(min(&quot;age&quot;),max(&quot;age&quot;),sum(&quot;salary&quot;),count(&quot;age&quot;)).show</span><br><span class=\"line\">a.agg(min(&quot;age&quot;),max(&quot;age&quot;),sum(&quot;salary&quot;),count(&quot;age&quot;)).show</span><br></pre></td></tr></table></figure>\n<p>and the result is<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">+--------+--------+-----------+----------+</span><br><span class=\"line\">|min(age)|max(age)|sum(salary)|count(age)|</span><br><span class=\"line\">+--------+--------+-----------+----------+</span><br><span class=\"line\">|      19|      30|      24800|         7|</span><br><span class=\"line\">+--------+--------+-----------+----------+</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"COUNT-DISTINCT\"><a href=\"#COUNT-DISTINCT\" class=\"headerlink\" title=\"COUNT DISTINCT\"></a>COUNT DISTINCT</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select count (distinct age) , count ( distinct name ) from people</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.select(count(&quot;age&quot;),countDistinct(&quot;age&quot;)).show</span><br><span class=\"line\">a.agg(count(&quot;age&quot;), countDistinct(&quot;name&quot;)).show</span><br></pre></td></tr></table></figure>\n<p>and the result is<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+-------------------+--------------------+</span><br><span class=\"line\">|count(DISTINCT age)|count(DISTINCT name)|</span><br><span class=\"line\">+-------------------+--------------------+</span><br><span class=\"line\">|                  7|                   3|</span><br><span class=\"line\">+-------------------+--------------------+</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"ORDERBY-desc\"><a href=\"#ORDERBY-desc\" class=\"headerlink\" title=\"ORDERBY desc\"></a>ORDERBY desc</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * from people orderby age desc, name desc</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.sort($&quot;age&quot;.desc,$&quot;name&quot;.desc).show</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+---+------+-------+------+</span><br><span class=\"line\">|age|depart|   name|salary|</span><br><span class=\"line\">+---+------+-------+------+</span><br><span class=\"line\">| 30|     B|   Andy|  4000|</span><br><span class=\"line\">| 23|     A|Michael|  3000|</span><br><span class=\"line\">| 23|     A|    Dan|  3500|</span><br><span class=\"line\">| 23|     A|    Ben|  3700|</span><br><span class=\"line\">| 23|     A|   Alex|  3600|</span><br><span class=\"line\">| 19|     A| Justin|  5000|</span><br><span class=\"line\">| 19|     B|   Jack|  2000|</span><br><span class=\"line\">+---+------+-------+------+</span><br></pre></td></tr></table></figure>\n<h2 id=\"inner-join-left-outer-join-and-convert-null-to-a-default-value\"><a href=\"#inner-join-left-outer-join-and-convert-null-to-a-default-value\" class=\"headerlink\" title=\"inner join, left outer join and convert null to a default value\"></a>inner join, left outer join and convert null to a default value</h2><p>first we make another dataframe based on a<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val c = a.filter(not ($&quot;age&quot;===23))</span><br><span class=\"line\"></span><br><span class=\"line\">scala&gt; c.show</span><br><span class=\"line\">+---+------+------+------+</span><br><span class=\"line\">|age|depart|  name|salary|</span><br><span class=\"line\">+---+------+------+------+</span><br><span class=\"line\">| 30|     B|  Andy|  4000|</span><br><span class=\"line\">| 19|     A|Justin|  5000|</span><br><span class=\"line\">| 19|     B|  Jack|  2000|</span><br><span class=\"line\">+---+------+------+------+</span><br></pre></td></tr></table></figure></p>\n<p>now we try to join a and c </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select </span><br><span class=\"line\">    a.age as a_age,</span><br><span class=\"line\">    if(c.age is null, 0, c.age) as c_age,</span><br><span class=\"line\">    a.depart as a_depart</span><br><span class=\"line\">from </span><br><span class=\"line\">    a</span><br><span class=\"line\">left outer join</span><br><span class=\"line\">    c</span><br><span class=\"line\">on </span><br><span class=\"line\">    a.age = c.age</span><br></pre></td></tr></table></figure>\n<p>the cording dataframe form is<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">scala&gt; a.join(c,a(&quot;age&quot;)===c(&quot;age&quot;),&quot;left&quot;).select(a(&quot;age&quot;).alias(&quot;a_age&quot;),c(&quot;age&quot;).alias(&quot;c_age&quot;),a(&quot;depart&quot;).alias(&quot;a_depart&quot;)).na.fill(0,Seq(&quot;c_age&quot;)).show</span><br><span class=\"line\">+-----+-----+--------+</span><br><span class=\"line\">|a_age|c_age|a_depart|</span><br><span class=\"line\">+-----+-----+--------+</span><br><span class=\"line\">|   23|    0|       A|</span><br><span class=\"line\">|   23|    0|       A|</span><br><span class=\"line\">|   23|    0|       A|</span><br><span class=\"line\">|   23|    0|       A|</span><br><span class=\"line\">|   30|   30|       B|</span><br><span class=\"line\">|   19|   19|       A|</span><br><span class=\"line\">|   19|   19|       A|</span><br><span class=\"line\">|   19|   19|       B|</span><br><span class=\"line\">|   19|   19|       B|</span><br><span class=\"line\">+-----+-----+--------+</span><br></pre></td></tr></table></figure></p>\n<p>what if those records whose c.age is null is execluded<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select </span><br><span class=\"line\">    a.age as a_age,</span><br><span class=\"line\">    if(c.age is null, 0, c.age) as c_age,</span><br><span class=\"line\">    a.depart as a_depart</span><br><span class=\"line\">from </span><br><span class=\"line\">    a</span><br><span class=\"line\">left outer join</span><br><span class=\"line\">    c</span><br><span class=\"line\">on </span><br><span class=\"line\">    a.age = c.age</span><br><span class=\"line\">where </span><br><span class=\"line\">    c.age is not null</span><br></pre></td></tr></table></figure></p>\n<p>the na.drop method provided this function<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scala&gt; a.join(c,a(&quot;age&quot;)===c(&quot;age&quot;),&quot;left&quot;).select(a(&quot;age&quot;).alias(&quot;a_age&quot;),c(&quot;age&quot;).alias(&quot;c_age&quot;),a(&quot;depart&quot;).alias(&quot;a_depart&quot;)).na.drop.show</span><br><span class=\"line\">+-----+-----+--------+</span><br><span class=\"line\">|a_age|c_age|a_depart|</span><br><span class=\"line\">+-----+-----+--------+</span><br><span class=\"line\">|   30|   30|       B|</span><br><span class=\"line\">|   19|   19|       A|</span><br><span class=\"line\">|   19|   19|       A|</span><br><span class=\"line\">|   19|   19|       B|</span><br><span class=\"line\">|   19|   19|       B|</span><br><span class=\"line\">+-----+-----+--------+</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Top-N-for-group\"><a href=\"#Top-N-for-group\" class=\"headerlink\" title=\"Top N for group\"></a>Top N for group</h2><p>use window operation can help<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import org.apache.spark.sql.expressions.Window</span><br><span class=\"line\">val w = Window.partitionBy($&quot;depart&quot;)</span><br><span class=\"line\">import org.apache.spark.sql.expressions.Window</span><br><span class=\"line\">val rankAsc = row_number().over(w.orderBy($&quot;salary&quot;)).alias(&quot;rank_asc&quot;)</span><br><span class=\"line\">val rankDesc = row_number().over(w.orderBy($&quot;salary&quot;.desc)).alias(&quot;rank_desc&quot;)</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scala&gt; a.select($&quot;*&quot;, rankAsc, rankDesc).filter($&quot;rank_asc&quot;&lt;3 || $&quot;rank_desc&quot; &gt;= 2).show</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br><span class=\"line\">|age|depart|   name|salary|rank_asc|rank_desc|</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br><span class=\"line\">| 30|     B|   Andy|  4000|       2|        1|</span><br><span class=\"line\">| 19|     B|   Jack|  2000|       1|        2|</span><br><span class=\"line\">| 23|     A|    Ben|  3700|       4|        2|</span><br><span class=\"line\">| 23|     A|   Alex|  3600|       3|        3|</span><br><span class=\"line\">| 23|     A|    Dan|  3500|       2|        4|</span><br><span class=\"line\">| 23|     A|Michael|  3000|       1|        5|</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br><span class=\"line\">scala&gt; a.select($&quot;*&quot;, rankAsc, rankDesc).filter($&quot;rank_asc&quot;&lt;3 &amp;&amp; $&quot;rank_desc&quot; &gt;= 2).show</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br><span class=\"line\">|age|depart|   name|salary|rank_asc|rank_desc|</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br><span class=\"line\">| 19|     B|   Jack|  2000|       1|        2|</span><br><span class=\"line\">| 23|     A|    Dan|  3500|       2|        4|</span><br><span class=\"line\">| 23|     A|Michael|  3000|       1|        5|</span><br><span class=\"line\">+---+------+-------+------+--------+---------+</span><br></pre></td></tr></table></figure>\n<p>what’s more, it is clearly <code>select *</code> in SQL could by implemented by <code>select($&quot;*&quot;)</code></p>\n"},{"title":"UVa1225","date":"2016-12-21T14:37:52.000Z","_content":"\n\n```\n#include <stdlib.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <strings.h>\nint main ( int argc, char *argv[] )\n{\n    int a[10]={0};\n    int temp = 0;\n    int i =0;\n    int num=0;\n    while(1==scanf(\"%d\",&num)){\n        memset(a,0,sizeof(a));\n        for (i = 1; i <= num; i++) {\n            temp = i;\n            do {\n                a[temp%10]++;\n                temp = temp/10;\n            } while(temp);\n        }\n        for (i = 0; i < 9; i++) {\n            printf ( \"%d \",a[i] );           /* code */\n        }\n        printf ( \"%d\\n\", a[i] );\n    }\n    return EXIT_SUCCESS;\n}\t\t\t\t/* ----------  end of function main  ---------- */\n```\n","source":"_posts/UVa1225.md","raw":"---\ntitle: UVa1225\ndate: 2016-12-21 22:37:52\ntags: 竞赛\n---\n\n\n```\n#include <stdlib.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <strings.h>\nint main ( int argc, char *argv[] )\n{\n    int a[10]={0};\n    int temp = 0;\n    int i =0;\n    int num=0;\n    while(1==scanf(\"%d\",&num)){\n        memset(a,0,sizeof(a));\n        for (i = 1; i <= num; i++) {\n            temp = i;\n            do {\n                a[temp%10]++;\n                temp = temp/10;\n            } while(temp);\n        }\n        for (i = 0; i < 9; i++) {\n            printf ( \"%d \",a[i] );           /* code */\n        }\n        printf ( \"%d\\n\", a[i] );\n    }\n    return EXIT_SUCCESS;\n}\t\t\t\t/* ----------  end of function main  ---------- */\n```\n","slug":"UVa1225","published":1,"updated":"2016-12-22T10:33:58.946Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2nb5001lyeg3lz19oadp","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;strings.h&gt;</span><br><span class=\"line\">int main ( int argc, char *argv[] )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int a[10]=&#123;0&#125;;</span><br><span class=\"line\">    int temp = 0;</span><br><span class=\"line\">    int i =0;</span><br><span class=\"line\">    int num=0;</span><br><span class=\"line\">    while(1==scanf(&quot;%d&quot;,&amp;num))&#123;</span><br><span class=\"line\">        memset(a,0,sizeof(a));</span><br><span class=\"line\">        for (i = 1; i &lt;= num; i++) &#123;</span><br><span class=\"line\">            temp = i;</span><br><span class=\"line\">            do &#123;</span><br><span class=\"line\">                a[temp%10]++;</span><br><span class=\"line\">                temp = temp/10;</span><br><span class=\"line\">            &#125; while(temp);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        for (i = 0; i &lt; 9; i++) &#123;</span><br><span class=\"line\">            printf ( &quot;%d &quot;,a[i] );           /* code */</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        printf ( &quot;%d\\n&quot;, a[i] );</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return EXIT_SUCCESS;</span><br><span class=\"line\">&#125;\t\t\t\t/* ----------  end of function main  ---------- */</span><br></pre></td></tr></table></figure>\n","excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;strings.h&gt;</span><br><span class=\"line\">int main ( int argc, char *argv[] )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int a[10]=&#123;0&#125;;</span><br><span class=\"line\">    int temp = 0;</span><br><span class=\"line\">    int i =0;</span><br><span class=\"line\">    int num=0;</span><br><span class=\"line\">    while(1==scanf(&quot;%d&quot;,&amp;num))&#123;</span><br><span class=\"line\">        memset(a,0,sizeof(a));</span><br><span class=\"line\">        for (i = 1; i &lt;= num; i++) &#123;</span><br><span class=\"line\">            temp = i;</span><br><span class=\"line\">            do &#123;</span><br><span class=\"line\">                a[temp%10]++;</span><br><span class=\"line\">                temp = temp/10;</span><br><span class=\"line\">            &#125; while(temp);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        for (i = 0; i &lt; 9; i++) &#123;</span><br><span class=\"line\">            printf ( &quot;%d &quot;,a[i] );           /* code */</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        printf ( &quot;%d\\n&quot;, a[i] );</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return EXIT_SUCCESS;</span><br><span class=\"line\">&#125;\t\t\t\t/* ----------  end of function main  ---------- */</span><br></pre></td></tr></table></figure>\n"},{"title":"UVa455","date":"2016-12-21T15:44:56.000Z","_content":"\n\ninspired by my wife, and i got the code below\n```\n#include <stdlib.h>\n#include <stdio.h>\n#include <strings.h>\nint main ( int argc, char *argv[] )\n{\n    char buf[81];\n    int i = 0;\n    memset(buf,0,sizeof(buf));\n    while(scanf(\"%s\",buf)!=EOF){\n        for(i=1;i<strlen(buf);i++){\n            if ( strlen(buf)%i==0 ){\n                if (strncmp(buf,buf+i,strlen(buf)-i)==0) {\n                    printf ( \" k is %d\\n\",i );\n                    break;\n                }\n            }\n        }\n        if(i==strlen(buf)){\n            printf ( \"k is %d\\n\",i );\n        }\n        memset(buf,0,sizeof(buf));\n    }\n    return EXIT_SUCCESS;\n```\n","source":"_posts/UVa455.md","raw":"---\ntitle: UVa455\ndate: 2016-12-21 23:44:56\ntags: 竞赛\n---\n\n\ninspired by my wife, and i got the code below\n```\n#include <stdlib.h>\n#include <stdio.h>\n#include <strings.h>\nint main ( int argc, char *argv[] )\n{\n    char buf[81];\n    int i = 0;\n    memset(buf,0,sizeof(buf));\n    while(scanf(\"%s\",buf)!=EOF){\n        for(i=1;i<strlen(buf);i++){\n            if ( strlen(buf)%i==0 ){\n                if (strncmp(buf,buf+i,strlen(buf)-i)==0) {\n                    printf ( \" k is %d\\n\",i );\n                    break;\n                }\n            }\n        }\n        if(i==strlen(buf)){\n            printf ( \"k is %d\\n\",i );\n        }\n        memset(buf,0,sizeof(buf));\n    }\n    return EXIT_SUCCESS;\n```\n","slug":"UVa455","published":1,"updated":"2016-12-22T10:33:58.946Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixmu2nbe001myeg3f4txmp4p","content":"<p>inspired by my wife, and i got the code below<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;strings.h&gt;</span><br><span class=\"line\">int main ( int argc, char *argv[] )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    char buf[81];</span><br><span class=\"line\">    int i = 0;</span><br><span class=\"line\">    memset(buf,0,sizeof(buf));</span><br><span class=\"line\">    while(scanf(&quot;%s&quot;,buf)!=EOF)&#123;</span><br><span class=\"line\">        for(i=1;i&lt;strlen(buf);i++)&#123;</span><br><span class=\"line\">            if ( strlen(buf)%i==0 )&#123;</span><br><span class=\"line\">                if (strncmp(buf,buf+i,strlen(buf)-i)==0) &#123;</span><br><span class=\"line\">                    printf ( &quot; k is %d\\n&quot;,i );</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if(i==strlen(buf))&#123;</span><br><span class=\"line\">            printf ( &quot;k is %d\\n&quot;,i );</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        memset(buf,0,sizeof(buf));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return EXIT_SUCCESS;</span><br></pre></td></tr></table></figure></p>\n","excerpt":"","more":"<p>inspired by my wife, and i got the code below<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;strings.h&gt;</span><br><span class=\"line\">int main ( int argc, char *argv[] )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    char buf[81];</span><br><span class=\"line\">    int i = 0;</span><br><span class=\"line\">    memset(buf,0,sizeof(buf));</span><br><span class=\"line\">    while(scanf(&quot;%s&quot;,buf)!=EOF)&#123;</span><br><span class=\"line\">        for(i=1;i&lt;strlen(buf);i++)&#123;</span><br><span class=\"line\">            if ( strlen(buf)%i==0 )&#123;</span><br><span class=\"line\">                if (strncmp(buf,buf+i,strlen(buf)-i)==0) &#123;</span><br><span class=\"line\">                    printf ( &quot; k is %d\\n&quot;,i );</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if(i==strlen(buf))&#123;</span><br><span class=\"line\">            printf ( &quot;k is %d\\n&quot;,i );</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        memset(buf,0,sizeof(buf));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return EXIT_SUCCESS;</span><br></pre></td></tr></table></figure></p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cixmu2n7k0000yeg374yhsj2o","tag_id":"cixmu2n7y0002yeg3svjp5o53","_id":"cixmu2n8e0007yeg3kwjvjbza"},{"post_id":"cixmu2n7t0001yeg3h6pkhv0y","tag_id":"cixmu2n8a0005yeg3rq8urfir","_id":"cixmu2n8t000byeg39xljp5vd"},{"post_id":"cixmu2n840004yeg3i072nyhd","tag_id":"cixmu2n8t000ayeg31n8v6tai","_id":"cixmu2n93000gyeg3q9gl7ijs"},{"post_id":"cixmu2n8k0009yeg3k0stsdwv","tag_id":"cixmu2n90000eyeg3138n13nh","_id":"cixmu2n9c000kyeg3rnck7u4n"},{"post_id":"cixmu2n8u000cyeg3l66tpmma","tag_id":"cixmu2n99000iyeg30b7isakd","_id":"cixmu2n9i000oyeg3pjeam372"},{"post_id":"cixmu2n8y000dyeg3f72cq8kn","tag_id":"cixmu2n9f000myeg3x3ucuseg","_id":"cixmu2n9u000syeg3ve5yvyjq"},{"post_id":"cixmu2n91000fyeg3m64wospz","tag_id":"cixmu2n9s000ryeg3rxqj1cd5","_id":"cixmu2na4000xyeg33gw8j63t"},{"post_id":"cixmu2na2000wyeg3kn7nmx49","tag_id":"cixmu2n7y0002yeg3svjp5o53","_id":"cixmu2na80010yeg3bj9y8lof"},{"post_id":"cixmu2n95000hyeg328o79730","tag_id":"cixmu2n9s000ryeg3rxqj1cd5","_id":"cixmu2nab0012yeg3r0jc03qd"},{"post_id":"cixmu2n9a000jyeg34igxakw1","tag_id":"cixmu2n9f000myeg3x3ucuseg","_id":"cixmu2nal0016yeg3wpiiiyb4"},{"post_id":"cixmu2n9d000lyeg30kbalqs2","tag_id":"cixmu2n9f000myeg3x3ucuseg","_id":"cixmu2nas0019yeg3cmjbcvje"},{"post_id":"cixmu2n9k000pyeg3vsrd2y4g","tag_id":"cixmu2n9s000ryeg3rxqj1cd5","_id":"cixmu2nav001byeg3j4ry9kjt"},{"post_id":"cixmu2n9n000qyeg3ijtkosl2","tag_id":"cixmu2n9s000ryeg3rxqj1cd5","_id":"cixmu2nax001dyeg3brcciqbr"},{"post_id":"cixmu2n9v000tyeg3hiyy3e6o","tag_id":"cixmu2naw001cyeg3hp9ferfr","_id":"cixmu2nay001fyeg33u45ewal"},{"post_id":"cixmu2n9y000uyeg3stasyio4","tag_id":"cixmu2nay001eyeg39owd0icn","_id":"cixmu2naz001hyeg33a6gczg0"},{"post_id":"cixmu2na90011yeg34na39s4d","tag_id":"cixmu2naz001gyeg3wdehz0ur","_id":"cixmu2nb1001jyeg3b0vritw7"},{"post_id":"cixmu2nam0017yeg3au5zwog2","tag_id":"cixmu2nb1001iyeg3xvsisvr2","_id":"cixmu2nb2001kyeg3s8of4plt"},{"post_id":"cixmu2nb5001lyeg3lz19oadp","tag_id":"cixmu2n99000iyeg30b7isakd","_id":"cixmu2nbg001nyeg3wnzzht2k"},{"post_id":"cixmu2nbe001myeg3f4txmp4p","tag_id":"cixmu2n99000iyeg30b7isakd","_id":"cixmu2nbh001oyeg3omdxdtlq"}],"Tag":[{"name":"tensorflow","_id":"cixmu2n7y0002yeg3svjp5o53"},{"name":"基础","_id":"cixmu2n8a0005yeg3rq8urfir"},{"name":"Flink","_id":"cixmu2n8t000ayeg31n8v6tai"},{"name":"Python","_id":"cixmu2n90000eyeg3138n13nh"},{"name":"竞赛","_id":"cixmu2n99000iyeg30b7isakd"},{"name":"Scala","_id":"cixmu2n9f000myeg3x3ucuseg"},{"name":"Spark","_id":"cixmu2n9s000ryeg3rxqj1cd5"},{"name":"Spark Scala Streaming","_id":"cixmu2naw001cyeg3hp9ferfr"},{"name":"Spark Streaming","_id":"cixmu2nay001eyeg39owd0icn"},{"name":"VIM","_id":"cixmu2naz001gyeg3wdehz0ur"},{"name":"Spark DataFrame","_id":"cixmu2nb1001iyeg3xvsisvr2"}]}}