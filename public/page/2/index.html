<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Page 2 | Zhangshengshan&#39;s Blog</title>
  <meta name="author" content="Zhang ShengShan">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Zhangshengshan&#39;s Blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  
  
    <link href="/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/css/themes/simplex.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  


<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?500f3b30aa83b6b7466c7ce0c0c18fb8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>

 <body>  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/">Zhangshengshan&#39;s Blog</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 <div class="page-header page-header-inverse ">
  <h1 class="title title-inverse ">Blogs on machine learning for my baby Ruru</h1>
</div>

<div class="row page">

	
	<div class="col-md-9">
	

		<div class="slogan">
      <i class="fa fa-heart"></i>
      Yet another bootstrap theme.
</div>    
		<div id="top_search"></div>
		<div class="mypage">
		
		<!-- title and entry -->
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2016-12-09 </div>
			<div class="article-title"><a href="/2016/12/09/SparkDataFrameLikeSql/" >SparkDataFrameLikeSql</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
	
		<p>The idea of spark Datafame may be inspired from dataframe of pandas which is a package of python for structure data processing. On my opinion, dataframe can by prefered by the people with BI(business intelligence) background for high development efficiency.</p>
<p>DataFrame in Spark could by registered as something which could be considered approximately as a virtual table, therefore anyone who has expierence of SQL could explore the data at quite a low cost of time.</p>
<p>This article will focus on some dataframe processing method without the help of registering a virtual table and executing SQL, however the corresponding SQL operations such as  SELECT, WHERE, GROUPBY, MIN, MAX, COUNT, SUM ,DISTINCT, ORDERBY, DESC/ASC, JOIN and GROUPBY TOP will be supplied for a better understanding of dataframe in spark.</p>
<h2 id="prepare-test-data"><a href="#prepare-test-data" class="headerlink" title="prepare test data"></a>prepare test data</h2><p>Firstly we make a DataFrame object a by reading a json file<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val sc: SparkContext // An existing SparkContext.</span><br><span class="line">val sqlContext = new org.apache.spark.sql.SQLContext(sc)</span><br><span class="line">// this is used to implicitly convert an RDD to a DataFrame.</span><br><span class="line">import sqlContext.implicits._</span><br><span class="line">val a = sqlContext.read.json(&quot;people.json&quot;)</span><br></pre></td></tr></table></figure></p>
<p>and the content of people.json is as below<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;name&quot;:&quot;Michael&quot; , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3000 &#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;Dan&quot;     , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3500 &#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;Alex&quot;    , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3600 &#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;Ben&quot;     , &quot;age&quot;:23 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:3700 &#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;Andy&quot;    , &quot;age&quot;:30 ,&quot;depart&quot;:&quot;B&quot;,&quot;salary&quot;:4000 &#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;Justin&quot;  , &quot;age&quot;:19 ,&quot;depart&quot;:&quot;A&quot;,&quot;salary&quot;:5000 &#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;Jack&quot;    , &quot;age&quot;:19 ,&quot;depart&quot;:&quot;B&quot;,&quot;salary&quot;:2000 &#125;</span><br></pre></td></tr></table></figure></p>
<p>let us image a as a Table which is stored in a RDS database such as MySQL.</p>
<h2 id="desc"><a href="#desc" class="headerlink" title="desc"></a>desc</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc people;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; a.printSchema</span><br><span class="line">root</span><br><span class="line">|-- age: long (nullable = true)</span><br><span class="line">|-- depart: string (nullable = true)</span><br><span class="line">|-- name: string (nullable = true)</span><br><span class="line">|-- salary: long (nullable = true)</span><br></pre></td></tr></table></figure>
<h2 id="SELECT"><a href="#SELECT" class="headerlink" title="SELECT"></a>SELECT</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select name from people;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a.select(&quot;name&quot;).show</span><br><span class="line">a.select($&quot;name&quot;).show</span><br><span class="line">a.select(a(&quot;name&quot;)).show</span><br></pre></td></tr></table></figure>
<p>the three methods above are equivelent.</p>
<h2 id="WHERE"><a href="#WHERE" class="headerlink" title="WHERE"></a>WHERE</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select name,age from people where age = 23</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a.select(&quot;name&quot;, &quot;age&quot;).where($&quot;age&quot;===23).show</span><br><span class="line">a.select(&quot;name&quot;, &quot;age&quot;).filter($&quot;age&quot;===23).show</span><br></pre></td></tr></table></figure>
<h2 id="MIN-MAX-SUM-COUNT"><a href="#MIN-MAX-SUM-COUNT" class="headerlink" title="MIN,MAX,SUM,COUNT"></a>MIN,MAX,SUM,COUNT</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select min(age), max(age), sum(salary), count(age) from people</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a.select(min(&quot;age&quot;),max(&quot;age&quot;),sum(&quot;salary&quot;),count(&quot;age&quot;)).show</span><br><span class="line">a.agg(min(&quot;age&quot;),max(&quot;age&quot;),sum(&quot;salary&quot;),count(&quot;age&quot;)).show</span><br></pre></td></tr></table></figure>
<p>and the result is<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+--------+--------+-----------+----------+</span><br><span class="line">|min(age)|max(age)|sum(salary)|count(age)|</span><br><span class="line">+--------+--------+-----------+----------+</span><br><span class="line">|      19|      30|      24800|         7|</span><br><span class="line">+--------+--------+-----------+----------+</span><br></pre></td></tr></table></figure></p>
<h2 id="COUNT-DISTINCT"><a href="#COUNT-DISTINCT" class="headerlink" title="COUNT DISTINCT"></a>COUNT DISTINCT</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count (distinct age) , count ( distinct name ) from people</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a.select(count(&quot;age&quot;),countDistinct(&quot;age&quot;)).show</span><br><span class="line">a.agg(count(&quot;age&quot;), countDistinct(&quot;name&quot;)).show</span><br></pre></td></tr></table></figure>
<p>and the result is<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+-------------------+--------------------+</span><br><span class="line">|count(DISTINCT age)|count(DISTINCT name)|</span><br><span class="line">+-------------------+--------------------+</span><br><span class="line">|                  7|                   3|</span><br><span class="line">+-------------------+--------------------+</span><br></pre></td></tr></table></figure></p>
<h2 id="ORDERBY-desc"><a href="#ORDERBY-desc" class="headerlink" title="ORDERBY desc"></a>ORDERBY desc</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from people orderby age desc, name desc</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a.sort($&quot;age&quot;.desc,$&quot;name&quot;.desc).show</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+---+------+-------+------+</span><br><span class="line">|age|depart|   name|salary|</span><br><span class="line">+---+------+-------+------+</span><br><span class="line">| 30|     B|   Andy|  4000|</span><br><span class="line">| 23|     A|Michael|  3000|</span><br><span class="line">| 23|     A|    Dan|  3500|</span><br><span class="line">| 23|     A|    Ben|  3700|</span><br><span class="line">| 23|     A|   Alex|  3600|</span><br><span class="line">| 19|     A| Justin|  5000|</span><br><span class="line">| 19|     B|   Jack|  2000|</span><br><span class="line">+---+------+-------+------+</span><br></pre></td></tr></table></figure>
<h2 id="inner-join-left-outer-join-and-convert-null-to-a-default-value"><a href="#inner-join-left-outer-join-and-convert-null-to-a-default-value" class="headerlink" title="inner join, left outer join and convert null to a default value"></a>inner join, left outer join and convert null to a default value</h2><p>first we make another dataframe based on a<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">val c = a.filter(not ($&quot;age&quot;===23))</span><br><span class="line"></span><br><span class="line">scala&gt; c.show</span><br><span class="line">+---+------+------+------+</span><br><span class="line">|age|depart|  name|salary|</span><br><span class="line">+---+------+------+------+</span><br><span class="line">| 30|     B|  Andy|  4000|</span><br><span class="line">| 19|     A|Justin|  5000|</span><br><span class="line">| 19|     B|  Jack|  2000|</span><br><span class="line">+---+------+------+------+</span><br></pre></td></tr></table></figure></p>
<p>now we try to join a and c </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line">    a.age as a_age,</span><br><span class="line">    if(c.age is null, 0, c.age) as c_age,</span><br><span class="line">    a.depart as a_depart</span><br><span class="line">from </span><br><span class="line">    a</span><br><span class="line">left outer join</span><br><span class="line">    c</span><br><span class="line">on </span><br><span class="line">    a.age = c.age</span><br></pre></td></tr></table></figure>
<p>the cording dataframe form is<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">scala&gt; a.join(c,a(&quot;age&quot;)===c(&quot;age&quot;),&quot;left&quot;).select(a(&quot;age&quot;).alias(&quot;a_age&quot;),c(&quot;age&quot;).alias(&quot;c_age&quot;),a(&quot;depart&quot;).alias(&quot;a_depart&quot;)).na.fill(0,Seq(&quot;c_age&quot;)).show</span><br><span class="line">+-----+-----+--------+</span><br><span class="line">|a_age|c_age|a_depart|</span><br><span class="line">+-----+-----+--------+</span><br><span class="line">|   23|    0|       A|</span><br><span class="line">|   23|    0|       A|</span><br><span class="line">|   23|    0|       A|</span><br><span class="line">|   23|    0|       A|</span><br><span class="line">|   30|   30|       B|</span><br><span class="line">|   19|   19|       A|</span><br><span class="line">|   19|   19|       A|</span><br><span class="line">|   19|   19|       B|</span><br><span class="line">|   19|   19|       B|</span><br><span class="line">+-----+-----+--------+</span><br></pre></td></tr></table></figure></p>
<p>what if those records whose c.age is null is execluded<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line">    a.age as a_age,</span><br><span class="line">    if(c.age is null, 0, c.age) as c_age,</span><br><span class="line">    a.depart as a_depart</span><br><span class="line">from </span><br><span class="line">    a</span><br><span class="line">left outer join</span><br><span class="line">    c</span><br><span class="line">on </span><br><span class="line">    a.age = c.age</span><br><span class="line">where </span><br><span class="line">    c.age is not null</span><br></pre></td></tr></table></figure></p>
<p>the na.drop method provided this function<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; a.join(c,a(&quot;age&quot;)===c(&quot;age&quot;),&quot;left&quot;).select(a(&quot;age&quot;).alias(&quot;a_age&quot;),c(&quot;age&quot;).alias(&quot;c_age&quot;),a(&quot;depart&quot;).alias(&quot;a_depart&quot;)).na.drop.show</span><br><span class="line">+-----+-----+--------+</span><br><span class="line">|a_age|c_age|a_depart|</span><br><span class="line">+-----+-----+--------+</span><br><span class="line">|   30|   30|       B|</span><br><span class="line">|   19|   19|       A|</span><br><span class="line">|   19|   19|       A|</span><br><span class="line">|   19|   19|       B|</span><br><span class="line">|   19|   19|       B|</span><br><span class="line">+-----+-----+--------+</span><br></pre></td></tr></table></figure></p>
<h2 id="Top-N-for-group"><a href="#Top-N-for-group" class="headerlink" title="Top N for group"></a>Top N for group</h2><p>use window operation can help<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.sql.expressions.Window</span><br><span class="line">val w = Window.partitionBy($&quot;depart&quot;)</span><br><span class="line">import org.apache.spark.sql.expressions.Window</span><br><span class="line">val rankAsc = row_number().over(w.orderBy($&quot;salary&quot;)).alias(&quot;rank_asc&quot;)</span><br><span class="line">val rankDesc = row_number().over(w.orderBy($&quot;salary&quot;.desc)).alias(&quot;rank_desc&quot;)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; a.select($&quot;*&quot;, rankAsc, rankDesc).filter($&quot;rank_asc&quot;&lt;3 || $&quot;rank_desc&quot; &gt;= 2).show</span><br><span class="line">+---+------+-------+------+--------+---------+</span><br><span class="line">|age|depart|   name|salary|rank_asc|rank_desc|</span><br><span class="line">+---+------+-------+------+--------+---------+</span><br><span class="line">| 30|     B|   Andy|  4000|       2|        1|</span><br><span class="line">| 19|     B|   Jack|  2000|       1|        2|</span><br><span class="line">| 23|     A|    Ben|  3700|       4|        2|</span><br><span class="line">| 23|     A|   Alex|  3600|       3|        3|</span><br><span class="line">| 23|     A|    Dan|  3500|       2|        4|</span><br><span class="line">| 23|     A|Michael|  3000|       1|        5|</span><br><span class="line">+---+------+-------+------+--------+---------+</span><br><span class="line">scala&gt; a.select($&quot;*&quot;, rankAsc, rankDesc).filter($&quot;rank_asc&quot;&lt;3 &amp;&amp; $&quot;rank_desc&quot; &gt;= 2).show</span><br><span class="line">+---+------+-------+------+--------+---------+</span><br><span class="line">|age|depart|   name|salary|rank_asc|rank_desc|</span><br><span class="line">+---+------+-------+------+--------+---------+</span><br><span class="line">| 19|     B|   Jack|  2000|       1|        2|</span><br><span class="line">| 23|     A|    Dan|  3500|       2|        4|</span><br><span class="line">| 23|     A|Michael|  3000|       1|        5|</span><br><span class="line">+---+------+-------+------+--------+---------+</span><br></pre></td></tr></table></figure>
<p>what’s more, it is clearly <code>select *</code> in SQL could by implemented by <code>select($&quot;*&quot;)</code></p>

	
	</div>
  <a type="button" href="/2016/12/09/SparkDataFrameLikeSql/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2016-12-05 </div>
			<div class="article-title"><a href="/2016/12/05/save-spark-rdd-into-Mysql/" >save spark rdd into Mysql</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
	
		<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Properties</span><br><span class="line">val target_df = targetRdd.toDF()</span><br><span class="line">val prop = new Properties()</span><br><span class="line">prop.put(&quot;user&quot;, &quot;username&quot;)</span><br><span class="line">prop.put(&quot;password&quot;, &quot;password&quot;)</span><br><span class="line">ret_df.write.mode(&quot;append&quot;).jdbc(&quot;jdbc:mysql://host:port/database&quot;,&quot;table&quot;,prop)</span><br></pre></td></tr></table></figure>

	
	</div>
  <a type="button" href="/2016/12/05/save-spark-rdd-into-Mysql/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2016-11-28 </div>
			<div class="article-title"><a href="/2016/11/28/SparkStreamLearning/" >SparkStreamLearning</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
	
		<h1 id="input-source"><a href="#input-source" class="headerlink" title="input source"></a>input source</h1><p>kafka<br>akka</p>
<h1 id="output"><a href="#output" class="headerlink" title="output"></a>output</h1><p>redis<br>kafka<br>elasticSearch<br>hive<br>mySql</p>

	
	</div>
  <a type="button" href="/2016/11/28/SparkStreamLearning/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2016-11-10 </div>
			<div class="article-title"><a href="/2016/11/10/MAC访问你DOCKER容器中的WEB页面/" >MAC访问你DOCKER容器中的WEB页面</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
	
		<p>docker run -d -p hostport:dockerport –name your_container_name  your_image_name nginx -g “daemon off;”</p>
<p>the above instruction start a docker nginx application which bind is port dockerport to its host port hostport.<br>usually you can access the nginx service on your host environment by curl the hostport, however in MacOs, ths hostport here<br>is the virtual machine. so when you curl localhost:hostport, you will get no response.</p>
<p>the right way is access the virtual machine responding port. so the ip of virtual machine is needed.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-machine ip your_virtual_machine</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl the ip you get:hostport</span><br></pre></td></tr></table></figure>

	
	</div>
  <a type="button" href="/2016/11/10/MAC访问你DOCKER容器中的WEB页面/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2016-11-09 </div>
			<div class="article-title"><a href="/2016/11/09/Install-Caffe-on-CentOS/" >Install Caffe on CentOS</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
	
		<p>尽量不要在CentOS平台上安装Caffe</p>

	
	</div>
  <a type="button" href="/2016/11/09/Install-Caffe-on-CentOS/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2016-08-22 </div>
			<div class="article-title"><a href="/2016/08/22/Spark-Window-Operation/" >Spark Window Operation </a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
	
		
	
	</div>
  <a type="button" href="/2016/08/22/Spark-Window-Operation/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2016-08-19 </div>
			<div class="article-title"><a href="/2016/08/19/Spark-2-0-Introduction/" >Spark 2.0 Introduction</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
	
		<h1 id="Spark-2-0-MLib-Introduction"><a href="#Spark-2-0-MLib-Introduction" class="headerlink" title="Spark 2.0 MLib Introduction"></a>Spark 2.0 MLib Introduction</h1><p>As of Spark 2.0, the RDD-based APIs in the spark.mllib package have entered maintenance mode. The primary Machine Learning API for Spark is now the DataFrame-based API in the spark.ml package.</p>
<p>Spark2.0 ,在spark.mllib中的基于RDD的机器学习APIs将会进入维护模式。现在机器学习的主要的API基于DataFrame,位于spark.ml中。</p>
<p>What are the implications?</p>
<pre><code>MLlib will still support the RDD-based API in spark.mllib with bug fixes.
MLlib will not add new features to the RDD-based API.
In the Spark 2.x releases, MLlib will add features to the DataFrames-based API to reach feature parity with the RDD-based API.
After reaching feature parity (roughly estimated for Spark 2.2), the RDD-based API will be deprecated.
The RDD-based API is expected to be removed in Spark 3.0.
</code></pre><p>Why is MLlib switching to the DataFrame-based API?</p>
<pre><code>DataFrames provide a more user-friendly API than RDDs. The many benefits of DataFrames include Spark Datasources, SQL/DataFrame queries, Tungsten and Catalyst optimizations, and uniform APIs across languages.
The DataFrame-based API for MLlib provides a uniform API across ML algorithms and across multiple languages.
DataFrames facilitate practical ML Pipelines, particularly feature transformations. See the Pipelines guide for details.
</code></pre>
	
	</div>
  <a type="button" href="/2016/08/19/Spark-2-0-Introduction/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2016-08-19 </div>
			<div class="article-title"><a href="/2016/08/19/Save-DataFrame-into-a-partitioned-table-of-HIVE/" >Save DataFrame into a partitioned table of HIVE</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
	
		<h1 id="How-to-save-a-spark-DataFrame-as-a-patitioned-hive-table"><a href="#How-to-save-a-spark-DataFrame-as-a-patitioned-hive-table" class="headerlink" title="How to save a spark DataFrame as a patitioned hive table"></a>How to save a spark DataFrame as a patitioned hive table</h1><h2 id="utilise-saveAsTable-method"><a href="#utilise-saveAsTable-method" class="headerlink" title="utilise saveAsTable method"></a>utilise saveAsTable method</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">val conf = new SparkConf().setAppName(&quot;Simple Application&quot;).setMaster(&quot;local&quot;)</span><br><span class="line">val sc = new SparkContext(conf)</span><br><span class="line">val sqlContext = new org.apache.spark.sql.SQLContext(sc)</span><br><span class="line">import sqlContext.implicits._</span><br><span class="line">val hiveContext = new org.apache.spark.sql.hive.HiveContext(sc)</span><br><span class="line">hiveContext.sql(&quot;use database&quot;)</span><br><span class="line"></span><br><span class="line">val cmd =</span><br><span class="line">  &quot;&quot;&quot;</span><br><span class="line">     select</span><br><span class="line">      col1,</span><br><span class="line">      col2</span><br><span class="line">     from</span><br><span class="line">      table</span><br><span class="line">  &quot;&quot;&quot;.stripMargin</span><br><span class="line">val yourDf = hiveContext.sql(cmd)</span><br><span class="line">yourDf.printSchema()</span><br><span class="line">yourDf.write.partitionBy(&quot;col2&quot;).saveAsTable(&quot;partitionTableName&quot;)</span><br></pre></td></tr></table></figure>

	
	</div>
  <a type="button" href="/2016/08/19/Save-DataFrame-into-a-partitioned-table-of-HIVE/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2016-08-11 </div>
			<div class="article-title"><a href="/2016/08/11/SparkPassFunctions/" >SparkPassFunctions</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
	
		<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class MyClass &#123;</span><br><span class="line">  val field = &quot;Hello&quot;</span><br><span class="line">  def doStuff(rdd: RDD[String]): RDD[String] = &#123;</span><br><span class="line">  val field_ = this.field</span><br><span class="line">  rdd.map(x =&gt; field_ + x)&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

	
	</div>
  <a type="button" href="/2016/08/11/SparkPassFunctions/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2016-07-26 </div>
			<div class="article-title"><a href="/2016/07/26/MergeSort/" >MergeSort</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
	
		<p>归并排序</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def msort[A](less: (A, A) =&gt; Boolean)(xs: List[A]): List[A] = &#123; </span><br><span class="line">    def merge(xs1: List[A], xs2: List[A]): List[A] =</span><br><span class="line">        if (xs1.isEmpty) xs2</span><br><span class="line">        else if (xs2.isEmpty) xs1</span><br><span class="line">        else if (less(xs1.head, xs2.head)) xs1.head :: merge(xs1.tail, xs2) else xs2.head :: merge(xs1, xs2.tail)</span><br><span class="line">    val n = xs.length/2</span><br><span class="line">    if (n == 0) xs</span><br><span class="line">    else merge(msort(less)(xs take n), msort(less)(xs drop n))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果你对python列表的用法比较熟悉的话，可以按照如下的方式理解</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xs take n   // xs[0:n+1]</span><br><span class="line">xs drop n   // xs[n+1:]</span><br></pre></td></tr></table></figure>
<p>msort函数应该按照如下方式进行调用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">msort((x: Int, y: Int) =&gt; x &lt; y)(List(5, 7, 1, 3))</span><br></pre></td></tr></table></figure></p>

	
	</div>
  <a type="button" href="/2016/07/26/MergeSort/#more" class="btn btn-default more">Read More</a>
</div>

		

		</div>

		<!-- pagination -->
		<div>
  		<center>
		<div class="pagination">
<ul class="pagination">
	 
		
    	<li class="prev"><a href="/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i> Prev</a></li>
  		

        <li><a href="/"><i class="fa fa-home"></i>Home</a></li>

		
		   <li class="next"> <a href="/page/3/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a> </li>          
        
	
</ul>
</div>

  		</center>
		</div>

		
		
	</div> <!-- col-md-9 -->

	
		<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
		
			
	<div class="widget">
		<h4>Tag Cloud</h4>
		<ul class="tag_box inline list-unstyled">		
		
			<li><a href="/tags/tensorflow/">tensorflow<span>2</span></a></li>
		
			<li><a href="/tags/Flink/">Flink<span>1</span></a></li>
		
			<li><a href="/tags/Spark-Scala-Streaming/">Spark Scala Streaming<span>1</span></a></li>
		
			<li><a href="/tags/Spark/">Spark<span>4</span></a></li>
		
			<li><a href="/tags/Python/">Python<span>1</span></a></li>
		
			<li><a href="/tags/Spark-DataFrame/">Spark DataFrame<span>1</span></a></li>
		
			<li><a href="/tags/基础/">基础<span>1</span></a></li>
		
			<li><a href="/tags/Scala/">Scala<span>3</span></a></li>
		
			<li><a href="/tags/竞赛/">竞赛<span>3</span></a></li>
		
			<li><a href="/tags/VIM/">VIM<span>1</span></a></li>
		
			<li><a href="/tags/Spark-Streaming/">Spark Streaming<span>1</span></a></li>
		
		 
		</ul>
	</div>


		
			
<div class="widget">
  <h4>Recent Posts</h4>
  <ul class="entry list-unstyled">
    
      <li>
        <a href="/2017/01/07/LearningFlink/" ><i class="fa fa-file-o"></i>LearningFlink</a>
      </li>
    
      <li>
        <a href="/2017/01/04/Deep-MNIST-for-Experts/" ><i class="fa fa-file-o"></i>Deep MNIST for Experts</a>
      </li>
    
      <li>
        <a href="/2017/01/04/Google-面试宝典/" ><i class="fa fa-file-o"></i>Google 面试宝典</a>
      </li>
    
      <li>
        <a href="/2016/12/28/install-tensorflow/" ><i class="fa fa-file-o"></i>install tensorflow</a>
      </li>
    
      <li>
        <a href="/2016/12/22/vim使用技巧/" ><i class="fa fa-file-o"></i>vim使用技巧</a>
      </li>
    
  </ul>
</div>

		
			
<div class="widget">
	<h4>Contact</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/zhangshengshan" title="My Github account." target="_blank"]);">Github</a></li>
	
		<li><i class="fa fa-envelope-o"></i><a href="mailto:zsszss0000@163.com" title="My Email account." target="_blank"]);">Email</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->

	
	
</div> <!-- row-fluid -->

	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2017 Zhang ShengShan
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
   </html>
